{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import IPython\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymedphys\n",
    "import pymedphys._wlutz.findfield\n",
    "import pymedphys._wlutz.iview\n",
    "import pymedphys._wlutz.imginterp\n",
    "import pymedphys._wlutz.reporting\n",
    "import pymedphys._wlutz.interppoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_diameter = 8 * 2\n",
    "edge_lengths = np.array([20, 24]) * 2\n",
    "penumbra = 2 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_paths = pymedphys.zenodo_data_paths('wlutz_tensorflow_training_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = {path.stem: path for path in training_data_paths if path.suffix == '.png'}\n",
    "labels_path = [path for path in training_data_paths if path.suffix == '.json'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(labels_path, 'r') as labels_file:\n",
    "    all_labels = json.load(labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {key: label['pymedphys'] for key, label in all_labels.items() if 'bb_centre' in label['pymedphys']}\n",
    "keys = np.array(list(labels.keys()))\n",
    "np.random.shuffle(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_a = len(keys) // 8\n",
    "split_b = len(keys) // 4\n",
    "\n",
    "validation_keys = keys[0:split_a]\n",
    "test_keys = keys[split_a:split_b]\n",
    "train_keys = keys[split_b::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_dx = [-edge_lengths[0] / 2, 0, edge_lengths[0], 0, -edge_lengths[0]]\n",
    "rect_dy = [-edge_lengths[1] / 2, edge_lengths[1], 0, -edge_lengths[1], 0]\n",
    "\n",
    "draw_x = tf.convert_to_tensor(np.cumsum(rect_dx), dtype=tf.float32)\n",
    "draw_y = tf.convert_to_tensor(np.cumsum(rect_dy), dtype=tf.float32)\n",
    "\n",
    "coord = tf.range(0,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,IMG_SIZE)\n",
    "y = np.arange(0,IMG_SIZE)\n",
    "\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "dx = 1/16\n",
    "x_expand = np.arange(-0.5 + dx/2, 127.5, dx)\n",
    "y_expand = np.arange(-0.5 + dx/2, 127.5, dx)\n",
    "\n",
    "xx_expand, yy_expand = np.meshgrid(x_expand, y_expand)\n",
    "\n",
    "bb_radius_sqrd = (bb_diameter / 2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_abs(coords):\n",
    "    return 63 - np.array(coords)*2\n",
    "\n",
    "def transform_labels(label):\n",
    "    field_rotation = label['field_rotation'] / 90\n",
    "    field_centre = transform_to_abs(label['field_centre'])\n",
    "    bb_centre = transform_to_abs(label['bb_centre'])\n",
    "    encoding = [field_centre[0], field_centre[1], field_rotation, bb_centre[0], bb_centre[1]]\n",
    "    \n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def reduce_expanded_mask(expanded_mask):\n",
    "    expanded_mask = tf.dtypes.cast(expanded_mask, tf.float32)\n",
    "    return tf.reduce_mean(tf.reduce_mean(tf.reshape(expanded_mask, (128, 16, 128, 16)), axis=1), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_circle_mask(bb_centre):\n",
    "    expanded_mask = (xx_expand - bb_centre[0])**2 + (yy_expand - bb_centre[1])**2 <= bb_radius_sqrd\n",
    "    circle_mask = reduce_expanded_mask(expanded_mask)\n",
    "    \n",
    "    return circle_mask * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.convert_to_tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_transformation_matrix(field_centre, field_rotation):\n",
    "    field_rotation_radians = field_rotation / 180 * np.pi\n",
    "    sin = tf.math.sin(field_rotation_radians)\n",
    "    cos = tf.math.cos(field_rotation_radians)\n",
    "    x = field_centre[0]\n",
    "    y = field_centre[1]\n",
    "    rand = np.random.uniform(0,1)\n",
    "    \n",
    "    return tf.convert_to_tensor([[cos, sin, x], [-sin, cos, y], [0, 0, 1]], name=f\"transformation_{rand}\", dtype=tf.float32)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def apply_transform(xx, yy, transform):\n",
    "    xx_flat = tf.reshape(xx, (-1,))\n",
    "    yy_flat = tf.reshape(yy, (-1,))\n",
    "    transformed = tf.matmul(transform, tf.stack([xx_flat, yy_flat, tf.ones_like(xx_flat, dtype=tf.float32)], axis=0))\n",
    "\n",
    "    xx_transformed = transformed[0]\n",
    "    yy_transformed = transformed[1]\n",
    "    \n",
    "    xx_transformed = tf.reshape(xx_transformed, xx.shape)\n",
    "    yy_transformed = tf.reshape(yy_transformed, yy.shape)\n",
    "\n",
    "    return xx_transformed, yy_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_partial_rect_mask(field_centre, x1, x2, y1, y2):  \n",
    "    m = (y2 - y1)/(x2 - x1)\n",
    "    c = y1 - m * x1\n",
    "    \n",
    "    field_x = field_centre[0]\n",
    "    field_y = field_centre[1]\n",
    "    \n",
    "    if (field_y <= field_x*m + c):\n",
    "        rect_mask = yy_expand <= xx_expand*m + c\n",
    "    else:\n",
    "        rect_mask = yy_expand >= xx_expand*m + c\n",
    "    \n",
    "    return rect_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_rect_mask(field_centre, field_rotation):\n",
    "    field_rotation = field_rotation\n",
    "    \n",
    "    transform = get_transformation_matrix(field_centre, field_rotation)\n",
    "    transformed_x, transformed_y = apply_transform(draw_x, draw_y, transform)\n",
    "\n",
    "    bounds_x = transformed_x[0:4]\n",
    "    bounds_y = transformed_y[0:4]\n",
    "\n",
    "    partial_masks = [\n",
    "        get_partial_rect_mask(\n",
    "            field_centre, bounds_x[i], bounds_x[(i + 1) % 4], bounds_y[i], bounds_y[(i + 1) % 4]\n",
    "        )\n",
    "        for i in range(4)]\n",
    "    \n",
    "    expanded_mask = (\n",
    "        partial_masks[0] &\n",
    "        partial_masks[1] &\n",
    "        partial_masks[2] &\n",
    "        partial_masks[3]\n",
    "    )\n",
    "    \n",
    "    return reduce_expanded_mask(expanded_mask) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_items_from_encoding(encoding):   \n",
    "    field_centre = [encoding[0], encoding[1]]\n",
    "    field_rotation = encoding[2] * 90\n",
    "    bb_centre = [encoding[3], encoding[4]]\n",
    "\n",
    "    return field_centre, field_rotation, bb_centre\n",
    "\n",
    "\n",
    "def extract_items_from_encodings(encodings):\n",
    "    field_centres = []\n",
    "    field_rotations = []\n",
    "    bb_centres = []\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        field_centres.append([encoding[0,0,0], encoding[0,0,1]])\n",
    "        field_rotations.append(encoding[0,0,2] * 90)\n",
    "        bb_centres.append([encoding[0,0,3], encoding[0,0,4]])\n",
    "    \n",
    "    return field_centres, field_rotations, bb_centres\n",
    "\n",
    "def decode(encoding):\n",
    "    return create_mask(*extract_items_from_encoding(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(image_path, encoding):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_png(image)\n",
    "\n",
    "    dim = tf.shape(image)\n",
    "    if dim[0] == 1024 and dim[1] == 1024:\n",
    "        image = image[1::2, ::2, :]\n",
    "\n",
    "    image = tf.image.central_crop(image, 0.25)\n",
    "    image = tf.reverse(image, [1])\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    image = 1 - (image / 127.5)\n",
    "    \n",
    "    encoding = tf.cast(encoding, dtype=tf.float32)\n",
    "    \n",
    "    mask = decode(encoding)\n",
    "    \n",
    "    return image[None, ...], mask[None, ...], encoding\n",
    "\n",
    "\n",
    "def get_dataset(keys, image_paths, labels):\n",
    "    image_paths_array = np.array([str(image_paths[key]) for key in keys])\n",
    "    labels_array = np.array([transform_labels(labels[key]) for key in keys])\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths_array, labels_array))\n",
    "    dataset = dataset.map(load)\n",
    "    dataset = dataset.shuffle(400)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(field_centre, field_rotation, bb_centre):\n",
    "    \n",
    "    circle_mask = get_circle_mask(bb_centre)\n",
    "    rect_mask = get_rect_mask(field_centre, field_rotation)\n",
    "    \n",
    "    mask = tf.concat([circle_mask[:,:,None], rect_mask[:,:,None]], axis=2)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "train_dataset = get_dataset(train_keys, image_paths, labels)\n",
    "test_dataset = get_dataset(test_keys, image_paths, labels)\n",
    "# train_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_dataset.take(1):\n",
    "    sample_image, sample_mask, sample_encoding = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.layers.Dense(5, activation=tf.keras.layers.LeakyReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2D(\n",
    "            filters, size, strides=2, padding='same',\n",
    "            kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def decode_batch(encoding):\n",
    "    \n",
    "    field_centre = [encoding[0, 0, 0, 0], encoding[0, 0, 0, 1]]\n",
    "    field_rotation = encoding[0, 0, 0, 2] * 90\n",
    "    bb_centre = [encoding[0, 0, 0, 3], encoding[0, 0, 0, 4]]\n",
    "\n",
    "    circle_mask = get_circle_mask(bb_centre)\n",
    "    rect_mask = get_rect_mask(field_centre, field_rotation)\n",
    "\n",
    "    mask = tf.concat([circle_mask[None,:,:,None], rect_mask[None,:,:,None]], axis=3)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DecodeToMask(tf.keras.layers.Layer):\n",
    "#     def __init__(self, *args, input_dim=512, **kwargs):\n",
    "#         super(DecodeToMask, self).__init__(*args, **kwargs)\n",
    "#         units = 5\n",
    "        \n",
    "#         w_init = tf.random_normal_initializer()\n",
    "#         self.w = tf.Variable(initial_value=w_init(shape=(input_dim, units),\n",
    "#                                                   dtype='float32'),\n",
    "#                              trainable=True)\n",
    "#         b_init = tf.zeros_initializer()\n",
    "#         self.b = tf.Variable(initial_value=b_init(shape=(units,),\n",
    "#                                                   dtype='float32'),\n",
    "#                              trainable=True)\n",
    "        \n",
    "#     def call(self, inputs):\n",
    "#         encodings = tf.matmul(inputs, self.w) + self.b\n",
    "#         return decode_batch(encodings)\n",
    "    \n",
    "# #     def compute_output_shape(self, *args, **kwargs):\n",
    "# #         return (1, 128, 128, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down_model = downsample(3, 4)\n",
    "# down_result = down_model(tf.expand_dims(inp, 0))\n",
    "# print (down_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.layers.Dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    inputs = tf.keras.layers.Input(shape=[128,128,1], batch_size=1)\n",
    "\n",
    "    down_stack = [\n",
    "        downsample(64, 4, apply_batchnorm=False), # (bs, 64, 64, 64)\n",
    "        downsample(128, 4), # (bs, 32, 32, 128)\n",
    "        downsample(256, 4), # (bs, 16, 16, 256)\n",
    "        downsample(512, 4), # (bs, 8, 8, 512)\n",
    "        downsample(512, 4), # (bs, 4, 4, 512)\n",
    "        downsample(512, 4), # (bs, 2, 2, 512)\n",
    "        downsample(512, 4), # (bs, 1, 1, 512)\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        \n",
    "    dense = tf.keras.layers.Dense(5)\n",
    "    \n",
    "#     decode_to_mask = DecodeToMask()\n",
    "    x = dense(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "\n",
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_output = generator(sample_image, training=False)\n",
    "print(gen_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# loss_object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=[128, 128, 1], name='input_image')\n",
    "    tar = tf.keras.layers.Input(shape=[128, 128, 2], name='target_image')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n",
    "\n",
    "    down1 = downsample(128, 4, False)(x) # (bs, 64, 64, 128)\n",
    "    down2 = downsample(256, 4)(down1) # (bs, 32, 32, 256)\n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down2) # (bs, 34, 34, 256)\n",
    "    conv = tf.keras.layers.Conv2D(\n",
    "        512, 4, strides=1,\n",
    "        kernel_initializer=initializer,\n",
    "        use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(\n",
    "        1, 4, strides=1,\n",
    "        kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()\n",
    "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_out = discriminator([sample_image, decode_batch(gen_output)], training=False)\n",
    "plt.imshow(disc_out[0,...,-1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):    \n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image, mask, encoding in train_dataset.take(10):\n",
    "#     field_centre, field_rotation, bb_centre = extract_items_from_encoding(encoding)\n",
    "    \n",
    "#     fig, axs = pymedphys._wlutz.reporting.image_analysis_figure(\n",
    "#         x, y, np.array(image)[:,:,0],\n",
    "#         np.array(bb_centre), np.array(field_centre), np.array(field_rotation),\n",
    "#         bb_diameter, edge_lengths, penumbra, units=''\n",
    "#     )\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, image, ground_truth_encoding):\n",
    "    predicted_encoding = model(image, training=True)\n",
    "    \n",
    "    predicted_field_centre = [predicted_encoding[0, 0, 0, 0], predicted_encoding[0, 0, 0, 1]]\n",
    "    predicted_field_rotation = predicted_encoding[0, 0, 0, 2] * 90\n",
    "    predicted_bb_centre = [predicted_encoding[0, 0, 0, 3], predicted_encoding[0, 0, 0, 4]]\n",
    "    \n",
    "    ground_field_centre = [ground_truth_encoding[0], ground_truth_encoding[1]]\n",
    "    ground_field_rotation = ground_truth_encoding[2] * 90\n",
    "    ground_bb_centre = [ground_truth_encoding[3], ground_truth_encoding[4]]\n",
    "    \n",
    "    fig, axs = pymedphys._wlutz.reporting.image_analysis_figure(\n",
    "        x, y, np.array(image)[0,:,:,0],\n",
    "        np.array(ground_bb_centre), np.array(ground_field_centre), np.array(ground_field_rotation),\n",
    "        bb_diameter, edge_lengths, penumbra, units=''\n",
    "    )\n",
    "    axs[0,0].set_title(\"Ground Truth\")\n",
    "    \n",
    "    fig, axs = pymedphys._wlutz.reporting.image_analysis_figure(\n",
    "        x, y, np.array(image)[0,:,:,0],\n",
    "        np.array(predicted_bb_centre), np.array(predicted_field_centre), np.array(predicted_field_rotation),\n",
    "        bb_diameter, edge_lengths, penumbra, units=''\n",
    "    )\n",
    "    axs[0,0].set_title(\"Predicted\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask, encoding in test_dataset.take(1):\n",
    "    generate_images(generator, image, encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir=\"logs/\"\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(\n",
    "  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, target_mask, target_encoding, epoch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "        \n",
    "        gen_output_image = decode_batch(gen_output)\n",
    "\n",
    "        disc_real_output = discriminator([input_image, target_mask], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output_image], training=True)\n",
    "\n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target_encoding)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))\n",
    "\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n",
    "        tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
    "        tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n",
    "        tf.summary.scalar('disc_loss', disc_loss, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_ds, epochs, test_ds):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        IPython.display.clear_output(wait=True)\n",
    "\n",
    "        for example_input, example_target_image, example_target_encoding in test_ds.take(1):\n",
    "            generate_images(generator, example_input, example_target_encoding)\n",
    "        print(\"Epoch: \", epoch)\n",
    "\n",
    "        # Train\n",
    "        for n, (input_image, target_mask, target_encoding) in train_ds.enumerate():\n",
    "            print('.', end='')\n",
    "            if (n+1) % 100 == 0:\n",
    "                print()\n",
    "            train_step(input_image, target_mask, target_encoding, epoch)\n",
    "        print()\n",
    "\n",
    "        # saving (checkpoint) the model every 20 epochs\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                            time.time()-start))\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target):   \n",
    "    rotation_target = target[2]\n",
    "    rotation_predicted = gen_output[0,0,0,2]\n",
    "    \n",
    "    diff_rotation = (rotation_target - rotation_predicted) % 180\n",
    "    diff_rotation = tf.reduce_min([diff_rotation, 180 - diff_rotation])\n",
    "    reshaped_rotation_diff = tf.reshape(diff_rotation, (-1,))\n",
    "    \n",
    "    positions_target = tf.concat((target[0:2], target[3::]), axis=0)\n",
    "    positions_predicted = tf.concat((gen_output[0,0,0,0:2], gen_output[0,0,0,3::]), axis=-1)\n",
    "    \n",
    "    diff_positions = tf.abs(positions_target - positions_predicted)\n",
    "    diff = tf.concat([diff_positions, reshaped_rotation_diff], axis=0)\n",
    "    \n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    # mean absolute error\n",
    "    l1_loss = tf.reduce_mean(diff)\n",
    "\n",
    "    total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "    return total_gen_loss, gan_loss, l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 5\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(train_dataset, EPOCHS, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x = np.arange(0, IMG_SIZE)\n",
    "# y = np.arange(0, IMG_SIZE)\n",
    "\n",
    "# for image, mask, _ in train_dataset.take(1):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.arange(0, IMG_SIZE)\n",
    "# y = np.arange(0, IMG_SIZE)\n",
    "\n",
    "# for image, mask, encoding in train_dataset.take(10):\n",
    "#     field_centre, field_rotation, bb_centre = extract_items_from_encoding(encoding)\n",
    "    \n",
    "#     fig, axs = pymedphys._wlutz.reporting.image_analysis_figure(\n",
    "#         x, y, np.array(image)[:,:,0],\n",
    "#         np.array(bb_centre), np.array(field_centre), np.array(field_rotation),\n",
    "#         bb_diameter, edge_lengths, penumbra, units=''\n",
    "#     )\n",
    "\n",
    "#     plt.contour(x, y, mask[:,:,0], [0], cmap='bwr_r', zorder=20)\n",
    "#     plt.contour(x, y, mask[:,:,1], [0], cmap='bwr_r', zorder=20)\n",
    "    \n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymedphys-master",
   "language": "python",
   "name": "pymedphys-master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
