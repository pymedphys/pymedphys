{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import lzma\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes it so any changes in pymedphys is automatically\n",
    "# propagated into the notebook without needing a kernel reset.\n",
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymedphys._utilities.filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = '192.168.100.200'\n",
    "root = pathlib.Path(r'\\\\physics-server\\iComLogFiles')\n",
    "live_path = root.joinpath(f'live/{ip}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 20000\n",
    "date_pattern = re.compile(b'\\d\\d\\d\\d-\\d\\d-\\d\\d\\d\\d:\\d\\d:\\d\\d.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# def pull_header(tag, length, results_dict, results):\n",
    "#     index = np.where(results == tag)[0]\n",
    "\n",
    "#     for i, ref in enumerate(index):\n",
    "#         asymx = results[ref+1:ref+length+1]\n",
    "#         asymx = np.array(asymx).astype(float)\n",
    "#         asymx[(asymx == -32767) | (asymx == 32767)] = None\n",
    "#         results_dict[\"{}-{}\".format(tag, i)] = asymx\n",
    "\n",
    "#     for ref in index[-1::-1]:\n",
    "#         results = np.delete(results, np.arange(ref,ref+length+1))\n",
    "        \n",
    "#     return results_dict, results\n",
    "\n",
    "\n",
    "# def organise_by_tags(results):\n",
    "#     results_dict = dict()\n",
    "\n",
    "#     results_dict, results = pull_header('ASYMX', 2, results_dict, results)\n",
    "#     results_dict, results = pull_header('ASYMY', 2, results_dict, results)\n",
    "#     results_dict, results = pull_header('MLCX', 160, results_dict, results)\n",
    "\n",
    "#     pattern = re.compile('[a-zA-Z][a-zA-Z0-9 -]+')\n",
    "\n",
    "#     alpha_numeric = np.array([\n",
    "#         pattern.match(value)\n",
    "#         for value in results\n",
    "#     ]).astype(bool)\n",
    "#     results_dict[\"Text Tags\"] = results[alpha_numeric].tolist()\n",
    "#     results = np.delete(results, np.where(alpha_numeric)[0])\n",
    "\n",
    "#     left_overs = results.astype(str)\n",
    "#     left_overs[(left_overs == '-32767') | (left_overs == '32767')] = None\n",
    "    \n",
    "#     left_overs = left_overs.tolist()\n",
    "    \n",
    "#     results_dict[\"Patient ID\"] = left_overs.pop(0)\n",
    "#     results_dict[\"Segment\"] = left_overs.pop(0)\n",
    "#     assert results_dict[\"Segment\"] == left_overs.pop(0)\n",
    "#     assert results_dict[\"Segment\"] == left_overs.pop(0)\n",
    "#     results_dict[\"Monitor Units\"] = left_overs.pop(0)\n",
    "\n",
    "#     results_dict[\"Left Overs\"] = left_overs\n",
    "    \n",
    "#     return results_dict\n",
    "\n",
    "\n",
    "# def convert(data_point):\n",
    "#     results = initial_results_parse(data_point)\n",
    "#     results_dict = organise_by_tags(results)\n",
    "    \n",
    "#     return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update(data=None):\n",
    "#     if data is None:\n",
    "#         with pymedphys._utilities.filesystem.open_no_lock(live_path, 'rb') as f:\n",
    "#             f.seek(0, os.SEEK_END)\n",
    "#             file_size = f.tell()\n",
    "#             f.seek(file_size - offset)\n",
    "#             data = f.read()\n",
    "        \n",
    "#     date_index = [m.span() for m in pattern.finditer(data)]\n",
    "#     start_points = [\n",
    "#         span[0] - 8 for span in date_index\n",
    "#     ]\n",
    "\n",
    "#     end_points = start_points[1::] + [None]\n",
    "\n",
    "#     data_points = [data[start:end] for start, end in zip(start_points, end_points)]\n",
    "    \n",
    "#     return convert(data_points[-1])\n",
    "\n",
    "\n",
    "# update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_recent_data_point():\n",
    "    with pymedphys._utilities.filesystem.open_no_lock(live_path, 'rb') as f:\n",
    "        f.seek(0, os.SEEK_END)\n",
    "        file_size = f.tell()\n",
    "        f.seek(file_size - offset)\n",
    "        data = f.read()\n",
    "        \n",
    "    date_index = [m.span() for m in date_pattern.finditer(data)]\n",
    "    start_points = [\n",
    "        span[0] - 8 for span in date_index\n",
    "    ]\n",
    "\n",
    "    end_points = start_points[1::] + [None]\n",
    "\n",
    "    data_points = [data[start:end] for start, end in zip(start_points, end_points)]\n",
    "    return data_points[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = get_most_recent_data_point()\n",
    "# new_lines = data.split(b'\\n')\n",
    "# new_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_positions_by_header(key, num_items, results_by_line):\n",
    "    header_index = results_by_line.index([key])\n",
    "    return [float(item[0]) for item in results_by_line[header_index + 1:header_index + 1 + num_items]]\n",
    "\n",
    "\n",
    "def get_jaw_and_mlc(results_by_line):\n",
    "    options = [\n",
    "        (b'ASYMX', 2), (b'ASYMY', 2), (b'MLCX', 160)\n",
    "    ]\n",
    "    collimation = {}\n",
    "    for key, num_items in options:\n",
    "        collimation[key] = extract_positions_by_header(key, num_items, results_by_line)\n",
    "        \n",
    "    return collimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pattern = re.compile(b'\\x00\\x00\\x00([a-zA-Z0-9 \\.-]+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0\\xb8\\x00DS\\x00R\\x04\\x00\\x00\\x00MLCX\n",
    "# \\n0\\x1c\\x01DS\\x00R\\x06\\x00\\x00\\x00-10.00\\n0\\x1c\\x01DS\\x00R\\x06\\x00\\x00\\x00-10.00\\n0\\x1\n",
    "\n",
    "def extract_coll(data, label, number):\n",
    "    header = b'0\\xb8\\x00DS\\x00R[\\x03\\x04\\x05\\x06]\\x00\\x00\\x00' + label + b'\\n'\n",
    "    item = b'0\\x1c\\x01DS\\x00R[\\x03\\x04\\x05\\x06]\\x00\\x00\\x00(-?\\d+\\.\\d+)'\n",
    "\n",
    "    regex = re.compile(header + b'\\n'.join([item,]*number))\n",
    "\n",
    "    match = regex.search(data)\n",
    "    span = match.span()\n",
    "\n",
    "    data = data[0:span[0]] + data[span[1]+1::]\n",
    "    items = np.array([float(item) for item in match.groups()])\n",
    "    \n",
    "    return data, items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_data = copy.copy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0\\x07\\x10DS\\x00P\\x01\\x00\\x00\\x001\\x010\\x07\\x10DS\\x00S\\x01\\x00\\x00\\x001\\x010\\x07\\x10DS\\x00R\\x01\\x00\\x00\\x001\\x010\\t\n",
    "\n",
    "\n",
    "def extract_by_lookup(data, key):\n",
    "    regex = re.compile(b'[0\\x00pP]' + key + b'\\x00[PSR][\\x01\\x02\\x03\\x04\\x05\\x06]\\x00\\x00\\x00([a-zA-Z0-9 \\.-]+)')\n",
    "    match = regex.search(data)\n",
    "\n",
    "    span = match.span()\n",
    "    removed_data = data[0:span[0]] + data[span[1]+1::]\n",
    "    \n",
    "    return removed_data, match.group(1)\n",
    "\n",
    "def extract_all_lookup(data, result):\n",
    "    for key, label in lookup.items():\n",
    "        try:\n",
    "            data, result[label] = extract_by_lookup(data, key)\n",
    "        except AttributeError:\n",
    "            result[label] = None\n",
    "        \n",
    "    return data\n",
    "\n",
    "def run_all_assertions(data, result):\n",
    "    for key, label in assert_equal.items():\n",
    "        try:\n",
    "            while True:\n",
    "                data, new_result = extract_by_lookup(data, key)\n",
    "                if result[label] != new_result:\n",
    "                    raise ValueError(f\"Expected these to be the same:\\n{label}\\n{result[label]}\\n{new_result}\")\n",
    "        except AttributeError:\n",
    "            pass  \n",
    "        \n",
    "    return data\n",
    "        \n",
    "\n",
    "def strict_extract(data):\n",
    "    result = dict()\n",
    "    \n",
    "    data = extract_all_lookup(data, result)\n",
    "    \n",
    "    data, result['mlc'] = extract_coll(data, b'MLCX', 160)\n",
    "    data, result['jaw_x'] = extract_coll(data, b'ASYMX', 2)\n",
    "    data, result['jaw_y'] = extract_coll(data, b'ASYMY', 2)\n",
    "    \n",
    "    data = run_all_assertions(data, result)\n",
    "    \n",
    "    return data, result\n",
    "\n",
    "lookup = {\n",
    "    b' \\x00LO': 'Patient ID',\n",
    "    b'\\xb2\\x00SH': 'Machine ID',\n",
    "    b'\\xc6\\x00CS': 'Radiation Type',\n",
    "    b'\\x14\\x01SH': 'Energy',\n",
    "    b'\\x18\\x01CS': 'Wedge',\n",
    "    b'\\x07\\x10DS': 'Segment',\n",
    "    b'\\t\\x10DS': 'Total MU',\n",
    "    b'2\\x00DS': 'Delivery MU',\n",
    "    b'3\\x00DS': 'Backup Delivery MU',\n",
    "    b'8\\x00SH': 'Beam Timer',\n",
    "    b'\\x0b\\x00DS': 'Segment MU',\n",
    "    b'\\x1e\\x01DS': 'Gantry',\n",
    "    b' \\x01DS': 'Collimator',\n",
    "    b'\\\"\\x01DS' : 'Table Column',\n",
    "    b'\\%\\x01DS' : 'Table Isocentric',\n",
    "    b'\\(\\x01DS' : 'Table Vertical',\n",
    "    b'\\)\\x01DS' : 'Table Longitudinal',\n",
    "    b'\\*\\x01DS' : 'Table Lateral',\n",
    "}\n",
    "\n",
    "assert_equal = {\n",
    "    b'\\x07\\x10DS': 'Segment',\n",
    "    b'\\x06\\x10LO': 'Machine ID',\n",
    "}\n",
    "\n",
    "data = get_most_recent_data_point()\n",
    "shrunk_data, result = strict_extract(data)\n",
    "\n",
    "print(result)\n",
    "\n",
    "def initial_results_parse(data_point):\n",
    "    pattern = re.compile(b'(........\\x00\\x00\\x00[a-zA-Z0-9 \\.-]+)')\n",
    "\n",
    "    results = pattern.findall(data_point)\n",
    "    results = np.array(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "initial_results_parse(shrunk_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data = get_most_recent_data_point()\n",
    "# new_lines = data.split(b'\\n')\n",
    "# results_by_line = [item_pattern.findall(line) for line in new_lines]\n",
    "# results = dict()\n",
    "\n",
    "# results['Patient ID'] = results_by_line[0][0].decode()\n",
    "# results['Segment'] = int(results_by_line[0][1])\n",
    "# assert results['Segment'] == int(results_by_line[0][2])\n",
    "# assert results['Segment'] == int(results_by_line[0][3])\n",
    "# results['Delivery MU'] = float(results_by_line[0][4])\n",
    "# # assert results['Delivery MU'] == float(results_by_line[1][-2])\n",
    "# results['Backup Delivery MU'] = float(results_by_line[1][-1])\n",
    "# results['Dose Rate'] = float(results_by_line[1][-3])\n",
    "\n",
    "# results['Segment MU'] = float(results_by_line[-1][-1])\n",
    "# results['Beam Timer'] = float(results_by_line[-1][5])\n",
    "\n",
    "# results['Machine ID'] = results_by_line[2][0].decode()\n",
    "# results['Radiation Type'] = results_by_line[3][0].decode()\n",
    "# results['Energy'] = results_by_line[7][0].decode()\n",
    "# results['Wedge'] = results_by_line[9][0].decode()\n",
    "\n",
    "# results['Gantry'] = float(results_by_line[-8][0])\n",
    "# results['Collimator'] = float(results_by_line[-7][0])\n",
    "\n",
    "# results['Table Column'] = int(results_by_line[-6][0])\n",
    "# results['Table Isocentric'] = int(results_by_line[-5][0])\n",
    "\n",
    "# results['Table Vertical'] = float(results_by_line[-4][0])\n",
    "# results['Table Longitudinal'] = float(results_by_line[-3][0])\n",
    "# results['Table Lateral'] = float(results_by_line[-2][0])\n",
    "\n",
    "# collimation = get_jaw_and_mlc(results_by_line)\n",
    "\n",
    "# mlcs = collimation[b'MLCX']\n",
    "# mlc_a = mlcs[0::2]\n",
    "# mlc_b = mlcs[1::2]\n",
    "\n",
    "# results['MLC-A'] = mlc_a\n",
    "# results['MLC-B'] = mlc_b\n",
    "\n",
    "# results['JAW'] = collimation[b'ASYMY']\n",
    "\n",
    "\n",
    "\n",
    "# print(results.keys())\n",
    "\n",
    "# results_by_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_items = 2\n",
    "# header_index = results_by_line.index([b'ASYMX'])\n",
    "# [float(item[0]) for item in results_by_line[header_index + 1:header_index + 1 + num_items]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymedphys-master",
   "language": "python",
   "name": "pymedphys-master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
