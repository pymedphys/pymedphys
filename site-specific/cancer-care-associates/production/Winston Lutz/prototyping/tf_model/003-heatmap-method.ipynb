{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import IPython\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following may be helpful:\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/issues/6271#issuecomment-266893850\n",
    "https://arxiv.org/pdf/1807.03146.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes it so any changes in pymedphys is automatically\n",
    "# propagated into the notebook without needing a kernel reset.\n",
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SIZE = 1024\n",
    "PIXELS_PER_UNIT = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "\n",
    "def down_block(x, depth, num_convs, channels, pool):\n",
    "    convolution_sequence = tf.keras.Sequential(name=f'down-convolution-d{depth}')       \n",
    "    convolution_sequence.add(\n",
    "        tf.keras.layers.ReLU()\n",
    "    )\n",
    "    for i in range(num_convs):\n",
    "        convolution_sequence.add(\n",
    "            tf.keras.layers.Conv2D(\n",
    "                channels, (3, 3), strides=1, padding='same',\n",
    "                kernel_initializer=initializer, use_bias=True)\n",
    "        )\n",
    "        if i != num_convs - 1:\n",
    "            convolution_sequence.add(\n",
    "                tf.keras.layers.ReLU()\n",
    "            )\n",
    "    \n",
    "    short_circuit_sequence = tf.keras.Sequential(name=f'down-short-circuit-d{depth}')\n",
    "    short_circuit_sequence.add(\n",
    "        tf.keras.layers.Conv2D(\n",
    "            channels, (1, 1), strides=1, padding='same',\n",
    "            kernel_initializer=tf.ones_initializer(), \n",
    "            use_bias=True, trainable=False)\n",
    "    )\n",
    "    \n",
    "    x = tf.keras.layers.Add()(\n",
    "        [convolution_sequence(x), short_circuit_sequence(x)]\n",
    "    )\n",
    "    \n",
    "    unet_short_circuit = x\n",
    "    \n",
    "    if pool != 0:\n",
    "        x = tf.keras.layers.AveragePooling2D((pool, pool), strides=None, padding='valid')(x)\n",
    "        \n",
    "    return x, unet_short_circuit\n",
    "    \n",
    "    \n",
    "def fully_connected_block(x, input_size, internal_channels, output_channels):\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "            internal_channels, \n",
    "            (input_size, input_size),\n",
    "            strides=1,\n",
    "            padding='valid',\n",
    "            kernel_initializer=initializer,\n",
    "            use_bias=True\n",
    "    )(x)\n",
    "    \n",
    "    repeats = 2\n",
    "    for _ in range(repeats):\n",
    "        short_circuit = x\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.Dense(internal_channels)(x)\n",
    "        x = tf.keras.layers.Add()([x, short_circuit])\n",
    "    \n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Dense(input_size * input_size * output_channels)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Reshape((input_size, input_size, output_channels))(x)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "\n",
    "def up_block(x, unet_short_circuit, depth, num_convs, channels, up_scale):\n",
    "    if up_scale != 0:\n",
    "        x = tf.keras.layers.UpSampling2D(size=(up_scale, up_scale))(x)\n",
    "        \n",
    "    x = tf.keras.layers.Add()([x, unet_short_circuit])\n",
    "    \n",
    "    convolution_sequence = tf.keras.Sequential(name=f'up-convolution-d{depth}')\n",
    "    convolution_sequence.add(\n",
    "        tf.keras.layers.ReLU()\n",
    "    )\n",
    "    for i in range(num_convs):\n",
    "        convolution_sequence.add(\n",
    "            tf.keras.layers.Conv2D(\n",
    "                channels, (3, 3), strides=1, padding='same',\n",
    "                kernel_initializer=initializer, use_bias=True)\n",
    "        )\n",
    "        if i != num_convs - 1:\n",
    "            convolution_sequence.add(\n",
    "                tf.keras.layers.ReLU()\n",
    "            )\n",
    "    \n",
    "    \n",
    "    internal_short_circuit = tf.keras.Sequential(name=f'up-short-circuit-d{depth}')\n",
    "    internal_short_circuit.add(\n",
    "        tf.keras.layers.Conv2D(\n",
    "            channels, (1, 1), strides=1, padding='same',\n",
    "            kernel_initializer=tf.ones_initializer(), \n",
    "            use_bias=True, trainable=False)\n",
    "    )\n",
    "    \n",
    "    x = tf.keras.layers.Add()(\n",
    "        [convolution_sequence(x), internal_short_circuit(x)]\n",
    "    )\n",
    "    \n",
    "    return x\n",
    "    \n",
    "    \n",
    "def Model(grid_size=GRID_SIZE):\n",
    "    down_block_params = [\n",
    "        (0, (3, 12, 2)),  # BS, 1024, 1024,  3 --> BS, 512, 512, 12\n",
    "        (1, (3, 12, 4)),  # BS,  512,  512, 12 --> BS, 128, 128, 12\n",
    "        (2, (3, 12, 4)),  # BS,  128,  128, 12 --> BS,  32,  32, 12\n",
    "        (3, (3, 12, 4)),  # BS,   32,   32, 12 --> BS,   8,   8, 12\n",
    "        (4, (4, 24, 0)),  # BS,    8,    8, 12 --> BS,   8,   8, 24\n",
    "    ]\n",
    "    fully_connected_params = (8, 96, 24)\n",
    "    up_block_params = [\n",
    "        (4, (4, 12, 0)),  \n",
    "        (3, (4, 12, 4)),  \n",
    "        (2, (3, 12, 4)), \n",
    "        (1, (3, 12, 4)), \n",
    "        (0, (3,  2, 2)), \n",
    "    ]\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=[grid_size,grid_size,1], batch_size=None)\n",
    "    x = inputs\n",
    "\n",
    "    unet_short_circuits = []\n",
    "    for depth, down_block_param in down_block_params:\n",
    "        x, unet_short_circuit = down_block(x, depth, *down_block_param)\n",
    "        unet_short_circuits.append(unet_short_circuit)\n",
    "        \n",
    "    x = fully_connected_block(x, *fully_connected_params)\n",
    "    \n",
    "    unet_short_circuits = reversed(unet_short_circuits)\n",
    "    \n",
    "    for unet_shot_circuit, (depth, up_block_param) in zip(unet_short_circuits, up_block_params):\n",
    "        x = up_block(x, unet_shot_circuit, depth, *up_block_param)\n",
    "    \n",
    "        \n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "\n",
    "model = Model()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymedphys._mocks import wlutz, profiles\n",
    "from pymedphys._wlutz import reporting, interppoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian(x_pos, y_pos, sigma):\n",
    "    variance = sigma**2\n",
    "    norm = 1 / (2*np.pi*variance)\n",
    "    def gaussian(x, y):\n",
    "        return norm * np.exp(-((x - x_pos)**2 + (y - y_pos)**2)/(2*variance))\n",
    "\n",
    "    return gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_dataset(grid_size, pixels_per_unit, include_params=True):\n",
    "    bounding_pixel_centre_val = (grid_size / 2 - 0.5) / pixels_per_unit   \n",
    "\n",
    "    field_centre = np.random.uniform(-60, 60, size=2)\n",
    "    field_side_lengths = np.exp(np.random.uniform(np.log(15), np.log(150), size=2))\n",
    "    field_penumbra = np.random.uniform(1, 5)\n",
    "\n",
    "    field_rotation = np.random.uniform(-180, 180)\n",
    "\n",
    "    transform = interppoints.translate_and_rotate_transform(field_centre, field_rotation)\n",
    "    \n",
    "    field_corners_before_transform = [\n",
    "        (-field_side_lengths[0]/2, -field_side_lengths[0]/2, field_side_lengths[0]/2, field_side_lengths[0]/2),\n",
    "        (-field_side_lengths[1]/2, field_side_lengths[1]/2, -field_side_lengths[1]/2, field_side_lengths[1]/2),\n",
    "    ]\n",
    "\n",
    "    bb_centre_before_transform = [\n",
    "        np.random.uniform(\n",
    "            -field_side_lengths[0]/2, field_side_lengths[0]/2),\n",
    "        np.random.uniform(\n",
    "            -field_side_lengths[1]/2, field_side_lengths[1]/2)\n",
    "    ]\n",
    "    bb_centre = interppoints.apply_transform(*bb_centre_before_transform, transform)\n",
    "    field_corners = np.array(interppoints.apply_transform(*field_corners_before_transform, transform))\n",
    "\n",
    "    bb_diameter = tf.random.uniform((), 0.5, 10).numpy()\n",
    "    bb_max_attenuation = tf.random.uniform((), 0.1, 0.5).numpy()\n",
    "\n",
    "\n",
    "    field = profiles.create_rectangular_field_function(\n",
    "        field_centre, field_side_lengths, field_penumbra, field_rotation\n",
    "    )\n",
    "    bb_penumbra = field_penumbra / 3\n",
    "    bb_attenuation_map = wlutz.create_bb_attenuation_func(\n",
    "        bb_diameter, bb_penumbra, bb_max_attenuation\n",
    "    )\n",
    "\n",
    "    x = np.linspace(\n",
    "        -bounding_pixel_centre_val,\n",
    "        bounding_pixel_centre_val,\n",
    "        grid_size\n",
    "    )\n",
    "    xx, yy = np.meshgrid(x, x)\n",
    "\n",
    "    without_bb = field(xx, yy)\n",
    "\n",
    "    def field_with_bb(x, y):\n",
    "        return field(x, y) * bb_attenuation_map(x - bb_centre[0], y - bb_centre[1])\n",
    "\n",
    "    img = field_with_bb(xx, yy)    \n",
    "    parameters = tf.concat([field_centre, field_side_lengths, [field_rotation], bb_centre, [bb_diameter]], 0)\n",
    "    \n",
    "    xx = tf.convert_to_tensor(xx, dtype=tf.float32)\n",
    "    yy = tf.convert_to_tensor(yy, dtype=tf.float32)\n",
    "    img = tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "    \n",
    "    model_input = tf.stack([xx, yy, img], axis=-1)\n",
    "    \n",
    "    sigma = 1.5 / PIXELS_PER_UNIT\n",
    "    bb_heatmap = tf.convert_to_tensor(create_gaussian(*bb_centre, sigma)(xx, yy), dtype=tf.float32)\n",
    "    \n",
    "    field_corner_heatmap = np.zeros_like(bb_heatmap)\n",
    "    for field_corner in field_corners.T:\n",
    "        field_corner_heatmap += create_gaussian(*field_corner, sigma)(xx, yy)\n",
    "        \n",
    "    field_corner_heatmap = tf.convert_to_tensor(field_corner_heatmap, dtype=tf.float32)\n",
    "    \n",
    "    model_output = tf.stack([bb_heatmap, field_corner_heatmap], axis=-1)\n",
    "    \n",
    "    if include_params:\n",
    "        return model_input, model_output, parameters\n",
    "    \n",
    "    return model_input[:,:,2::], model_output\n",
    "\n",
    "\n",
    "model_input, model_output, parameters = create_single_dataset(GRID_SIZE, PIXELS_PER_UNIT)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.contourf(model_input[:,:,0], model_input[:,:,1], model_input[:,:,2], 100)\n",
    "plt.contourf(model_input[:,:,0], model_input[:,:,1], model_output[:,:,0], levels=np.linspace(0.5,1.2,100), cmap='magma')\n",
    "plt.contourf(model_input[:,:,0], model_input[:,:,1], model_output[:,:,1], levels=np.linspace(0.5,1.2,100), cmap='cividis')\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_dataset(batch_size, grid_size=GRID_SIZE, pixels_per_unit=PIXELS_PER_UNIT, include_params=True):\n",
    "    def dataset_generator():\n",
    "        yield create_single_dataset(grid_size, pixels_per_unit, include_params=include_params)\n",
    "        \n",
    "    if include_params:\n",
    "        generator_params = (\n",
    "            (tf.float32, tf.float32, tf.float32), \n",
    "            (tf.TensorShape([grid_size, grid_size, 3]), tf.TensorShape([grid_size, grid_size, 2]), tf.TensorShape([8]))\n",
    "        )\n",
    "    else:\n",
    "        generator_params = (\n",
    "            (tf.float32, tf.float32), \n",
    "            (tf.TensorShape([grid_size, grid_size, 1]), tf.TensorShape([grid_size, grid_size, 2]))\n",
    "        )\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        dataset_generator, *generator_params\n",
    "    )\n",
    "\n",
    "    dataset = dataset.repeat().batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw_images(model_input, model_output):\n",
    "    dim = model_input.shape\n",
    "    for i in range(dim[0]):        \n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.contourf(model_input[i,:,:,0], model_input[i,:,:,1], model_input[i,:,:,2], 100)\n",
    "        plt.contourf(\n",
    "            model_input[i,:,:,0], model_input[i,:,:,1], model_output[i,:,:,0], \n",
    "            levels=np.linspace(np.mean(model_output[i,:,:,0]),np.max(model_output[i,:,:,0]), 20), \n",
    "            cmap='magma',\n",
    "            alpha=0.3,\n",
    "            linestyles=None,\n",
    "        )\n",
    "        plt.contourf(\n",
    "            model_input[i,:,:,0], model_input[i,:,:,1], model_output[i,:,:,1], \n",
    "            levels=np.linspace(np.mean(model_output[i,:,:,1]),np.max(model_output[i,:,:,1]), 20),\n",
    "            cmap='cividis',\n",
    "            alpha=0.3,\n",
    "            linestyles=None,\n",
    "        )\n",
    "        plt.axis('equal')\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for model_input, model_output, parameters in create_pipeline_dataset(1).take(2):\n",
    "    plot_raw_images(model_input, model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parameters(parameters):\n",
    "    parameters = {\n",
    "        'field_centre': (parameters[0], parameters[1]),\n",
    "        'field_side_lengths': (parameters[2], parameters[3]),\n",
    "        'field_rotation': parameters[4],\n",
    "        'bb_centre': (parameters[5], parameters[6]),\n",
    "        'bb_diameter': parameters[7]\n",
    "    }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_figure(image, field_centre, field_side_lengths, field_rotation, bb_centre, bb_diameter):\n",
    "    dim = image.shape\n",
    "    \n",
    "    return reporting.image_analysis_figure(\n",
    "        np.array(image[0,:,0]), np.array(image[:,0,1]), np.array(image[:,:,2]),\n",
    "        np.array(bb_centre), np.array(field_centre), np.array(field_rotation),\n",
    "        bb_diameter, field_side_lengths, penumbra=0.03, units=''\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_figures(model, batch_model_inputs, batch_model_outputs, batch_parameters, predicted):\n",
    "    batch_dim = batch_model_inputs.shape\n",
    "    num_batches = batch_dim[0]\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        parameters = extract_parameters(batch_parameters[i, :])\n",
    "        \n",
    "        ground_truth_bb_centre = (\n",
    "            np.sum(model_input[i,:,:,0] * batch_model_outputs[i,:,:,0]) / np.sum(batch_model_outputs[i,:,:,0]),\n",
    "            np.sum(model_input[i,:,:,1] * batch_model_outputs[i,:,:,0]) / np.sum(batch_model_outputs[i,:,:,0]),            \n",
    "        )\n",
    "        \n",
    "        ground_truth_field_centre = (\n",
    "            np.sum(model_input[i,:,:,0] * batch_model_outputs[i,:,:,1]) / np.sum(batch_model_outputs[i,:,:,1]),\n",
    "            np.sum(model_input[i,:,:,1] * batch_model_outputs[i,:,:,1]) / np.sum(batch_model_outputs[i,:,:,1]),\n",
    "        )\n",
    "        \n",
    "        ground_truth_parameters = {\n",
    "            **parameters,\n",
    "            'bb_centre': ground_truth_bb_centre,\n",
    "            'field_centre': ground_truth_field_centre\n",
    "        }\n",
    "        \n",
    "        predicted_bb_centre = (\n",
    "            np.sum(model_input[i,:,:,0] * predicted[i,:,:,0]) / np.sum(predicted[i,:,:,0]),\n",
    "            np.sum(model_input[i,:,:,1] * predicted[i,:,:,0]) / np.sum(predicted[i,:,:,0]),   \n",
    "        )\n",
    "        \n",
    "        predicted_field_centre = (\n",
    "            np.sum(model_input[i,:,:,0] * predicted[i,:,:,1]) / np.sum(predicted[i,:,:,1]),\n",
    "            np.sum(model_input[i,:,:,1] * predicted[i,:,:,1]) / np.sum(predicted[i,:,:,1]),\n",
    "        )\n",
    "        \n",
    "        predicted_parameters = {\n",
    "            **parameters,\n",
    "            'bb_centre': predicted_bb_centre,\n",
    "            'field_centre': predicted_field_centre\n",
    "        }\n",
    "    \n",
    "        fig, axs = create_figure(batch_model_inputs[i,:,:,:], **ground_truth_parameters)\n",
    "        axs[0,0].set_title(\"Ground Truth\")\n",
    "\n",
    "        fig, axs = create_figure(batch_model_inputs[i,:,:,:], **predicted_parameters)\n",
    "        axs[0,0].set_title(\"Predicted\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions():\n",
    "    for model_input, model_output, parameters in create_pipeline_dataset(1).take(1): \n",
    "        predicted = model(model_input[:,:,:,2::], training=True)\n",
    "        \n",
    "        plot_raw_images(model_input, predicted)\n",
    "        results_figures(model, model_input, model_output, parameters, predicted)\n",
    "        \n",
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# checkpoint_dir = './training_checkpoints'\n",
    "# checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "# checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "#                                  model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        IPython.display.clear_output(wait=True)\n",
    "        show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "poetry run tensorboard --logdir examples/site-specific/cancer-care-associates/production/Winston\\ Lutz/prototyping/tf_model/logs/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "EPOCHS = 10000\n",
    "STEPS_PER_EPOCH = 2\n",
    "VALIDATION_STEPS = 1\n",
    "\n",
    "test_dataset = create_pipeline_dataset(1, include_params=False)\n",
    "train_dataset = create_pipeline_dataset(BATCH_SIZE, include_params=False)\n",
    "\n",
    "\n",
    "model_history = model.fit(\n",
    "    train_dataset, epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    validation_data=test_dataset,\n",
    "    callbacks=[DisplayCallback(), tensorboard_callback],\n",
    "    use_multiprocessing=True,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymedphys-master",
   "language": "python",
   "name": "pymedphys-master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
