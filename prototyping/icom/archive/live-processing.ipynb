{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import lzma\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes it so any changes in pymedphys is automatically\n",
    "# propagated into the notebook without needing a kernel reset.\n",
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymedphys._utilities.filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = '192.168.100.200'\n",
    "root = pathlib.Path(r'\\\\physics-server\\iComLogFiles')\n",
    "live_path = root.joinpath(f'live/{ip}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 20000\n",
    "date_pattern = re.compile(b'\\d\\d\\d\\d-\\d\\d-\\d\\d\\d\\d:\\d\\d:\\d\\d.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_results_parse(data_point):\n",
    "    pattern = re.compile(b'\\x00\\x00\\x00([a-zA-Z0-9 \\.-]+)')\n",
    "\n",
    "    results = pattern.findall(data_point)\n",
    "    results = np.array(results).astype(str)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def pull_header(tag, length, results_dict, results):\n",
    "    index = np.where(results == tag)[0]\n",
    "\n",
    "    for i, ref in enumerate(index):\n",
    "        asymx = results[ref+1:ref+length+1]\n",
    "        asymx = np.array(asymx).astype(float)\n",
    "        asymx[(asymx == -32767) | (asymx == 32767)] = None\n",
    "        results_dict[\"{}-{}\".format(tag, i)] = asymx\n",
    "\n",
    "    for ref in index[-1::-1]:\n",
    "        results = np.delete(results, np.arange(ref,ref+length+1))\n",
    "        \n",
    "    return results_dict, results\n",
    "\n",
    "\n",
    "def organise_by_tags(results):\n",
    "    results_dict = dict()\n",
    "\n",
    "    results_dict, results = pull_header('ASYMX', 2, results_dict, results)\n",
    "    results_dict, results = pull_header('ASYMY', 2, results_dict, results)\n",
    "    results_dict, results = pull_header('MLCX', 160, results_dict, results)\n",
    "\n",
    "    pattern = re.compile('[a-zA-Z][a-zA-Z0-9 -]+')\n",
    "\n",
    "    alpha_numeric = np.array([\n",
    "        pattern.match(value)\n",
    "        for value in results\n",
    "    ]).astype(bool)\n",
    "    results_dict[\"Text Tags\"] = results[alpha_numeric].tolist()\n",
    "    results = np.delete(results, np.where(alpha_numeric)[0])\n",
    "\n",
    "    left_overs = results.astype(str)\n",
    "    left_overs[(left_overs == '-32767') | (left_overs == '32767')] = None\n",
    "    \n",
    "    left_overs = left_overs.tolist()\n",
    "    \n",
    "    results_dict[\"Patient ID\"] = left_overs.pop(0)\n",
    "    results_dict[\"Segment\"] = left_overs.pop(0)\n",
    "    assert results_dict[\"Segment\"] == left_overs.pop(0)\n",
    "    assert results_dict[\"Segment\"] == left_overs.pop(0)\n",
    "    results_dict[\"Monitor Units\"] = left_overs.pop(0)\n",
    "\n",
    "    results_dict[\"Left Overs\"] = left_overs\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "\n",
    "def convert(data_point):\n",
    "    results = initial_results_parse(data_point)\n",
    "    results_dict = organise_by_tags(results)\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(data=None):\n",
    "    if data is None:\n",
    "        with pymedphys._utilities.filesystem.open_no_lock(live_path, 'rb') as f:\n",
    "            f.seek(0, os.SEEK_END)\n",
    "            file_size = f.tell()\n",
    "            f.seek(file_size - offset)\n",
    "            data = f.read()\n",
    "        \n",
    "    date_index = [m.span() for m in pattern.finditer(data)]\n",
    "    start_points = [\n",
    "        span[0] - 8 for span in date_index\n",
    "    ]\n",
    "\n",
    "    end_points = start_points[1::] + [None]\n",
    "\n",
    "    data_points = [data[start:end] for start, end in zip(start_points, end_points)]\n",
    "    \n",
    "    return convert(data_points[-1])\n",
    "\n",
    "\n",
    "update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_recent_data_point():\n",
    "    with pymedphys._utilities.filesystem.open_no_lock(live_path, 'rb') as f:\n",
    "        f.seek(0, os.SEEK_END)\n",
    "        file_size = f.tell()\n",
    "        f.seek(file_size - offset)\n",
    "        data = f.read()\n",
    "        \n",
    "    date_index = [m.span() for m in date_pattern.finditer(data)]\n",
    "    start_points = [\n",
    "        span[0] - 8 for span in date_index\n",
    "    ]\n",
    "\n",
    "    end_points = start_points[1::] + [None]\n",
    "\n",
    "    data_points = [data[start:end] for start, end in zip(start_points, end_points)]\n",
    "    return data_points[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = get_most_recent_data_point()\n",
    "# new_lines = data.split(b'\\n')\n",
    "# new_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_positions_by_header(key, num_items, results_by_line):\n",
    "    header_index = results_by_line.index([key])\n",
    "    return [float(item[0]) for item in results_by_line[header_index + 1:header_index + 1 + num_items]]\n",
    "\n",
    "\n",
    "def get_jaw_and_mlc(results_by_line):\n",
    "    options = [\n",
    "        (b'ASYMX', 2), (b'ASYMY', 2), (b'MLCX', 160)\n",
    "    ]\n",
    "    collimation = {}\n",
    "    for key, num_items in options:\n",
    "        collimation[key] = extract_positions_by_header(key, num_items, results_by_line)\n",
    "        \n",
    "    return collimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pattern = re.compile(b'\\x00\\x00\\x00([a-zA-Z0-9 \\.-]+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlc_header = b'0\\xb8\\x00DS\\x00R\\x04\\x00\\x00\\x00MLCX\\n'\n",
    "mlc_item = b'0\\x1c\\x01DS\\x00R[\\x05\\x04]\\x00\\x00\\x00(-?\\d+\\.\\d+)'\n",
    "\n",
    "mlc_regex = re.compile(mlc_header + b'\\n'.join([mlc_item,]*160))\n",
    "\n",
    "mlc_match = mlc_regex.search(data)\n",
    "mlc_span = mlc_match.span()\n",
    "\n",
    "mlc_removed_data = data[0:mlc_span[0]] + data[mlc_span[1]+1::]\n",
    "# mlc_removed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlc_data = [float(item) for item in mlc_match.groups()]\n",
    "# mlc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaw_x_header = b'0\\xb8\\x00DS\\x00R\\x05\\x00\\x00\\x00ASYMX\\n'\n",
    "jaw_x_item = b'0\\x1c\\x01DS\\x00R[\\x05\\x04]\\x00\\x00\\x00(-?\\d+\\.\\d+)'\n",
    "\n",
    "jaw_x_regex = re.compile(jaw_x_header + b'\\n'.join([jaw_x_item,]*2))\n",
    "\n",
    "jaw_x_match = jaw_x_regex.search(mlc_removed_data)\n",
    "jaw_x_span = jaw_x_match.span()\n",
    "\n",
    "jaw_x_removed_data = mlc_removed_data[0:jaw_x_span[0]] + mlc_removed_data[jaw_x_span[1]+1::]\n",
    "\n",
    "jaw_x_data = [float(item) for item in jaw_x_match.groups()]\n",
    "jaw_x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaw_y_header = b'0\\xb8\\x00DS\\x00R\\x05\\x00\\x00\\x00ASYMY\\n'\n",
    "jaw_y_item = b'0\\x1c\\x01DS\\x00R[\\x05\\x04]\\x00\\x00\\x00(-?\\d+\\.\\d+)'\n",
    "\n",
    "jaw_y_regex = re.compile(jaw_y_header + b'\\n'.join([jaw_y_item,]*2))\n",
    "\n",
    "jaw_y_match = jaw_y_regex.search(jaw_x_removed_data)\n",
    "jaw_y_span = jaw_y_match.span()\n",
    "\n",
    "jaw_y_removed_data = jaw_x_removed_data[0:jaw_y_span[0]] + jaw_x_removed_data[jaw_y_span[1]+1::]\n",
    "\n",
    "jaw_y_data = [float(item) for item in jaw_y_match.groups()]\n",
    "jaw_y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaw_y_removed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_id_regex = re.compile(b'0\\xb2\\x00SH\\x00P\\x04\\x00\\x00\\x00(\\d+)\\n')\n",
    "machine_id_match = machine_id_regex.search(jaw_y_removed_data)\n",
    "machine_id_span = machine_id_match.span()\n",
    "machine_id_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_id = int(machine_id_match.group(1))\n",
    "machine_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_data = jaw_y_removed_data[0:machine_id_span[0]]\n",
    "footer_data = jaw_y_removed_data[machine_id_span[0]::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_most_recent_data_point()\n",
    "new_lines = data.split(b'\\n')\n",
    "results_by_line = [item_pattern.findall(line) for line in new_lines]\n",
    "results = dict()\n",
    "\n",
    "results['Patient ID'] = results_by_line[0][0].decode()\n",
    "results['Segment'] = int(results_by_line[0][1])\n",
    "assert results['Segment'] == int(results_by_line[0][2])\n",
    "assert results['Segment'] == int(results_by_line[0][3])\n",
    "results['Delivery MU'] = float(results_by_line[0][4])\n",
    "# assert results['Delivery MU'] == float(results_by_line[1][-2])\n",
    "results['Backup Delivery MU'] = float(results_by_line[1][-1])\n",
    "results['Dose Rate'] = float(results_by_line[1][-3])\n",
    "\n",
    "results['Segment MU'] = float(results_by_line[-1][-1])\n",
    "results['Beam Timer'] = float(results_by_line[-1][5])\n",
    "\n",
    "results['Machine ID'] = results_by_line[2][0].decode()\n",
    "results['Radiation Type'] = results_by_line[3][0].decode()\n",
    "results['Energy'] = results_by_line[7][0].decode()\n",
    "results['Wedge'] = results_by_line[9][0].decode()\n",
    "\n",
    "results['Gantry'] = float(results_by_line[-8][0])\n",
    "results['Collimator'] = float(results_by_line[-7][0])\n",
    "\n",
    "results['Table Column'] = int(results_by_line[-6][0])\n",
    "results['Table Isocentric'] = int(results_by_line[-5][0])\n",
    "\n",
    "results['Table Vertical'] = float(results_by_line[-4][0])\n",
    "results['Table Longitudinal'] = float(results_by_line[-3][0])\n",
    "results['Table Lateral'] = float(results_by_line[-2][0])\n",
    "\n",
    "collimation = get_jaw_and_mlc(results_by_line)\n",
    "\n",
    "mlcs = collimation[b'MLCX']\n",
    "mlc_a = mlcs[0::2]\n",
    "mlc_b = mlcs[1::2]\n",
    "\n",
    "results['MLC-A'] = mlc_a\n",
    "results['MLC-B'] = mlc_b\n",
    "\n",
    "results['JAW'] = collimation[b'ASYMY']\n",
    "\n",
    "\n",
    "\n",
    "print(results.keys())\n",
    "\n",
    "results_by_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = 2\n",
    "header_index = results_by_line.index([b'ASYMX'])\n",
    "[float(item[0]) for item in results_by_line[header_index + 1:header_index + 1 + num_items]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymedphys-master",
   "language": "python",
   "name": "pymedphys-master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
