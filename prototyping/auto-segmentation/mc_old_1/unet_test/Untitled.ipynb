{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load header\n",
    "# INPUT GENERATOR\n",
    "DATA_PATH = \"/home/matthew/priv/PROSTATE_TEST/\"\n",
    "STRUCTURE_NAMES = [\"patient\"]\n",
    "\n",
    "CONTEXT = 0\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "# Train/Valid/Test\n",
    "SPLIT_RATIO = (0.7, 0.2, 0.1)\n",
    "\n",
    "# DATA SHAPES\n",
    "INPUT_SHAPE = (2*CONTEXT + 1, 128, 128, 1)\n",
    "OUTPUT_SHAPE = (1, 512, 512, len(STRUCTURE_NAMES))\n",
    "OUTPUT_CHANNELS = OUTPUT_SHAPE[-1]\n",
    "\n",
    "# MODEL COMPILING\n",
    "EPOCHS = 1\n",
    "OPTIMIZER = 'adam'\n",
    "\n",
    "import tensorflow as tf\n",
    "LOSS = tf.nn.sigmoid_cross_entropy_with_logits\n",
    "\n",
    "METRICS = ['accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import *\n",
    "from generator import DataGen\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_paths, context_paths, label_paths = get_paths(DATA_PATH, CONTEXT)\n",
    "\n",
    "train_paths, valid_paths, test_paths = split_paths(input_paths, SPLIT_RATIO)\n",
    "\n",
    "# For quick training\n",
    "train_paths = train_paths[0:2*BATCH_SIZE]\n",
    "valid_paths = valid_paths[0:2*BATCH_SIZE]\n",
    "test_paths = test_paths[0:1*BATCH_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in train_paths: print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load generator\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "import skimage.draw\n",
    "import numpy as np\n",
    "# Perhaps use tf.io instead\n",
    "import pydicom\n",
    "from pathlib import Path\n",
    "import skimage.transform\n",
    "\n",
    "\n",
    "class DataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, input_paths, context_paths, label_paths, context,\n",
    "                 batch_size, structure_names, resize=128):\n",
    "        self.input_paths = input_paths\n",
    "        self.context_paths = context_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.context = context\n",
    "        self.batch_size = batch_size\n",
    "        self.structure_names = structure_names\n",
    "\n",
    "        for path in self.label_paths:\n",
    "            _ = self.pre_cached_structures(path)\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    @functools.lru_cache()\n",
    "    def pre_cached_structures(self, path):\n",
    "        return pydicom.dcmread(path, force=True)\n",
    "\n",
    "    def get_parent_dir(self, path):\n",
    "        return Path(path).parent.name\n",
    "\n",
    "    # def resize_vol(volume, shape):\n",
    "    #     for s in volume:\n",
    "    #         skimage.transform.resize(s, shape)\n",
    "    #     return volume\n",
    "\n",
    "\n",
    "    def __getitem__(self, batch_index):\n",
    "\n",
    "        if (batch_index + 1) * self.batch_size > len(self.input_paths):\n",
    "            self.batch_size = len(\n",
    "                self.input_paths) - batch_index * self.batch_size\n",
    "\n",
    "        batch_paths = self.input_paths[batch_index *\n",
    "                                       self.batch_size:(batch_index + 1) *\n",
    "                                       self.batch_size]\n",
    "\n",
    "        batch_inputs = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for image_path in batch_paths:\n",
    "            # Get parent dir\n",
    "            parent_dir = self.get_parent_dir(image_path)\n",
    "            # Get mask path\n",
    "            mask_path = [s for s in self.label_paths if parent_dir in s][0]\n",
    "            # Get index\n",
    "            image_index = self.context_paths.index(image_path)\n",
    "            # Get context\n",
    "            input_paths = self.context_paths[image_index -\n",
    "                                             self.context:image_index +\n",
    "                                             self.context + 1]\n",
    "\n",
    "            try:\n",
    "                assert len(input_paths) == 2 * self.context + 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            ###################### IMAGE LOOP ###################################\n",
    "\n",
    "            images = []\n",
    "            for dcm_path in input_paths:\n",
    "                dicom_ct = pydicom.dcmread(dcm_path, force=True)\n",
    "                try:\n",
    "                    dicom_ct.file_meta.TransferSyntaxUID\n",
    "                except AttributeError:\n",
    "                    dicom_ct.file_meta.TransferSyntaxUID = (\n",
    "                        pydicom.uid.ImplicitVRLittleEndian)\n",
    "                image = dicom_ct.pixel_array\n",
    "                image = skimage.transform.resize(image, (128, 128))\n",
    "                images = images + [image]\n",
    "\n",
    "            batch_inputs.append(images)\n",
    "\n",
    "            ####################### MASK LOOP ####################################\n",
    "\n",
    "            img = pydicom.dcmread(image_path, force=True)\n",
    "            img_position = img.ImagePositionPatient\n",
    "            img_spacing = [x for x in img.PixelSpacing] + [img.SliceThickness]\n",
    "            img_orientation = img.ImageOrientationPatient\n",
    "\n",
    "            dicom_structures = self.pre_cached_structures(mask_path)\n",
    "\n",
    "            assert img.FrameOfReferenceUID == dicom_structures.StructureSetROISequence[\n",
    "                0].ReferencedFrameOfReferenceUID\n",
    "\n",
    "            dcm_rs_struct_names = [\n",
    "                structure.ROIName\n",
    "                for structure in dicom_structures.StructureSetROISequence\n",
    "            ]\n",
    "\n",
    "            structure_names = self.structure_names\n",
    "\n",
    "            names_to_pull = [\n",
    "                name for name in dcm_rs_struct_names if name in structure_names\n",
    "            ]\n",
    "            try:\n",
    "                assert len(names_to_pull) == len(structure_names)\n",
    "            except:\n",
    "                batch_inputs.pop()\n",
    "                continue\n",
    "\n",
    "            structure_indexes = [\n",
    "                dcm_rs_struct_names.index(name) for name in names_to_pull\n",
    "            ]\n",
    "\n",
    "            mask = np.zeros(shape=(1, 512, 512, len(structure_indexes)))\n",
    "\n",
    "            dx, dy, *rest = img_spacing\n",
    "            Cx, Cy, *rest = img_position\n",
    "            Ox, Oy = img_orientation[0], img_orientation[4]\n",
    "\n",
    "            for mask_index, structure_index in enumerate(structure_indexes):\n",
    "                z = [\n",
    "                    z_slice.ContourData[2::3][0]\n",
    "                    for z_slice in dicom_structures.\n",
    "                    ROIContourSequence[structure_index].ContourSequence\n",
    "                ]\n",
    "\n",
    "                try:\n",
    "                    indexes = z.index(img_position[2])\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    len(indexes)\n",
    "                except:\n",
    "                    indexes = [indexes]\n",
    "\n",
    "                for index in indexes:\n",
    "                    xyz = dicom_structures.ROIContourSequence[\n",
    "                        structure_index].ContourSequence[index].ContourData\n",
    "\n",
    "                    x = np.array(xyz[0::3])\n",
    "                    y = np.array(xyz[1::3])\n",
    "\n",
    "                    r = (y - Cy) / dy * Oy\n",
    "                    c = (x - Cx) / dx * Ox\n",
    "\n",
    "                    rr, cc = skimage.draw.polygon(r, c)\n",
    "\n",
    "                    mask[:, rr, cc, mask_index] = True\n",
    "            mask = skimage.transform.resize(mask, (1, 128, 128, 1))\n",
    "            batch_labels.append(mask)\n",
    "\n",
    "        ###################### RETURNS ###################################\n",
    "        batch_inputs = np.array(batch_inputs)\n",
    "        batch_inputs = batch_inputs[..., np.newaxis]\n",
    "\n",
    "        #batch_input = np.array(batch_inputs)\n",
    "        batch_labels = np.array(batch_labels)\n",
    "\n",
    "        return batch_inputs, batch_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        # number of batches per epoch\n",
    "        return int(np.ceil(len(self.input_paths) / float(self.batch_size)))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\n",
    "        \"\"\"\n",
    "        None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGen(train_paths,\n",
    "                       context_paths,\n",
    "                       label_paths,\n",
    "                       context=CONTEXT,\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       structure_names=STRUCTURE_NAMES)\n",
    "\n",
    "valid_gen = DataGen(valid_paths,\n",
    "                    context_paths,\n",
    "                    label_paths,\n",
    "                    context=CONTEXT,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    structure_names=STRUCTURE_NAMES)\n",
    "\n",
    "# test_gen = DataGen(test_paths,\n",
    "#                     context_paths,\n",
    "#                     label_paths,\n",
    "#                     context=CONTEXT,\n",
    "#                     batch_size=BATCH_SIZE,\n",
    "#                     structure_names=STRUCTURE_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "batch_index = randint(0, round(len(train_paths) / BATCH_SIZE) - 1)\n",
    "print(batch_index)\n",
    "inputs, labels = train_gen.__getitem__(batch_index=batch_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arr in labels: print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 10), sharex=True, sharey=True)\n",
    "axes[0].imshow(inputs[index,0,:,:,0])\n",
    "axes[1].imshow(labels[index,0,:,:,0])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load model_myfull_slim\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def down_block(x, m, n, c, size):\n",
    "    Zc = int((n / 2) * (size - 1))\n",
    "    crop = tf.keras.layers.Cropping3D(cropping=(Zc, 0, 0))(x)\n",
    "    crop = tf.keras.layers.Conv3D(c, 1, activation=None)(crop)\n",
    "\n",
    "#     result = tf.keras.layers.ReLU()(x)\n",
    "    result = x\n",
    "    for repeat in range(m):\n",
    "        result = tf.keras.layers.Conv3D(c, (1, 3, 3),\n",
    "                                        strides=1,\n",
    "                                        padding='same')(result)\n",
    "        result = tf.keras.layers.ReLU()(result)\n",
    "\n",
    "    for repeat in range(n):\n",
    "#         result = tf.keras.layers.Conv3D(c, (1, 3, 3),\n",
    "#                                         strides=1,\n",
    "#                                         padding='same', activation=None)(result)\n",
    "        result = tf.keras.layers.Conv3D(c, (size, 1, 1),\n",
    "                                        strides=1,\n",
    "                                        padding='valid', activation=None)(result)\n",
    "        \n",
    "#         if repeat != range(n)[-1]:\n",
    "#             result = tf.keras.layers.ReLU()(result)\n",
    "\n",
    "    result = tf.keras.layers.Add()([crop, result])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def pool(x, size):\n",
    "    result = tf.keras.layers.AveragePooling3D(pool_size=(1, size, size),\n",
    "                                              strides=None,\n",
    "                                              padding='valid')(x)\n",
    "    return result\n",
    "\n",
    "\n",
    "def fc_block(x, r):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.layers.Conv3D(1024, (1, 8, 8),\n",
    "                                    strides=1,\n",
    "                                    padding='valid')(x)\n",
    "    for repeat in range(r):\n",
    "        crop = result\n",
    "        # TODO: Should this be a dense layer with RelU activation instead?\n",
    "        result = tf.keras.layers.ReLU()(result)\n",
    "        result = tf.keras.layers.Add()([crop, result])\n",
    "\n",
    "#     result = tf.keras.layers.ReLU()(result)\n",
    "    result = tf.keras.layers.Reshape((1, 8, 8, 256))(x)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def up_block(x, m, c):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    crop = tf.keras.layers.Conv3D(c, 1, activation=None)(x)\n",
    "\n",
    "    result = tf.keras.layers.ReLU()(x)\n",
    "    for repeat in range(m):\n",
    "        result = tf.keras.layers.Conv3D(c, (1, 3, 3),\n",
    "                                        strides=1,\n",
    "                                        padding='same')(result)\n",
    "        result = tf.keras.layers.ReLU()(result)\n",
    "    result = tf.keras.layers.Add()([crop, result])\n",
    "    return result\n",
    "\n",
    "\n",
    "def upscale(x, size):\n",
    "    result = tf.keras.layers.UpSampling3D(size=(1, size, size))(x)\n",
    "    return result\n",
    "\n",
    "\n",
    "def stack(x, skip):\n",
    "    # NOTE axis 0 is the batch\n",
    "    result = tf.keras.layers.Concatenate(axis=1)([x, skip])\n",
    "    return result\n",
    "\n",
    "\n",
    "# def Model(input_shape, output_channels):\n",
    "#     input_shape = (1, 128, 128, 1)\n",
    "#     inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "#     skips = []\n",
    "\n",
    "#     x = down_block(inputs, 0, 2, 64, 5)\n",
    "#     skips.append(x)\n",
    "# #    x = pool(x, 4)\n",
    "\n",
    "# #     x = down_block(x, 0, 2, 128, 4)\n",
    "# #     skips.append(x)\n",
    "# #     x = pool(x, 4)\n",
    "\n",
    "#    # x = down_block(x, 0, 2, 256, 4)\n",
    "#    # skips.append(x)\n",
    "#    # x = pool(x, 4)\n",
    "\n",
    "#     #x = fc_block(x, 2)\n",
    "\n",
    "#    # x = upscale(x, 4)\n",
    "#    # x = stack(skips[-1], x)\n",
    "#    # x = up_block(x, 1, 128)\n",
    "\n",
    "# #     x = upscale(x, 4)\n",
    "# #     x = stack(skips[-1], x)\n",
    "# #     x = up_block(x, 1, 64)\n",
    "\n",
    "# #    x = upscale(x, 4)\n",
    "#     x = stack(skips[-1], x)\n",
    "#     x = up_block(x, 1, 1)\n",
    "\n",
    "#     x = tf.keras.layers.Conv3D(filters=output_channels,\n",
    "#                                kernel_size=(26, 1, 1),\n",
    "#                                strides=1,\n",
    "#                                activation='sigmoid',\n",
    "#                                padding='valid')(x)\n",
    "\n",
    "#     return tf.keras.Model(inputs=inputs, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(input_shape, output_channels):\n",
    "    input_shape = (21, 128, 128, 1)\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    skips = []\n",
    "\n",
    "    x = down_block(inputs, 0, 1, 64, 5)\n",
    "    skips.append(x)\n",
    "    x = pool(x, 4)\n",
    "\n",
    "#     x = down_block(x, 0, 2, 128, 4)\n",
    "#     skips.append(x)\n",
    "#     x = pool(x, 4)\n",
    "\n",
    "   # x = down_block(x, 0, 2, 256, 4)\n",
    "   # skips.append(x)\n",
    "   # x = pool(x, 4)\n",
    "\n",
    "    #x = fc_block(x, 2)\n",
    "\n",
    "   # x = upscale(x, 4)\n",
    "   # x = stack(skips[-1], x)\n",
    "   # x = up_block(x, 1, 128)\n",
    "\n",
    "#     x = upscale(x, 4)\n",
    "#     x = stack(skips[-1], x)\n",
    "#     x = up_block(x, 1, 64)\n",
    "\n",
    "    x = upscale(x, 4)\n",
    "    x = stack(skips[-1], x)\n",
    "    x = up_block(x, 1, 1)\n",
    "\n",
    "    x = tf.keras.layers.Conv3D(filters=output_channels,\n",
    "                               kernel_size=(34, 1, 1),\n",
    "                               strides=1,\n",
    "                               activation='sigmoid',\n",
    "                               padding='valid')(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(INPUT_SHAPE, OUTPUT_CHANNELS)\n",
    "\n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS)\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=train_gen,\n",
    "                    validation_data=valid_gen,\n",
    "                    steps_per_epoch=len(train_paths) // BATCH_SIZE,\n",
    "                    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get testing batch\n",
    "from random import randint\n",
    "batch_index = randint(0, round(len(test_paths) / BATCH_SIZE))\n",
    "test_inputs, test_labels = test_gen.__getitem__(batch_index=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 4\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 10), sharex=True, sharey=True)\n",
    "axes[0].imshow(predicts[index,0,:,:,0])\n",
    "axes[1].imshow(test_labels[index,0,:,:,0])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
