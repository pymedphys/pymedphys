{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes it so any changes in pymedphys is automatically\n",
    "# propagated into the notebook without needing a kernel reset.\n",
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymedphys\n",
    "from pymedphys.labs.autosegmentation import pipeline, filtering, indexing, mask, tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all of the DICOM data within a directory called 'dicom' \n",
    "# organised by 'training', 'validation', and 'testing' in here:\n",
    "data_path_root = pathlib.Path.home().joinpath('.data/dicom-ct-and-structures')\n",
    "dicom_directory = data_path_root.joinpath('dicom')\n",
    "\n",
    "training_directory = dicom_directory.joinpath('training')\n",
    "validation_directory = dicom_directory.joinpath('validation')\n",
    "testing_directory = dicom_directory.joinpath('testing')\n",
    "\n",
    "# Of note, the DICOM file directory structure need not have any further\n",
    "# organisation beyond being placed somewhere within one of the three\n",
    "# 'training', 'validation', or 'testing'. They can be organised into\n",
    "# directories by patient but that is not a requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mappings_path = data_path_root.joinpath('name_mappings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_paths = pymedphys.zenodo_data_paths(\"auto-segmentation\")\n",
    "\n",
    "for path in dicom_paths:\n",
    "    if path.suffix == '.dcm':\n",
    "        dataset_id = path.parent.name\n",
    "        parent_and_file = path.parts[-2::]\n",
    "\n",
    "        if int(dataset_id) < 4:\n",
    "            new_path = validation_directory.joinpath(*parent_and_file)\n",
    "        elif int(dataset_id) < 12:\n",
    "            new_path = testing_directory.joinpath(*parent_and_file)\n",
    "        else:\n",
    "            new_path = training_directory.joinpath(*parent_and_file)\n",
    "\n",
    "    elif path.name == 'name_mappings.json':\n",
    "        new_path = name_mappings_path\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected file found. {path}.\")\n",
    "        \n",
    "    if not new_path.exists():\n",
    "        new_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following names_map is used to standardise the structure names\n",
    "names_map = filtering.load_names_mapping(name_mappings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks for the following structures, in the following order\n",
    "structures_to_learn = [\n",
    "    'lens_left', 'lens_right', 'eye_left', 'eye_right', 'patient']\n",
    "\n",
    "# Use the following to filter the slices used for training, validation,\n",
    "# and testing\n",
    "filters = {\n",
    "    \"study_set_must_have_all_of\": structures_to_learn,\n",
    "    \"slice_at_least_one_of\": [\n",
    "        'lens_left', 'lens_right', 'eye_left', 'eye_right'\n",
    "    ],\n",
    "    \"slice_must_have\": ['patient'],\n",
    "    \"slice_cannot_have\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ct_image_paths,\n",
    "    structure_set_paths,\n",
    "    ct_uid_to_structure_uid,\n",
    "    structure_uid_to_ct_uids,\n",
    ") = indexing.get_uid_cache(data_path_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    structure_names_by_ct_uid,\n",
    "    structure_names_by_structure_set_uid,\n",
    ") = indexing.get_cached_structure_names_by_uids(\n",
    "    data_path_root, structure_set_paths, names_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = pipeline.create_datasets(\n",
    "    data_path_root, names_map, structures_to_learn, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all npz files and build ct_uid to training type map\n",
    "\n",
    "ct_uid_to_training_type = {}\n",
    "ct_uids_by_training_type = {}\n",
    "\n",
    "for dataset_type, dataset in datasets.items():\n",
    "    for ct_uid, x_grid, y_grid, input_array, output_array in dataset:\n",
    "        ct_uid = ct_uid.numpy().decode()        \n",
    "        ct_uid_to_training_type[ct_uid] = dataset_type\n",
    "        try:\n",
    "            ct_uids_by_training_type[dataset_type].append(ct_uid)\n",
    "        except KeyError:\n",
    "            ct_uids_by_training_type[dataset_type] = []\n",
    "\n",
    "\n",
    "ct_uids_by_training_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures_to_learn_path = data_path_root.joinpath(\"structures_to_learn.json\")\n",
    "with open(structures_to_learn_path, \"w\") as f:\n",
    "    json.dump(structures_to_learn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_uids_by_training_type_path = data_path_root.joinpath(\"ct_uids_by_training_type.json\")\n",
    "\n",
    "with open(ct_uids_by_training_type_path, \"w\") as f:\n",
    "    json.dump(ct_uids_by_training_type, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymedphys-master",
   "language": "python",
   "name": "pymedphys-master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
