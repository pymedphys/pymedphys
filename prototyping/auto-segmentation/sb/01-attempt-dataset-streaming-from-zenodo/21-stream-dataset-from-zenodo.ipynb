{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes it so any changes in pymedphys is automatically\n",
    "# propagated into the notebook without needing a kernel reset.\n",
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymedphys\n",
    "from pymedphys.labs.autosegmentation import pipeline, filtering, indexing, mask, tfrecord\n",
    "from pymedphys._data import zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_from_zenodo_download(\n",
    "    record_name, ct_uids, structures_to_learn\n",
    "):\n",
    "    def generator():\n",
    "        for ct_uid in ct_uids:\n",
    "            npz_path = pymedphys.zenodo_data_paths(\n",
    "                record_name, \n",
    "                filenames=[\"f{ct_uid}.npz\"]\n",
    "            )[0]\n",
    "            data = np.load(npz_path)\n",
    "            x_grid = data[\"x_grid\"]\n",
    "            y_grid = data[\"y_grid\"]\n",
    "            input_array = data[\"input_array\"]\n",
    "            output_array = data[\"output_array\"]\n",
    "            \n",
    "            input_array = input_array[:, :, None]\n",
    "\n",
    "            yield ct_uid, x_grid, y_grid, input_array, output_array\n",
    "\n",
    "    parameters = (\n",
    "        (tf.string, tf.float64, tf.float64, tf.int32, tf.float64),\n",
    "        (\n",
    "            tf.TensorShape(()),\n",
    "            tf.TensorShape([512]),\n",
    "            tf.TensorShape([512]),\n",
    "            tf.TensorShape([512, 512, 1]),\n",
    "            tf.TensorShape([512, 512, len(structures_to_learn)]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(generator, *parameters)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_from_zenodo_download(\n",
    "    record_name\n",
    "):\n",
    "    filenames_to_download = ['ct_uids_by_training_type.zip', 'structures_to_learn.zip']\n",
    "\n",
    "    configuration_paths = pymedphys.zenodo_data_paths(\n",
    "        record_name, \n",
    "        filenames=filenames_to_download)\n",
    "\n",
    "    configurations = {}\n",
    "    for path in configuration_paths:\n",
    "        with open(path) as f:\n",
    "            configurations[path.stem] = json.load(f)\n",
    "\n",
    "    ct_uids_by_training_type = configurations['ct_uids_by_training_type']\n",
    "    structures_to_learn = configurations['structures_to_learn']\n",
    "    \n",
    "    datasets = {}\n",
    "    for training_type, ct_uids in ct_uids_by_training_type.items():\n",
    "        datasets[training_type] = dataset_from_zenodo_download(\n",
    "            record_name, ct_uids, structures_to_learn\n",
    "        )\n",
    "        \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_name = \"auto-segmentation-eye-lens-patient-npz\"\n",
    "datasets = datasets_from_zenodo_download(record_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "urls = zenodo.get_zenodo_file_urls(record_name)\n",
    "filenames_to_download = ['ct_uids_by_training_type.zip', 'structures_to_learn.zip']\n",
    "\n",
    "configuration_paths = pymedphys.zenodo_data_paths(\n",
    "    record_name, \n",
    "    filenames=filenames_to_download)\n",
    "\n",
    "configurations = {}\n",
    "for path in configuration_paths:\n",
    "    with open(path) as f:\n",
    "        configurations[path.stem] = json.load(f)\n",
    "        \n",
    "ct_uids_by_training_type = configurations['ct_uids_by_training_type']\n",
    "structures_to_learn = configurations['structures_to_learn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_urls = {\n",
    "    uid: urls[f\"{uid}.npz\"] for uid in ct_uids_by_training_type['training']\n",
    "}\n",
    "\n",
    "download_urls\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct_uids_by_training_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct_uids_by_training_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration_files = {\n",
    "    'training_types': 'ct_uids_by_training_type.zip',\n",
    "    'structures_to_learn': 'structures_to_learn.zip'\n",
    "}\n",
    "\n",
    "filenames_to_download = [item for _, item in configuration_files.items()]\n",
    "filenames_to_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = pymedphys.zenodo_data_paths(\n",
    "    'auto-segmentation-eye-lens-patient-npz', \n",
    "    filenames=filenames_to_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration_paths = {}\n",
    "\n",
    "for key, filename in configuration_files.items():\n",
    "    configuration_paths[key] = [\n",
    "        path for path in paths if path.stem == pathlib.Path(filename).stem][0]\n",
    "    \n",
    "configuration_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_paths = pymedphys.zenodo_data_paths(\"auto-segmentation\")\n",
    "\n",
    "for path in dicom_paths:\n",
    "    if path.suffix == '.dcm':\n",
    "        dataset_id = path.parent.name\n",
    "        parent_and_file = path.parts[-2::]\n",
    "\n",
    "        if int(dataset_id) < 4:\n",
    "            new_path = validation_directory.joinpath(*parent_and_file)\n",
    "        elif int(dataset_id) < 12:\n",
    "            new_path = testing_directory.joinpath(*parent_and_file)\n",
    "        else:\n",
    "            new_path = training_directory.joinpath(*parent_and_file)\n",
    "\n",
    "    elif path.name == 'name_mappings.json':\n",
    "        new_path = name_mappings_path\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected file found. {path}.\")\n",
    "        \n",
    "    if not new_path.exists():\n",
    "        new_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following names_map is used to standardise the structure names\n",
    "names_map = filtering.load_names_mapping(name_mappings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks for the following structures, in the following order\n",
    "structures_to_learn = [\n",
    "    'lens_left', 'lens_right', 'eye_left', 'eye_right', 'patient']\n",
    "\n",
    "# Use the following to filter the slices used for training, validation,\n",
    "# and testing\n",
    "filters = {\n",
    "    \"study_set_must_have_all_of\": structures_to_learn,\n",
    "    \"slice_at_least_one_of\": [\n",
    "        'lens_left', 'lens_right', 'eye_left', 'eye_right'\n",
    "    ],\n",
    "    \"slice_must_have\": ['patient'],\n",
    "    \"slice_cannot_have\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ct_image_paths,\n",
    "    structure_set_paths,\n",
    "    ct_uid_to_structure_uid,\n",
    "    structure_uid_to_ct_uids,\n",
    ") = indexing.get_uid_cache(data_path_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    structure_names_by_ct_uid,\n",
    "    structure_names_by_structure_set_uid,\n",
    ") = indexing.get_cached_structure_names_by_uids(\n",
    "    data_path_root, structure_set_paths, names_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = pipeline.create_datasets(\n",
    "    data_path_root, names_map, structures_to_learn, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all npz files and build ct_uid to training type map\n",
    "\n",
    "ct_uid_to_training_type = {}\n",
    "ct_uids_by_training_type = {}\n",
    "\n",
    "for dataset_type, dataset in datasets.items():\n",
    "    for ct_uid, x_grid, y_grid, input_array, output_array in dataset:\n",
    "        ct_uid = ct_uid.numpy().decode()        \n",
    "        ct_uid_to_training_type[ct_uid] = dataset_type\n",
    "        try:\n",
    "            ct_uids_by_training_type[dataset_type].append(ct_uid)\n",
    "        except KeyError:\n",
    "            ct_uids_by_training_type[dataset_type] = []\n",
    "\n",
    "\n",
    "ct_uids_by_training_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures_to_learn_path = data_path_root.joinpath(\"structures_to_learn.json\")\n",
    "with open(structures_to_learn_path, \"w\") as f:\n",
    "    json.dump(structures_to_learn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_uids_by_training_type_path = data_path_root.joinpath(\"ct_uids_by_training_type.json\")\n",
    "\n",
    "with open(ct_uids_by_training_type_path, \"w\") as f:\n",
    "    json.dump(ct_uids_by_training_type, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymedphys-master",
   "language": "python",
   "name": "pymedphys-master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
