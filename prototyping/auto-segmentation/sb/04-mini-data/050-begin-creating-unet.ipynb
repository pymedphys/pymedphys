{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from urllib import request\n",
    "import pathlib\n",
    "import collections\n",
    "import warnings\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "import IPython\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://github.com/pymedphys/data/releases/download/mini-lung/mini-lung-medical-decathlon.zip'\n",
    "# filename = url.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = pathlib.Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = sorted(data_path.glob('**/*_image.png'))\n",
    "\n",
    "mask_paths = [\n",
    "    path.parent.joinpath(path.name.replace('_image.png', '_mask.png'))\n",
    "    for path in image_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_mask_pairs = collections.defaultdict(lambda: [])\n",
    "\n",
    "for image_path, mask_path in zip(image_paths, mask_paths):\n",
    "    patient_label = image_path.parent.name\n",
    "    \n",
    "    image = imageio.imread(image_path)\n",
    "    mask = imageio.imread(mask_path)\n",
    "    \n",
    "    image_mask_pairs[patient_label].append((image, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours_from_mask(mask, contour_level=128):\n",
    "    if np.max(mask) < contour_level:\n",
    "        return []\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning)\n",
    "        fig, ax = plt.subplots()\n",
    "        cs = ax.contour(range(mask.shape[0]), range(mask.shape[0]), mask, [contour_level])\n",
    "\n",
    "    contours = [path.vertices for path in cs.collections[0].get_paths()]\n",
    "    plt.close(fig)\n",
    "\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(patient_label, chosen_slice):\n",
    "    image = image_mask_pairs[patient_label][chosen_slice][0]\n",
    "    mask = image_mask_pairs[patient_label][chosen_slice][1]\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image, vmin=0, vmax=100)\n",
    "\n",
    "    contours = get_contours_from_mask(mask)\n",
    "    for contour in contours:\n",
    "        plt.plot(*contour.T, 'r', lw=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_patient(patient_label):\n",
    "    def view_slice(chosen_slice):\n",
    "        display(patient_label, chosen_slice)\n",
    "        \n",
    "    number_of_slices = len(image_mask_pairs[patient_label])\n",
    "    \n",
    "    ipywidgets.interact(view_slice, chosen_slice=ipywidgets.IntSlider(min=0, max=number_of_slices, step=1, value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_labels = sorted(list(image_mask_pairs.keys()))\n",
    "# patient_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipywidgets.interact(view_patient, patient_label=patient_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_tumour_map = collections.defaultdict(lambda: [])\n",
    "for patient_label, pairs in image_mask_pairs.items():\n",
    "    for image, mask in pairs:\n",
    "        has_tumour_map[patient_label].append(np.max(mask) >= 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumour_to_slice_map = collections.defaultdict(lambda: collections.defaultdict(lambda: []))\n",
    "\n",
    "for patient_label, tumour_slices in has_tumour_map.items():\n",
    "    for i, has_tumour in enumerate(tumour_slices):\n",
    "        tumour_to_slice_map[patient_label][has_tumour].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = patient_labels[0:50]\n",
    "test = patient_labels[50:60]\n",
    "validation = patient_labels[60:]\n",
    "\n",
    "len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_per_patient = 5\n",
    "batch_size = len(training) * num_images_per_patient\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.uniform(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.shuffle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_image_mask_pairs = collections.defaultdict(lambda: [])\n",
    "\n",
    "# for patient_label, pairs in image_mask_pairs.items():\n",
    "#     for image, mask in pairs:\n",
    "#         tensor_image_mask_pairs[patient_label].append((\n",
    "#             tf.convert_to_tensor(image[:,:,None], dtype=tf.float32) / 255 * 2 - 1,\n",
    "#             tf.convert_to_tensor(mask[:,:,None], dtype=tf.float32) / 255 * 2 - 1\n",
    "#         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_select_from_each_patient(patient_labels, tumour_class_probability):\n",
    "    patient_labels_to_use = copy.copy(patient_labels)\n",
    "    random.shuffle(patient_labels_to_use)\n",
    "    \n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    for patient_label in patient_labels_to_use:\n",
    "        if random.uniform(0, 1) < tumour_class_probability:\n",
    "            find_tumour = True\n",
    "        else:\n",
    "            find_tumour = False\n",
    "            \n",
    "        slice_to_use = random.choice(tumour_to_slice_map[patient_label][find_tumour])\n",
    "        \n",
    "        mask = image_mask_pairs[patient_label][slice_to_use][1]\n",
    "        if find_tumour:\n",
    "            assert np.max(mask) >= 128\n",
    "        else:\n",
    "            assert np.max(mask) < 128\n",
    "        \n",
    "        images.append(image_mask_pairs[patient_label][slice_to_use][0])\n",
    "        masks.append(image_mask_pairs[patient_label][slice_to_use][1])\n",
    "        \n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_dataset(patient_labels, batch_size, grid_size=128):  \n",
    "    def image_mask_generator():\n",
    "        while True:\n",
    "            images, masks = random_select_from_each_patient(\n",
    "                patient_labels, tumour_class_probability=0.5)\n",
    "\n",
    "            for image, mask in zip(images, masks):\n",
    "                yield (\n",
    "                tf.convert_to_tensor(image[:,:,None], dtype=tf.float32) / 255 * 2 - 1,\n",
    "                tf.convert_to_tensor(mask[:,:,None], dtype=tf.float32) / 255 * 2 - 1\n",
    "            )\n",
    "    \n",
    "    generator_params = (\n",
    "        (tf.float32, tf.float32), \n",
    "        (tf.TensorShape([grid_size, grid_size, 1]), tf.TensorShape([grid_size, grid_size, 1]))\n",
    "    )\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        image_mask_generator, *generator_params\n",
    "    )\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "training_dataset = create_pipeline_dataset(training, batch_size)\n",
    "validation_dataset = create_pipeline_dataset(validation, len(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in training_dataset.take(1):\n",
    "    print(image.shape)\n",
    "    print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_select_from_each_patient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_select_from_each_patient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_first_of_batch(image, mask):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image[0,:,:,0], vmin=-1, vmax=1)\n",
    "\n",
    "    contours = get_contours_from_mask(mask[0,:,:,0], contour_level=0)\n",
    "    for contour in contours:\n",
    "        plt.plot(*contour.T, 'r', lw=3)\n",
    "        \n",
    "\n",
    "for image, mask in training_dataset.take(1):\n",
    "    display_first_of_batch(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x, convs, filters, kernel, drop=False, pool=True, norm=True):\n",
    "    # Convolution\n",
    "    for _ in range(convs):\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            filters, kernel, padding=\"same\", kernel_initializer=\"he_normal\"\n",
    "        )(x)\n",
    "        if norm is True:\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    # Skips\n",
    "    skip = x\n",
    "\n",
    "    # Regularise and down-sample\n",
    "    if drop is True:\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    if pool is True:\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            filters,\n",
    "            kernel,\n",
    "            strides=2,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "        )(x)\n",
    "        if norm is True:\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    return x, skip\n",
    "\n",
    "\n",
    "def decode(x, skip, convs, filters, kernel, drop=False, norm=False):\n",
    "    # Up-convolution\n",
    "    x = tf.keras.layers.Conv2DTranspose(\n",
    "        filters, kernel, strides=2, padding=\"same\", kernel_initializer=\"he_normal\"\n",
    "    )(x)\n",
    "\n",
    "    if norm is True:\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    # Concat with skip\n",
    "    x = tf.keras.layers.concatenate([skip, x], axis=3)\n",
    "\n",
    "    # Convolution\n",
    "    for _ in range(convs):\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            filters, kernel, padding=\"same\", kernel_initializer=\"he_normal\"\n",
    "        )(x)\n",
    "        if norm is True:\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    if drop is True:\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_network(grid_size=128, output_channels=1):\n",
    "    inputs = tf.keras.layers.Input((grid_size, grid_size, 1))\n",
    "\n",
    "    encoder_args = [\n",
    "        # convs, filter, kernel, drop, pool, norm\n",
    "        (2, 32, 3, False, True, True),  # 64, 32\n",
    "        (2, 64, 3, False, True, True),  # 32, 64\n",
    "        (2, 128, 3, False, True, True),  # 16, 128\n",
    "        (2, 256, 3, False, True, True),  # 8, 256\n",
    "    ]\n",
    "\n",
    "    decoder_args = [\n",
    "        # convs, filter, kernel, drop, norm\n",
    "        (2, 128, 3, True, True),  # 16, 512\n",
    "        (2, 64, 3, True, True),  # 32, 256\n",
    "        (2, 32, 3, False, True),  # 64, 128\n",
    "        (2, 16, 3, False, True),  # 128, 64\n",
    "    ]\n",
    "\n",
    "    x = inputs\n",
    "    skips = []\n",
    "\n",
    "    for args in encoder_args:\n",
    "        x, skip = encode(x, *args)\n",
    "        skips.append(skip)\n",
    "\n",
    "    skips.reverse()\n",
    "\n",
    "    for skip, args in zip(skips, decoder_args):\n",
    "        x = decode(x, skip, *args)\n",
    "        \n",
    "    outputs = tf.keras.layers.Conv2D(\n",
    "        output_channels,\n",
    "        1,\n",
    "        activation=\"sigmoid\",\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )\n",
    "    \n",
    "    x = outputs(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = create_network()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_a_prediction():\n",
    "    for image, mask in training_dataset.take(10):\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(image[0,:,:,0], vmin=-1, vmax=1)\n",
    "\n",
    "        contours = get_contours_from_mask(mask[0,:,:,0], contour_level=0)\n",
    "        for contour in contours:\n",
    "            plt.plot(*contour.T, 'k--', lw=1)\n",
    "            \n",
    "        predicted_mask = model.predict(image[0:1, :, :, 0:1])\n",
    "        predicted_contours = get_contours_from_mask(predicted_mask[0,:,:,0], contour_level=0)\n",
    "        for contour in predicted_contours:\n",
    "            plt.plot(*contour.T, 'r', lw=3)\n",
    "            \n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "show_a_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        IPython.display.clear_output(wait=True)\n",
    "        show_a_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "STEPS_PER_EPOCH = 1\n",
    "VALIDATION_STEPS = 1\n",
    "\n",
    "model_history = model.fit(\n",
    "    training_dataset, epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=[\n",
    "        DisplayCallback(), \n",
    "#         tensorboard_callback\n",
    "    ],\n",
    "    use_multiprocessing=True,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymedphys-master",
   "language": "python",
   "name": "pymedphys-master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
