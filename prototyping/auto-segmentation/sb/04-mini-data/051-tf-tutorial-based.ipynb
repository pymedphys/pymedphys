{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from urllib import request\n",
    "import pathlib\n",
    "import collections\n",
    "import warnings\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "import IPython\n",
    "import ipywidgets\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow_examples.models.pix2pix import pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = pathlib.Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://github.com/pymedphys/data/releases/download/mini-lung/mini-lung-medical-decathlon.zip'\n",
    "# filename = url.split('/')[-1]\n",
    "\n",
    "# request.urlretrieve(url, filename)\n",
    "\n",
    "# with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = sorted(data_path.glob('**/*_image.png'))\n",
    "\n",
    "mask_paths = [\n",
    "    path.parent.joinpath(path.name.replace('_image.png', '_mask.png'))\n",
    "    for path in image_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_mask_pairs = collections.defaultdict(lambda: [])\n",
    "\n",
    "for image_path, mask_path in zip(image_paths, mask_paths):\n",
    "    patient_label = image_path.parent.name\n",
    "    \n",
    "    image = imageio.imread(image_path)\n",
    "    mask = imageio.imread(mask_path)\n",
    "    \n",
    "    image_mask_pairs[patient_label].append((image, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours_from_mask(mask, contour_level=0):\n",
    "    if np.max(mask) < contour_level:\n",
    "        return []\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning)\n",
    "        fig, ax = plt.subplots()\n",
    "        cs = ax.contour(range(mask.shape[0]), range(mask.shape[0]), mask, [contour_level])\n",
    "\n",
    "    contours = [path.vertices for path in cs.collections[0].get_paths()]\n",
    "    plt.close(fig)\n",
    "\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_tumour_map = collections.defaultdict(lambda: [])\n",
    "for patient_label, pairs in image_mask_pairs.items():\n",
    "    for image, mask in pairs:\n",
    "        has_tumour_map[patient_label].append(np.max(mask) >= 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumour_to_slice_map = collections.defaultdict(lambda: collections.defaultdict(lambda: []))\n",
    "\n",
    "for patient_label, tumour_slices in has_tumour_map.items():\n",
    "    for i, has_tumour in enumerate(tumour_slices):\n",
    "        tumour_to_slice_map[patient_label][has_tumour].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_labels = sorted(list(image_mask_pairs.keys()))\n",
    "\n",
    "training = patient_labels[0:50]\n",
    "test = patient_labels[50:60]\n",
    "validation = patient_labels[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_select_from_each_patient(patient_labels, tumour_class_probability):\n",
    "    patient_labels_to_use = copy.copy(patient_labels)\n",
    "    random.shuffle(patient_labels_to_use)\n",
    "    \n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    for patient_label in patient_labels_to_use:\n",
    "        if random.uniform(0, 1) < tumour_class_probability:\n",
    "            find_tumour = True\n",
    "        else:\n",
    "            find_tumour = False\n",
    "            \n",
    "        slice_to_use = random.choice(tumour_to_slice_map[patient_label][find_tumour])\n",
    "        \n",
    "        mask = image_mask_pairs[patient_label][slice_to_use][1]\n",
    "        if find_tumour:\n",
    "            assert np.max(mask) >= 128\n",
    "        else:\n",
    "            assert np.max(mask) < 128\n",
    "        \n",
    "        images.append(image_mask_pairs[patient_label][slice_to_use][0])\n",
    "        masks.append(image_mask_pairs[patient_label][slice_to_use][1])\n",
    "        \n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_dataset(patient_labels, batch_size, grid_size=128, tumour_class_probability=0.5):  \n",
    "    def image_mask_generator():\n",
    "        while True:\n",
    "            images, masks = random_select_from_each_patient(\n",
    "                patient_labels, tumour_class_probability)\n",
    "\n",
    "            for image, mask in zip(images, masks):\n",
    "                yield (\n",
    "                tf.convert_to_tensor(image[:,:,None], dtype=tf.float32) / 255 * 2 - 1,\n",
    "                tf.convert_to_tensor(mask[:,:,None], dtype=tf.float32) / 255 * 2 - 1\n",
    "            )\n",
    "    \n",
    "    generator_params = (\n",
    "        (tf.float32, tf.float32), \n",
    "        (tf.TensorShape([grid_size, grid_size, 1]), tf.TensorShape([grid_size, grid_size, 1]))\n",
    "    )\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        image_mask_generator, *generator_params\n",
    "    )\n",
    "\n",
    "    dataset = dataset.batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "num_images_per_patient = 5\n",
    "batch_size = len(training) * num_images_per_patient\n",
    "\n",
    "training_dataset = create_pipeline_dataset(training, batch_size)\n",
    "validation_dataset = create_pipeline_dataset(validation, len(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumour_from_validation_dataset = create_pipeline_dataset(validation, 1, tumour_class_probability=1)\n",
    "\n",
    "def show_a_prediction():\n",
    "    for image, mask in tumour_from_validation_dataset.take(1):\n",
    "        plt.figure(figsize=(18,10))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(image[0,:,:,0], vmin=-1, vmax=1)\n",
    "\n",
    "        if 'model' in globals():\n",
    "            predicted_mask = model.predict(image[0:1, :, :, 0:1])\n",
    "            predicted_contours = get_contours_from_mask(predicted_mask[0,:,:,0], contour_level=0)\n",
    "            for contour in predicted_contours:\n",
    "                plt.plot(*contour.T, 'r', lw=2, alpha=0.5)\n",
    "        \n",
    "        contours = get_contours_from_mask(mask[0,:,:,0], contour_level=0)\n",
    "        for contour in contours:\n",
    "            plt.plot(*contour.T, 'b', lw=2, alpha=0.5)\n",
    "        \n",
    "                \n",
    "        plt.title('Image')\n",
    "                \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(mask[0,:,:,0], vmin=-1, vmax=1)\n",
    "        \n",
    "        plt.title('Gold standard mask')\n",
    "        \n",
    "        if 'predicted_mask' in locals():\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(predicted_mask[0,:,:,0], vmin=-1, vmax=1)\n",
    "            \n",
    "            plt.title('Predicted mask')\n",
    "            \n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "show_a_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = tf.keras.applications.ResNet101V2(input_shape=[128, 128, 3], include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FD60EbcAQqov"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liCeLH0ctjq7"
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n",
    "\n",
    "# Use the activations of these layers\n",
    "layer_names = [\n",
    "    'block_1_expand_relu',   # 64x64\n",
    "    'block_3_expand_relu',   # 32x32\n",
    "    'block_6_expand_relu',   # 16x16\n",
    "    'block_13_expand_relu',  # 8x8\n",
    "    'block_16_project',      # 4x4\n",
    "]\n",
    "layers = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "# Create the feature extraction model\n",
    "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
    "\n",
    "down_stack.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0ZbfywEbZpJ"
   },
   "outputs": [],
   "source": [
    "up_stack = [\n",
    "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
    "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
    "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
    "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45HByxpVtrPF"
   },
   "outputs": [],
   "source": [
    "def unet_model():\n",
    "    inputs = tf.keras.layers.Input(shape=[128, 128, 1])\n",
    "    x = inputs\n",
    "    \n",
    "    first = tf.keras.layers.Conv2D(\n",
    "        3, 1, padding=\"same\"\n",
    "    )\n",
    "    \n",
    "    # Spread out to 3 channels to match backbone\n",
    "    x = first(x)\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = down_stack(x)\n",
    "    x = skips[-1]\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        concat = tf.keras.layers.Concatenate()\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    # This is the last layer of the model\n",
    "    last = tf.keras.layers.Conv2DTranspose(\n",
    "        1, 3, strides=2,\n",
    "        padding='same')  #64x64 -> 128x128\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0DGH_4T0VYn"
   },
   "source": [
    "## Train the model\n",
    "Now, all that is left to do is to compile and train the model. The loss being used here is `losses.SparseCategoricalCrossentropy(from_logits=True)`. The reason to use this loss function is because the network is trying to assign each pixel a label, just like multi-class prediction. In the true segmentation mask, each pixel has either a {0,1,2}. The network here is outputting three channels. Essentially, each channel is trying to learn to predict a class, and `losses.SparseCategoricalCrossentropy(from_logits=True)` is the recommended loss for \n",
    "such a scenario. Using the output of the network, the label assigned to the pixel is the channel with the highest value. This is what the create_mask function is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_dsc(y_true, y_pred):\n",
    "    smooth = 1\n",
    "    total_pixels = 128 * 128 * 1\n",
    "    weights = total_pixels / (K.sum(y_true, axis=(0, 1, 2)) + smooth)\n",
    "    intersection = K.sum(y_true * y_pred, axis=(0, 1, 2))\n",
    "    union = K.sum(y_true + y_pred, axis=(0, 1, 2))\n",
    "    w_intersection = K.sum(intersection * weights)\n",
    "    w_union = K.sum(union * weights)\n",
    "    \n",
    "    return (2 * w_intersection + smooth) / (w_union + smooth)\n",
    "\n",
    "\n",
    "def weighted_dsc_loss(y_true, y_pred):\n",
    "    return 1 - weighted_dsc(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6he36HK5uKAc"
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = unet_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=weighted_dsc_loss,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVMzbIZLcyEF"
   },
   "source": [
    "Have a quick look at the resulting model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sw82qF1Gcovr"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_a_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22AyVYWQdkgk"
   },
   "source": [
    "Let's observe how the model improves while it is training. To accomplish this task, a callback function is defined below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHrHsqijdmL6"
   },
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        IPython.display.clear_output(wait=True)\n",
    "        show_a_prediction()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StKDH_B9t4SD"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "STEPS_PER_EPOCH = 1\n",
    "VALIDATION_STEPS = 1\n",
    "\n",
    "model_history = model.fit(training_dataset, epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          validation_steps=VALIDATION_STEPS,\n",
    "                          validation_data=validation_dataset,\n",
    "                          callbacks=[DisplayCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P_mu0SAbt40Q"
   },
   "outputs": [],
   "source": [
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "epochs = range(EPOCHS)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "segmentation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pymedphys-master",
   "language": "python",
   "name": "pymedphys-master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
