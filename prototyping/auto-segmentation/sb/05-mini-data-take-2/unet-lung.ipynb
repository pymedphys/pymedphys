{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zi6LRJcDJLRV"
   },
   "source": [
    "# CT scan UNet demo\n",
    "\n",
    "This notebook creates a UNet for a minified dataset of animal CTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CiSdZ8Q0JLRa"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import urllib.request\n",
    "import shutil\n",
    "import collections\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9s04q2zZJLRb"
   },
   "outputs": [],
   "source": [
    "zip_url = 'https://github.com/pymedphys/data/releases/download/mini-lung/mini-lung-medical-decathlon.zip'\n",
    "zip_filepath = 'data.zip'\n",
    "\n",
    "data_directory = pathlib.Path('data', 'unet', 'lung')\n",
    "\n",
    "if not data_directory.exists():\n",
    "    urllib.request.urlretrieve(zip_url, zip_filepath)\n",
    "    shutil.unpack_archive(zip_filepath, data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUvDaKsUbL1D"
   },
   "outputs": [],
   "source": [
    "directories = sorted(list(data_directory.glob('*')))\n",
    "\n",
    "split = 4\n",
    "\n",
    "training_directories = directories[:-split]\n",
    "validation_directories = directories[-split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqOS2yMibemH"
   },
   "outputs": [],
   "source": [
    "assert len(set(validation_directories).intersection(training_directories)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydwJnGwmJLRb"
   },
   "outputs": [],
   "source": [
    "crop_slice = slice(32, -32)\n",
    "\n",
    "def _load_image(image_path):\n",
    "    png_image = imageio.imread(image_path)\n",
    "    normalised_image = png_image[crop_slice,crop_slice,None] / 255\n",
    "    \n",
    "    return normalised_image\n",
    "\n",
    "\n",
    "def _load_mask(mask_path):\n",
    "    png_mask = imageio.imread(mask_path)\n",
    "    normalised_mask = png_mask[None,crop_slice,crop_slice,None] / 255\n",
    "    \n",
    "    return normalised_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g5SOoZKunucz"
   },
   "outputs": [],
   "source": [
    "z_size = 8\n",
    "mask_image_index = z_size // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGU8fYdkJLRc"
   },
   "outputs": [],
   "source": [
    "def load_dataset_type(directories, shuffle=True):\n",
    "    image_suffix = '_image.png'\n",
    "    mask_suffix = '_mask.png'\n",
    "\n",
    "    mask_paths = []\n",
    "    for directory in directories:\n",
    "        mask_paths += list(directory.glob(f'*{mask_suffix}'))\n",
    "        \n",
    "    if shuffle:\n",
    "        np.random.shuffle(mask_paths)\n",
    "\n",
    "    image_arrays = []\n",
    "    mask_arrays = []\n",
    "    for mask_path in mask_paths:\n",
    "        mask = _load_mask(mask_path)\n",
    "        if np.sum(mask) == 0:\n",
    "            continue\n",
    "            \n",
    "        mask_number = int(mask_path.name.split('_')[0])\n",
    "        start_image_slice = mask_number - mask_image_index\n",
    "        end_image_slice = start_image_slice + z_size\n",
    "        image_filenames = [\n",
    "            str(slice_num).zfill(6) + image_suffix\n",
    "            for slice_num in range(start_image_slice, end_image_slice)\n",
    "        ]\n",
    "        image_paths = [\n",
    "            mask_path.parent.joinpath(filename)\n",
    "            for filename in image_filenames\n",
    "        ]\n",
    "        try:\n",
    "            images_for_mask = [\n",
    "                _load_image(image_path)\n",
    "                for image_path in image_paths\n",
    "            ]\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "\n",
    "        mask_arrays.append(mask)\n",
    "        image_arrays.append(images_for_mask)\n",
    "\n",
    "    images = np.array(image_arrays)\n",
    "    masks = np.array(mask_arrays)\n",
    "    \n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TiYaFEJWJLRc"
   },
   "outputs": [],
   "source": [
    "training_images, training_masks = load_dataset_type(training_directories)\n",
    "validation_images, validation_masks = load_dataset_type(validation_directories, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "POVbu2vrnDmS",
    "outputId": "1e4b02a0-e7f9-462f-8d10-dce743dd2b6e"
   },
   "outputs": [],
   "source": [
    "training_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GfIt6ECGnDmS",
    "outputId": "b39a6197-056b-4c95-c47a-2ba60d21e9f7"
   },
   "outputs": [],
   "source": [
    "training_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4ej7bHVJLRc"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "sample_image, sample_mask = validation_images[i,:,:,:], validation_masks[i,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "A0u1bRevJLRc",
    "outputId": "eb0a120b-bb1e-4da2-da54-f123b453526f"
   },
   "outputs": [],
   "source": [
    "def display(image, mask, prediction=None):\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Input Image')            \n",
    "    plt.imshow(image[mask_image_index,:,:,0])\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('True Mask')            \n",
    "    plt.imshow(mask[0,:,:,0])\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    if prediction is None:\n",
    "        try:\n",
    "            prediction = model.predict(image[None, ...])[0,...]\n",
    "        except NameError:\n",
    "            return\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Predicted Mask')            \n",
    "    plt.imshow(prediction[0,:,:,0])\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    \n",
    "    \n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        display(sample_image, sample_mask)\n",
    "        plt.show()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
    "    \n",
    "    \n",
    "display(sample_image, sample_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mh8KP0ctJLRd"
   },
   "outputs": [],
   "source": [
    "def _activation(x):\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _convolution(x, number_of_filters, kernel_size=3):\n",
    "    x = tf.keras.layers.Conv3D(\n",
    "        number_of_filters, kernel_size, padding=\"same\", kernel_initializer=\"he_normal\"\n",
    "    )(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _conv_transpose(x, number_of_filters, kernel_size=3):\n",
    "    x = tf.keras.layers.Conv3DTranspose(\n",
    "        number_of_filters,\n",
    "        kernel_size,\n",
    "        strides=2,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V40Om2B2JLRd"
   },
   "outputs": [],
   "source": [
    "def encode(\n",
    "    x,\n",
    "    number_of_filters,\n",
    "    number_of_convolutions=2,\n",
    "):\n",
    "    for _ in range(number_of_convolutions):\n",
    "        x = _convolution(x, number_of_filters)\n",
    "        x = _activation(x)\n",
    "    skip = x\n",
    "\n",
    "    x = tf.keras.layers.MaxPool3D()(x)\n",
    "    x = _activation(x)\n",
    "\n",
    "    return x, skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0YtxC_9JLRd"
   },
   "outputs": [],
   "source": [
    "def decode(\n",
    "    x,\n",
    "    skip,\n",
    "    number_of_filters,\n",
    "    number_of_convolutions=2,\n",
    "):\n",
    "    x = _conv_transpose(x, number_of_filters)\n",
    "    x = _activation(x)\n",
    "\n",
    "    x = tf.keras.layers.concatenate([skip, x], axis=-1)\n",
    "\n",
    "    for _ in range(number_of_convolutions):\n",
    "        x = _convolution(x, number_of_filters)\n",
    "        x = _activation(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frZStXWWJLRd"
   },
   "outputs": [],
   "source": [
    "mask_dims = training_masks.shape\n",
    "image_dims = training_images.shape\n",
    "assert mask_dims[2] == mask_dims[3]\n",
    "grid_size = int(mask_dims[2])\n",
    "\n",
    "assert grid_size == image_dims[2]\n",
    "assert grid_size == image_dims[3]\n",
    "\n",
    "assert z_size == image_dims[1]\n",
    "output_channels = int(mask_dims[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZzufytjWJLRf"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input((z_size, grid_size, grid_size, 1))\n",
    "x = inputs\n",
    "skips = []\n",
    "\n",
    "for number_of_filters in [32, 64, 128]:\n",
    "    x, skip = encode(x, number_of_filters)\n",
    "    skips.append(skip)\n",
    "    \n",
    "skips.reverse()\n",
    "\n",
    "for number_of_filters, skip in zip([256, 128, 64], skips):\n",
    "    x = decode(x, skip, number_of_filters)\n",
    "\n",
    "x = tf.keras.layers.Conv3D(\n",
    "    filters=1,\n",
    "    kernel_size=1,\n",
    "    activation=\"sigmoid\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    ")(x)\n",
    "\n",
    "x = tf.keras.layers.MaxPool3D(\n",
    "    pool_size=(z_size, 1, 1)\n",
    ")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bcnWXRGmJLRf",
    "outputId": "73c960f9-77b6-43cf-ad72-f8faa675f9aa"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "EHYE0T1VJLRf",
    "outputId": "892b1859-ea69-42d4-8391-2697d2a977bc"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.Precision()\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(sample_image, sample_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0TNPQy5AJLRg",
    "outputId": "f856ffea-c407-43e9-e6e9-182a9bd71d4a"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    training_images, \n",
    "    training_masks,\n",
    "    epochs=100,\n",
    "    validation_data=(validation_images, validation_masks),\n",
    "    callbacks=[DisplayCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJA_XHS73QnX"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(validation_images)\n",
    "image_combos = list(zip(validation_images, validation_masks, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8IwPQePKUUr"
   },
   "outputs": [],
   "source": [
    "num_val_images = validation_images.shape[0]\n",
    "random_selection = np.array(random.sample(range(num_val_images), 30))\n",
    "\n",
    "for i in random_selection:\n",
    "    print(i)\n",
    "    image = validation_images[i]\n",
    "    mask = validation_masks[i]\n",
    "    prediction = predictions[i]\n",
    "    display(image, mask, prediction)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "unet-lung.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
