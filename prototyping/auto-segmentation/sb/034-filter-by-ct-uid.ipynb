{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes it so any changes in pymedphys is automatically\n",
    "# propagated into the notebook without needing a kernel reset.\n",
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymedphys\n",
    "from pymedphys._experimental.autosegmentation import indexing, filtering, pipeline, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_expansion = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks for the following structures, in the following order\n",
    "structures_to_learn = [\n",
    "    'lens_left', 'lens_right', 'eye_left', 'eye_right', 'patient']\n",
    "\n",
    "# Use the following to filter the slices used for training, validation,\n",
    "# and testing\n",
    "filters = {\n",
    "    \"study_set_must_have_all_of\": structures_to_learn,\n",
    "    \"slice_at_least_one_of\": [\n",
    "        'lens_left', 'lens_right', 'eye_left', 'eye_right'\n",
    "    ],\n",
    "    \"slice_must_have\": ['patient'],\n",
    "    \"slice_cannot_have\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_uids, ct_uids = pipeline.get_filtered_uids(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_uids = structure_uids[0:2]\n",
    "validation_uids = structure_uids[2:5]\n",
    "training_uids = structure_uids[5::]\n",
    "\n",
    "print(testing_uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_out_ct_uids(orignal_ct_uid_list, to_be_removed):\n",
    "    return [item for item in orignal_ct_uid_list if not item in to_be_removed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, testing_ct_uids = pipeline.get_filtered_uids(filters, structure_uids=structure_uids[0:2])\n",
    "_, validation_ct_uids = pipeline.get_filtered_uids(filters, structure_uids=structure_uids[2:5])\n",
    "_, training_ct_uids = pipeline.get_filtered_uids(filters, structure_uids=structure_uids[5::])\n",
    "\n",
    "# Adjust the following for further removal of CT UIDs (data cleaning)\n",
    "ct_uids_for_removal = ['1.2.840.113704.1.111.2288.1561526844.18195', '1.2.840.113704.1.111.2288.1561527104.18456']\n",
    "# ct_uids_for_removal = []\n",
    "\n",
    "testing_ct_uids = filter_out_ct_uids(testing_ct_uids, ct_uids_for_removal)\n",
    "validation_ct_uids = filter_out_ct_uids(validation_ct_uids, ct_uids_for_removal)\n",
    "training_ct_uids = filter_out_ct_uids(training_ct_uids, ct_uids_for_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE TensorFlow is not yet installed as part of requirements\n",
    "\n",
    "testing = pipeline.create_dataset(\n",
    "    testing_ct_uids, structures_to_learn, expansion=mask_expansion)\n",
    "\n",
    "validation = pipeline.create_dataset(\n",
    "    validation_ct_uids, structures_to_learn, expansion=mask_expansion)\n",
    "\n",
    "training = pipeline.create_dataset(\n",
    "    training_ct_uids, structures_to_learn, expansion=mask_expansion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnostic_plotting(x_grid, y_grid, input_array, output_array):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    \n",
    "    x_grid = x_grid.numpy()\n",
    "    y_grid = y_grid.numpy()\n",
    "    input_array = input_array.numpy()[:,:,0]\n",
    "    output_array = output_array.numpy()\n",
    "    \n",
    "    for i, structure in enumerate(structures_to_learn[0:-1]):\n",
    "        if structure.endswith('left'):\n",
    "            colour = 'r'\n",
    "        elif structure.endswith('right'):\n",
    "            colour = 'b'\n",
    "        else:\n",
    "            raise ValueError(\"Expected either left or right\")\n",
    "            \n",
    "        if structure.startswith('lens'):\n",
    "            colour += '--'\n",
    "        elif structure.startswith('eye'):\n",
    "            colour += '-'\n",
    "        else:\n",
    "            raise ValueError(\"Expected either eye or lens\")\n",
    "\n",
    "        contours = mask.get_contours_from_mask(\n",
    "            x_grid, y_grid, output_array[:,:,i])\n",
    "        for contour in contours:\n",
    "            plt.plot(*contour.T, colour)\n",
    "            \n",
    "    \n",
    "    plt.axis('equal')\n",
    "    ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    contours = mask.get_contours_from_mask(\n",
    "        x_grid, y_grid, output_array[:,:,-1])\n",
    "    for contour in contours:\n",
    "        plt.plot(*contour.T, 'k--')\n",
    "    \n",
    "    windowed = np.copy(input_array)\n",
    "\n",
    "    vmin = 900\n",
    "    vmax = 1200\n",
    "    windowed[windowed<vmin] = vmin\n",
    "    windowed[windowed>vmax] = vmax\n",
    "\n",
    "    plt.contourf(x_grid, y_grid, windowed, 50)\n",
    "    plt.colorbar()\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ct_uid, x_grid, y_grid, input_array, output_array in training:    \n",
    "    ct_uid = ct_uid.numpy().decode()\n",
    "    \n",
    "    display.display(display.Markdown(f\"## {ct_uid}\"))\n",
    "    diagnostic_plotting(x_grid, y_grid, input_array, output_array)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymedphys-master",
   "language": "python",
   "name": "pymedphys-master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
