{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Further Machine Learning Resources](05.15-Learning-More.ipynb) | [Contents](Index.ipynb) |\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/06.00-Figure-Code.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Figure Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Many of the figures used throughout this text are created in-place by code that appears in print.\n",
    "In a few cases, however, the required code is long enough (or not immediately relevant enough) that we instead put it here for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('figures'):\n",
    "    os.makedirs('figures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Broadcasting\n",
    "\n",
    "[Figure Context](02.05-Computation-on-arrays-broadcasting.ipynb#Introducing-Broadcasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Adapted from astroML: see http://www.astroml.org/book_figures/appendix/fig_broadcast_visual.html\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Draw a figure and axis with no boundary\n",
    "fig = plt.figure(figsize=(6, 4.5), facecolor='w')\n",
    "ax = plt.axes([0, 0, 1, 1], xticks=[], yticks=[], frameon=False)\n",
    "\n",
    "\n",
    "def draw_cube(ax, xy, size, depth=0.4,\n",
    "              edges=None, label=None, label_kwargs=None, **kwargs):\n",
    "    \"\"\"draw and label a cube.  edges is a list of numbers between\n",
    "    1 and 12, specifying which of the 12 cube edges to draw\"\"\"\n",
    "    if edges is None:\n",
    "        edges = range(1, 13)\n",
    "\n",
    "    x, y = xy\n",
    "\n",
    "    if 1 in edges:\n",
    "        ax.plot([x, x + size],\n",
    "                [y + size, y + size], **kwargs)\n",
    "    if 2 in edges:\n",
    "        ax.plot([x + size, x + size],\n",
    "                [y, y + size], **kwargs)\n",
    "    if 3 in edges:\n",
    "        ax.plot([x, x + size],\n",
    "                [y, y], **kwargs)\n",
    "    if 4 in edges:\n",
    "        ax.plot([x, x],\n",
    "                [y, y + size], **kwargs)\n",
    "\n",
    "    if 5 in edges:\n",
    "        ax.plot([x, x + depth],\n",
    "                [y + size, y + depth + size], **kwargs)\n",
    "    if 6 in edges:\n",
    "        ax.plot([x + size, x + size + depth],\n",
    "                [y + size, y + depth + size], **kwargs)\n",
    "    if 7 in edges:\n",
    "        ax.plot([x + size, x + size + depth],\n",
    "                [y, y + depth], **kwargs)\n",
    "    if 8 in edges:\n",
    "        ax.plot([x, x + depth],\n",
    "                [y, y + depth], **kwargs)\n",
    "\n",
    "    if 9 in edges:\n",
    "        ax.plot([x + depth, x + depth + size],\n",
    "                [y + depth + size, y + depth + size], **kwargs)\n",
    "    if 10 in edges:\n",
    "        ax.plot([x + depth + size, x + depth + size],\n",
    "                [y + depth, y + depth + size], **kwargs)\n",
    "    if 11 in edges:\n",
    "        ax.plot([x + depth, x + depth + size],\n",
    "                [y + depth, y + depth], **kwargs)\n",
    "    if 12 in edges:\n",
    "        ax.plot([x + depth, x + depth],\n",
    "                [y + depth, y + depth + size], **kwargs)\n",
    "\n",
    "    if label:\n",
    "        if label_kwargs is None:\n",
    "            label_kwargs = {}\n",
    "        ax.text(x + 0.5 * size, y + 0.5 * size, label,\n",
    "                ha='center', va='center', **label_kwargs)\n",
    "\n",
    "solid = dict(c='black', ls='-', lw=1,\n",
    "             label_kwargs=dict(color='k'))\n",
    "dotted = dict(c='black', ls='-', lw=0.5, alpha=0.5,\n",
    "              label_kwargs=dict(color='gray'))\n",
    "depth = 0.3\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Draw top operation: vector plus scalar\n",
    "draw_cube(ax, (1, 10), 1, depth, [1, 2, 3, 4, 5, 6, 9], '0', **solid)\n",
    "draw_cube(ax, (2, 10), 1, depth, [1, 2, 3, 6, 9], '1', **solid)\n",
    "draw_cube(ax, (3, 10), 1, depth, [1, 2, 3, 6, 7, 9, 10], '2', **solid)\n",
    "\n",
    "draw_cube(ax, (6, 10), 1, depth, [1, 2, 3, 4, 5, 6, 7, 9, 10], '5', **solid)\n",
    "draw_cube(ax, (7, 10), 1, depth, [1, 2, 3, 6, 7, 9, 10, 11], '5', **dotted)\n",
    "draw_cube(ax, (8, 10), 1, depth, [1, 2, 3, 6, 7, 9, 10, 11], '5', **dotted)\n",
    "\n",
    "draw_cube(ax, (12, 10), 1, depth, [1, 2, 3, 4, 5, 6, 9], '5', **solid)\n",
    "draw_cube(ax, (13, 10), 1, depth, [1, 2, 3, 6, 9], '6', **solid)\n",
    "draw_cube(ax, (14, 10), 1, depth, [1, 2, 3, 6, 7, 9, 10], '7', **solid)\n",
    "\n",
    "ax.text(5, 10.5, '+', size=12, ha='center', va='center')\n",
    "ax.text(10.5, 10.5, '=', size=12, ha='center', va='center')\n",
    "ax.text(1, 11.5, r'${\\tt np.arange(3) + 5}$',\n",
    "        size=12, ha='left', va='bottom')\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Draw middle operation: matrix plus vector\n",
    "\n",
    "# first block\n",
    "draw_cube(ax, (1, 7.5), 1, depth, [1, 2, 3, 4, 5, 6, 9], '1', **solid)\n",
    "draw_cube(ax, (2, 7.5), 1, depth, [1, 2, 3, 6, 9], '1', **solid)\n",
    "draw_cube(ax, (3, 7.5), 1, depth, [1, 2, 3, 6, 7, 9, 10], '1', **solid)\n",
    "\n",
    "draw_cube(ax, (1, 6.5), 1, depth, [2, 3, 4], '1', **solid)\n",
    "draw_cube(ax, (2, 6.5), 1, depth, [2, 3], '1', **solid)\n",
    "draw_cube(ax, (3, 6.5), 1, depth, [2, 3, 7, 10], '1', **solid)\n",
    "\n",
    "draw_cube(ax, (1, 5.5), 1, depth, [2, 3, 4], '1', **solid)\n",
    "draw_cube(ax, (2, 5.5), 1, depth, [2, 3], '1', **solid)\n",
    "draw_cube(ax, (3, 5.5), 1, depth, [2, 3, 7, 10], '1', **solid)\n",
    "\n",
    "# second block\n",
    "draw_cube(ax, (6, 7.5), 1, depth, [1, 2, 3, 4, 5, 6, 9], '0', **solid)\n",
    "draw_cube(ax, (7, 7.5), 1, depth, [1, 2, 3, 6, 9], '1', **solid)\n",
    "draw_cube(ax, (8, 7.5), 1, depth, [1, 2, 3, 6, 7, 9, 10], '2', **solid)\n",
    "\n",
    "draw_cube(ax, (6, 6.5), 1, depth, range(2, 13), '0', **dotted)\n",
    "draw_cube(ax, (7, 6.5), 1, depth, [2, 3, 6, 7, 9, 10, 11], '1', **dotted)\n",
    "draw_cube(ax, (8, 6.5), 1, depth, [2, 3, 6, 7, 9, 10, 11], '2', **dotted)\n",
    "\n",
    "draw_cube(ax, (6, 5.5), 1, depth, [2, 3, 4, 7, 8, 10, 11, 12], '0', **dotted)\n",
    "draw_cube(ax, (7, 5.5), 1, depth, [2, 3, 7, 10, 11], '1', **dotted)\n",
    "draw_cube(ax, (8, 5.5), 1, depth, [2, 3, 7, 10, 11], '2', **dotted)\n",
    "\n",
    "# third block\n",
    "draw_cube(ax, (12, 7.5), 1, depth, [1, 2, 3, 4, 5, 6, 9], '1', **solid)\n",
    "draw_cube(ax, (13, 7.5), 1, depth, [1, 2, 3, 6, 9], '2', **solid)\n",
    "draw_cube(ax, (14, 7.5), 1, depth, [1, 2, 3, 6, 7, 9, 10], '3', **solid)\n",
    "\n",
    "draw_cube(ax, (12, 6.5), 1, depth, [2, 3, 4], '1', **solid)\n",
    "draw_cube(ax, (13, 6.5), 1, depth, [2, 3], '2', **solid)\n",
    "draw_cube(ax, (14, 6.5), 1, depth, [2, 3, 7, 10], '3', **solid)\n",
    "\n",
    "draw_cube(ax, (12, 5.5), 1, depth, [2, 3, 4], '1', **solid)\n",
    "draw_cube(ax, (13, 5.5), 1, depth, [2, 3], '2', **solid)\n",
    "draw_cube(ax, (14, 5.5), 1, depth, [2, 3, 7, 10], '3', **solid)\n",
    "\n",
    "ax.text(5, 7.0, '+', size=12, ha='center', va='center')\n",
    "ax.text(10.5, 7.0, '=', size=12, ha='center', va='center')\n",
    "ax.text(1, 9.0, r'${\\tt np.ones((3,\\, 3)) + np.arange(3)}$',\n",
    "        size=12, ha='left', va='bottom')\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Draw bottom operation: vector plus vector, double broadcast\n",
    "\n",
    "# first block\n",
    "draw_cube(ax, (1, 3), 1, depth, [1, 2, 3, 4, 5, 6, 7, 9, 10], '0', **solid)\n",
    "draw_cube(ax, (1, 2), 1, depth, [2, 3, 4, 7, 10], '1', **solid)\n",
    "draw_cube(ax, (1, 1), 1, depth, [2, 3, 4, 7, 10], '2', **solid)\n",
    "\n",
    "draw_cube(ax, (2, 3), 1, depth, [1, 2, 3, 6, 7, 9, 10, 11], '0', **dotted)\n",
    "draw_cube(ax, (2, 2), 1, depth, [2, 3, 7, 10, 11], '1', **dotted)\n",
    "draw_cube(ax, (2, 1), 1, depth, [2, 3, 7, 10, 11], '2', **dotted)\n",
    "\n",
    "draw_cube(ax, (3, 3), 1, depth, [1, 2, 3, 6, 7, 9, 10, 11], '0', **dotted)\n",
    "draw_cube(ax, (3, 2), 1, depth, [2, 3, 7, 10, 11], '1', **dotted)\n",
    "draw_cube(ax, (3, 1), 1, depth, [2, 3, 7, 10, 11], '2', **dotted)\n",
    "\n",
    "# second block\n",
    "draw_cube(ax, (6, 3), 1, depth, [1, 2, 3, 4, 5, 6, 9], '0', **solid)\n",
    "draw_cube(ax, (7, 3), 1, depth, [1, 2, 3, 6, 9], '1', **solid)\n",
    "draw_cube(ax, (8, 3), 1, depth, [1, 2, 3, 6, 7, 9, 10], '2', **solid)\n",
    "\n",
    "draw_cube(ax, (6, 2), 1, depth, range(2, 13), '0', **dotted)\n",
    "draw_cube(ax, (7, 2), 1, depth, [2, 3, 6, 7, 9, 10, 11], '1', **dotted)\n",
    "draw_cube(ax, (8, 2), 1, depth, [2, 3, 6, 7, 9, 10, 11], '2', **dotted)\n",
    "\n",
    "draw_cube(ax, (6, 1), 1, depth, [2, 3, 4, 7, 8, 10, 11, 12], '0', **dotted)\n",
    "draw_cube(ax, (7, 1), 1, depth, [2, 3, 7, 10, 11], '1', **dotted)\n",
    "draw_cube(ax, (8, 1), 1, depth, [2, 3, 7, 10, 11], '2', **dotted)\n",
    "\n",
    "# third block\n",
    "draw_cube(ax, (12, 3), 1, depth, [1, 2, 3, 4, 5, 6, 9], '0', **solid)\n",
    "draw_cube(ax, (13, 3), 1, depth, [1, 2, 3, 6, 9], '1', **solid)\n",
    "draw_cube(ax, (14, 3), 1, depth, [1, 2, 3, 6, 7, 9, 10], '2', **solid)\n",
    "\n",
    "draw_cube(ax, (12, 2), 1, depth, [2, 3, 4], '1', **solid)\n",
    "draw_cube(ax, (13, 2), 1, depth, [2, 3], '2', **solid)\n",
    "draw_cube(ax, (14, 2), 1, depth, [2, 3, 7, 10], '3', **solid)\n",
    "\n",
    "draw_cube(ax, (12, 1), 1, depth, [2, 3, 4], '2', **solid)\n",
    "draw_cube(ax, (13, 1), 1, depth, [2, 3], '3', **solid)\n",
    "draw_cube(ax, (14, 1), 1, depth, [2, 3, 7, 10], '4', **solid)\n",
    "\n",
    "ax.text(5, 2.5, '+', size=12, ha='center', va='center')\n",
    "ax.text(10.5, 2.5, '=', size=12, ha='center', va='center')\n",
    "ax.text(1, 4.5, r'${\\tt np.arange(3).reshape((3,\\, 1)) + np.arange(3)}$',\n",
    "        ha='left', size=12, va='bottom')\n",
    "\n",
    "ax.set_xlim(0, 16)\n",
    "ax.set_ylim(0.5, 12.5)\n",
    "\n",
    "fig.savefig('figures/02.05-broadcasting.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Aggregation and Grouping\n",
    "\n",
    "Figures from the chapter on aggregation and grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Split-Apply-Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_dataframe(df, loc=None, width=None, ax=None, linestyle=None,\n",
    "                   textstyle=None):\n",
    "    loc = loc or [0, 0]\n",
    "    width = width or 1\n",
    "\n",
    "    x, y = loc\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    ncols = len(df.columns) + 1\n",
    "    nrows = len(df.index) + 1\n",
    "\n",
    "    dx = dy = width / ncols\n",
    "\n",
    "    if linestyle is None:\n",
    "        linestyle = {'color':'black'}\n",
    "\n",
    "    if textstyle is None:\n",
    "        textstyle = {'size': 12}\n",
    "\n",
    "    textstyle.update({'ha':'center', 'va':'center'})\n",
    "\n",
    "    # draw vertical lines\n",
    "    for i in range(ncols + 1):\n",
    "        plt.plot(2 * [x + i * dx], [y, y + dy * nrows], **linestyle)\n",
    "\n",
    "    # draw horizontal lines\n",
    "    for i in range(nrows + 1):\n",
    "        plt.plot([x, x + dx * ncols], 2 * [y + i * dy], **linestyle)\n",
    "\n",
    "    # Create index labels\n",
    "    for i in range(nrows - 1):\n",
    "        plt.text(x + 0.5 * dx, y + (i + 0.5) * dy,\n",
    "                 str(df.index[::-1][i]), **textstyle)\n",
    "\n",
    "    # Create column labels\n",
    "    for i in range(ncols - 1):\n",
    "        plt.text(x + (i + 1.5) * dx, y + (nrows - 0.5) * dy,\n",
    "                 str(df.columns[i]), style='italic', **textstyle)\n",
    "        \n",
    "    # Add index label\n",
    "    if df.index.name:\n",
    "        plt.text(x + 0.5 * dx, y + (nrows - 0.5) * dy,\n",
    "                 str(df.index.name), style='italic', **textstyle)\n",
    "\n",
    "    # Insert data\n",
    "    for i in range(nrows - 1):\n",
    "        for j in range(ncols - 1):\n",
    "            plt.text(x + (j + 1.5) * dx,\n",
    "                     y + (i + 0.5) * dy,\n",
    "                     str(df.values[::-1][i, j]), **textstyle)\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Draw figure\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'data': [1, 2, 3, 4, 5, 6]},\n",
    "                   index=['A', 'B', 'C', 'A', 'B', 'C'])\n",
    "df.index.name = 'key'\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6), facecolor='white')\n",
    "ax = plt.axes([0, 0, 1, 1])\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "draw_dataframe(df, [0, 0])\n",
    "\n",
    "for y, ind in zip([3, 1, -1], 'ABC'):\n",
    "    split = df[df.index == ind]\n",
    "    draw_dataframe(split, [2, y])\n",
    "\n",
    "    sum = pd.DataFrame(split.sum()).T\n",
    "    sum.index = [ind]\n",
    "    sum.index.name = 'key'\n",
    "    sum.columns = ['data']\n",
    "    draw_dataframe(sum, [4, y + 0.25])\n",
    "    \n",
    "result = df.groupby(df.index).sum()\n",
    "draw_dataframe(result, [6, 0.75])\n",
    "\n",
    "style = dict(fontsize=14, ha='center', weight='bold')\n",
    "plt.text(0.5, 3.6, \"Input\", **style)\n",
    "plt.text(2.5, 4.6, \"Split\", **style)\n",
    "plt.text(4.5, 4.35, \"Apply (sum)\", **style)\n",
    "plt.text(6.5, 2.85, \"Combine\", **style)\n",
    "\n",
    "arrowprops = dict(facecolor='black', width=1, headwidth=6)\n",
    "plt.annotate('', (1.8, 3.6), (1.2, 2.8), arrowprops=arrowprops)\n",
    "plt.annotate('', (1.8, 1.75), (1.2, 1.75), arrowprops=arrowprops)\n",
    "plt.annotate('', (1.8, -0.1), (1.2, 0.7), arrowprops=arrowprops)\n",
    "\n",
    "plt.annotate('', (3.8, 3.8), (3.2, 3.8), arrowprops=arrowprops)\n",
    "plt.annotate('', (3.8, 1.75), (3.2, 1.75), arrowprops=arrowprops)\n",
    "plt.annotate('', (3.8, -0.3), (3.2, -0.3), arrowprops=arrowprops)\n",
    "\n",
    "plt.annotate('', (5.8, 2.8), (5.2, 3.6), arrowprops=arrowprops)\n",
    "plt.annotate('', (5.8, 1.75), (5.2, 1.75), arrowprops=arrowprops)\n",
    "plt.annotate('', (5.8, 0.7), (5.2, -0.1), arrowprops=arrowprops)\n",
    "    \n",
    "plt.axis('equal')\n",
    "plt.ylim(-1.5, 5);\n",
    "\n",
    "fig.savefig('figures/03.08-split-apply-combine.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## What Is Machine Learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# common plot formatting for below\n",
    "def format_plot(ax, title):\n",
    "    ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "    ax.set_xlabel('feature 1', color='gray')\n",
    "    ax.set_ylabel('feature 2', color='gray')\n",
    "    ax.set_title(title, color='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Classification Example Figures\n",
    "\n",
    "[Figure context](05.01-What-Is-Machine-Learning.ipynb#Classification:-Predicting-Discrete-Labels)\n",
    "\n",
    "The following code generates the figures from the Classification section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# create 50 separable points\n",
    "X, y = make_blobs(n_samples=50, centers=2,\n",
    "                  random_state=0, cluster_std=0.60)\n",
    "\n",
    "# fit the support vector classifier model\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X, y)\n",
    "\n",
    "# create some new points to predict\n",
    "X2, _ = make_blobs(n_samples=80, centers=2,\n",
    "                   random_state=0, cluster_std=0.80)\n",
    "X2 = X2[50:]\n",
    "\n",
    "# predict the labels\n",
    "y2 = clf.predict(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Classification Example Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot the data\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "point_style = dict(cmap='Paired', s=50)\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, **point_style)\n",
    "\n",
    "# format plot\n",
    "format_plot(ax, 'Input Data')\n",
    "ax.axis([-1, 4, -2, 7])\n",
    "\n",
    "fig.savefig('figures/05.01-classification-1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Classification Example Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get contours describing the model\n",
    "xx = np.linspace(-1, 4, 10)\n",
    "yy = np.linspace(-2, 7, 10)\n",
    "xy1, xy2 = np.meshgrid(xx, yy)\n",
    "Z = np.array([clf.decision_function([t])\n",
    "              for t in zip(xy1.flat, xy2.flat)]).reshape(xy1.shape)\n",
    "\n",
    "# plot points and model\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "line_style = dict(levels = [-1.0, 0.0, 1.0],\n",
    "                  linestyles = ['dashed', 'solid', 'dashed'],\n",
    "                  colors = 'gray', linewidths=1)\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, **point_style)\n",
    "ax.contour(xy1, xy2, Z, **line_style)\n",
    "\n",
    "# format plot\n",
    "format_plot(ax, 'Model Learned from Input Data')\n",
    "ax.axis([-1, 4, -2, 7])\n",
    "\n",
    "fig.savefig('figures/05.01-classification-2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Classification Example Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "\n",
    "ax[0].scatter(X2[:, 0], X2[:, 1], c='gray', **point_style)\n",
    "ax[0].axis([-1, 4, -2, 7])\n",
    "\n",
    "ax[1].scatter(X2[:, 0], X2[:, 1], c=y2, **point_style)\n",
    "ax[1].contour(xy1, xy2, Z, **line_style)\n",
    "ax[1].axis([-1, 4, -2, 7])\n",
    "\n",
    "format_plot(ax[0], 'Unknown Data')\n",
    "format_plot(ax[1], 'Predicted Labels')\n",
    "\n",
    "fig.savefig('figures/05.01-classification-3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Regression Example Figures\n",
    "\n",
    "[Figure Context](05.01-What-Is-Machine-Learning.ipynb#Regression:-Predicting-Continuous-Labels)\n",
    "\n",
    "The following code generates the figures from the regression section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create some data for the regression\n",
    "rng = np.random.RandomState(1)\n",
    "\n",
    "X = rng.randn(200, 2)\n",
    "y = np.dot(X, [-2, 1]) + 0.1 * rng.randn(X.shape[0])\n",
    "\n",
    "# fit the regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# create some new points to predict\n",
    "X2 = rng.randn(100, 2)\n",
    "\n",
    "# predict the labels\n",
    "y2 = model.predict(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Regression Example Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot data points\n",
    "fig, ax = plt.subplots()\n",
    "points = ax.scatter(X[:, 0], X[:, 1], c=y, s=50,\n",
    "                    cmap='viridis')\n",
    "\n",
    "# format plot\n",
    "format_plot(ax, 'Input Data')\n",
    "ax.axis([-4, 4, -3, 3])\n",
    "\n",
    "fig.savefig('figures/05.01-regression-1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Regression Example Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "\n",
    "points = np.hstack([X, y[:, None]]).reshape(-1, 1, 3)\n",
    "segments = np.hstack([points, points])\n",
    "segments[:, 0, 2] = -8\n",
    "\n",
    "# plot points in 3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(X[:, 0], X[:, 1], y, c=y, s=35,\n",
    "           cmap='viridis')\n",
    "ax.add_collection3d(Line3DCollection(segments, colors='gray', alpha=0.2))\n",
    "ax.scatter(X[:, 0], X[:, 1], -8 + np.zeros(X.shape[0]), c=y, s=10,\n",
    "           cmap='viridis')\n",
    "\n",
    "# format plot\n",
    "ax.patch.set_facecolor('white')\n",
    "ax.view_init(elev=20, azim=-70)\n",
    "ax.set_zlim3d(-8, 8)\n",
    "ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
    "ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "ax.zaxis.set_major_formatter(plt.NullFormatter())\n",
    "ax.set(xlabel='feature 1', ylabel='feature 2', zlabel='label')\n",
    "\n",
    "# Hide axes (is there a better way?)\n",
    "ax.w_xaxis.line.set_visible(False)\n",
    "ax.w_yaxis.line.set_visible(False)\n",
    "ax.w_zaxis.line.set_visible(False)\n",
    "for tick in ax.w_xaxis.get_ticklines():\n",
    "    tick.set_visible(False)\n",
    "for tick in ax.w_yaxis.get_ticklines():\n",
    "    tick.set_visible(False)\n",
    "for tick in ax.w_zaxis.get_ticklines():\n",
    "    tick.set_visible(False)\n",
    "\n",
    "fig.savefig('figures/05.01-regression-2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Regression Example Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "# plot data points\n",
    "fig, ax = plt.subplots()\n",
    "pts = ax.scatter(X[:, 0], X[:, 1], c=y, s=50,\n",
    "                 cmap='viridis', zorder=2)\n",
    "\n",
    "# compute and plot model color mesh\n",
    "xx, yy = np.meshgrid(np.linspace(-4, 4),\n",
    "                     np.linspace(-3, 3))\n",
    "Xfit = np.vstack([xx.ravel(), yy.ravel()]).T\n",
    "yfit = model.predict(Xfit)\n",
    "zz = yfit.reshape(xx.shape)\n",
    "ax.pcolorfast([-4, 4], [-3, 3], zz, alpha=0.5,\n",
    "              cmap='viridis', norm=pts.norm, zorder=1)\n",
    "\n",
    "# format plot\n",
    "format_plot(ax, 'Input Data with Linear Fit')\n",
    "ax.axis([-4, 4, -3, 3])\n",
    "\n",
    "fig.savefig('figures/05.01-regression-3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Regression Example Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot the model fit\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "\n",
    "ax[0].scatter(X2[:, 0], X2[:, 1], c='gray', s=50)\n",
    "ax[0].axis([-4, 4, -3, 3])\n",
    "\n",
    "ax[1].scatter(X2[:, 0], X2[:, 1], c=y2, s=50,\n",
    "              cmap='viridis', norm=pts.norm)\n",
    "ax[1].axis([-4, 4, -3, 3])\n",
    "\n",
    "# format plots\n",
    "format_plot(ax[0], 'Unknown Data')\n",
    "format_plot(ax[1], 'Predicted Labels')\n",
    "\n",
    "fig.savefig('figures/05.01-regression-4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Clustering Example Figures\n",
    "\n",
    "[Figure context](#Clustering:-Inferring-Labels-on-Unlabeled-Data)\n",
    "\n",
    "The following code generates the figures from the clustering section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# create 50 separable points\n",
    "X, y = make_blobs(n_samples=100, centers=4,\n",
    "                  random_state=42, cluster_std=1.5)\n",
    "\n",
    "# Fit the K Means model\n",
    "model = KMeans(4, random_state=0)\n",
    "y = model.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Clustering Example Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot the input data\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(X[:, 0], X[:, 1], s=50, color='gray')\n",
    "\n",
    "# format the plot\n",
    "format_plot(ax, 'Input Data')\n",
    "\n",
    "fig.savefig('figures/05.01-clustering-1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Clustering Example Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot the data with cluster labels\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(X[:, 0], X[:, 1], s=50, c=y, cmap='viridis')\n",
    "\n",
    "# format the plot\n",
    "format_plot(ax, 'Learned Cluster Labels')\n",
    "\n",
    "fig.savefig('figures/05.01-clustering-2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Dimensionality Reduction Example Figures\n",
    "\n",
    "[Figure context](05.01-What-Is-Machine-Learning.ipynb#Dimensionality-Reduction:-Inferring-Structure-of-Unlabeled-Data)\n",
    "\n",
    "The following code generates the figures from the dimensionality reduction section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Dimensionality Reduction Example Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_swiss_roll\n",
    "\n",
    "# make data\n",
    "X, y = make_swiss_roll(200, noise=0.5, random_state=42)\n",
    "X = X[:, [0, 2]]\n",
    "\n",
    "# visualize data\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[:, 0], X[:, 1], color='gray', s=30)\n",
    "\n",
    "# format the plot\n",
    "format_plot(ax, 'Input Data')\n",
    "\n",
    "fig.savefig('figures/05.01-dimesionality-1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Dimensionality Reduction Example Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "\n",
    "model = Isomap(n_neighbors=8, n_components=1)\n",
    "y_fit = model.fit_transform(X).ravel()\n",
    "\n",
    "# visualize data\n",
    "fig, ax = plt.subplots()\n",
    "pts = ax.scatter(X[:, 0], X[:, 1], c=y_fit, cmap='viridis', s=30)\n",
    "cb = fig.colorbar(pts, ax=ax)\n",
    "\n",
    "# format the plot\n",
    "format_plot(ax, 'Learned Latent Parameter')\n",
    "cb.set_ticks([])\n",
    "cb.set_label('Latent Variable', color='gray')\n",
    "\n",
    "fig.savefig('figures/05.01-dimesionality-2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Introducing Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Features and Labels Grid\n",
    "\n",
    "The following is the code generating the diagram showing the features matrix and target array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.axis('off')\n",
    "ax.axis('equal')\n",
    "\n",
    "# Draw features matrix\n",
    "ax.vlines(range(6), ymin=0, ymax=9, lw=1)\n",
    "ax.hlines(range(10), xmin=0, xmax=5, lw=1)\n",
    "font_prop = dict(size=12, family='monospace')\n",
    "ax.text(-1, -1, \"Feature Matrix ($X$)\", size=14)\n",
    "ax.text(0.1, -0.3, r'n_features $\\longrightarrow$', **font_prop)\n",
    "ax.text(-0.1, 0.1, r'$\\longleftarrow$ n_samples', rotation=90,\n",
    "        va='top', ha='right', **font_prop)\n",
    "\n",
    "# Draw labels vector\n",
    "ax.vlines(range(8, 10), ymin=0, ymax=9, lw=1)\n",
    "ax.hlines(range(10), xmin=8, xmax=9, lw=1)\n",
    "ax.text(7, -1, \"Target Vector ($y$)\", size=14)\n",
    "ax.text(7.9, 0.1, r'$\\longleftarrow$ n_samples', rotation=90,\n",
    "        va='top', ha='right', **font_prop)\n",
    "\n",
    "ax.set_ylim(10, -2)\n",
    "\n",
    "fig.savefig('figures/05.02-samples-features.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Hyperparameters and Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cross-Validation Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_rects(N, ax, textprop={}):\n",
    "    for i in range(N):\n",
    "        ax.add_patch(plt.Rectangle((0, i), 5, 0.7, fc='white'))\n",
    "        ax.add_patch(plt.Rectangle((5. * i / N, i), 5. / N, 0.7, fc='lightgray'))\n",
    "        ax.text(5. * (i + 0.5) / N, i + 0.35,\n",
    "                \"validation\\nset\", ha='center', va='center', **textprop)\n",
    "        ax.text(0, i + 0.35, \"trial {0}\".format(N - i),\n",
    "                ha='right', va='center', rotation=90, **textprop)\n",
    "    ax.set_xlim(-1, 6)\n",
    "    ax.set_ylim(-0.2, N + 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.axis('off')\n",
    "draw_rects(2, ax, textprop=dict(size=14))\n",
    "\n",
    "fig.savefig('figures/05.03-2-fold-CV.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 5-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.axis('off')\n",
    "draw_rects(5, ax, textprop=dict(size=10))\n",
    "\n",
    "fig.savefig('figures/05.03-5-fold-CV.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Overfitting and Underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_data(N=30, err=0.8, rseed=1):\n",
    "    # randomly sample the data\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    X = rng.rand(N, 1) ** 2\n",
    "    y = 10 - 1. / (X.ravel() + 0.1)\n",
    "    if err > 0:\n",
    "        y += err * rng.randn(N)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                         LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, y = make_data()\n",
    "xfit = np.linspace(-0.1, 1.0, 1000)[:, None]\n",
    "model1 = PolynomialRegression(1).fit(X, y)\n",
    "model20 = PolynomialRegression(20).fit(X, y)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "\n",
    "ax[0].scatter(X.ravel(), y, s=40)\n",
    "ax[0].plot(xfit.ravel(), model1.predict(xfit), color='gray')\n",
    "ax[0].axis([-0.1, 1.0, -2, 14])\n",
    "ax[0].set_title('High-bias model: Underfits the data', size=14)\n",
    "\n",
    "ax[1].scatter(X.ravel(), y, s=40)\n",
    "ax[1].plot(xfit.ravel(), model20.predict(xfit), color='gray')\n",
    "ax[1].axis([-0.1, 1.0, -2, 14])\n",
    "ax[1].set_title('High-variance model: Overfits the data', size=14)\n",
    "\n",
    "fig.savefig('figures/05.03-bias-variance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Bias-Variance Tradeoff Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "\n",
    "X2, y2 = make_data(10, rseed=42)\n",
    "\n",
    "ax[0].scatter(X.ravel(), y, s=40, c='blue')\n",
    "ax[0].plot(xfit.ravel(), model1.predict(xfit), color='gray')\n",
    "ax[0].axis([-0.1, 1.0, -2, 14])\n",
    "ax[0].set_title('High-bias model: Underfits the data', size=14)\n",
    "ax[0].scatter(X2.ravel(), y2, s=40, c='red')\n",
    "ax[0].text(0.02, 0.98, \"training score: $R^2$ = {0:.2f}\".format(model1.score(X, y)),\n",
    "           ha='left', va='top', transform=ax[0].transAxes, size=14, color='blue')\n",
    "ax[0].text(0.02, 0.91, \"validation score: $R^2$ = {0:.2f}\".format(model1.score(X2, y2)),\n",
    "           ha='left', va='top', transform=ax[0].transAxes, size=14, color='red')\n",
    "\n",
    "ax[1].scatter(X.ravel(), y, s=40, c='blue')\n",
    "ax[1].plot(xfit.ravel(), model20.predict(xfit), color='gray')\n",
    "ax[1].axis([-0.1, 1.0, -2, 14])\n",
    "ax[1].set_title('High-variance model: Overfits the data', size=14)\n",
    "ax[1].scatter(X2.ravel(), y2, s=40, c='red')\n",
    "ax[1].text(0.02, 0.98, \"training score: $R^2$ = {0:.2g}\".format(model20.score(X, y)),\n",
    "           ha='left', va='top', transform=ax[1].transAxes, size=14, color='blue')\n",
    "ax[1].text(0.02, 0.91, \"validation score: $R^2$ = {0:.2g}\".format(model20.score(X2, y2)),\n",
    "           ha='left', va='top', transform=ax[1].transAxes, size=14, color='red')\n",
    "\n",
    "fig.savefig('figures/05.03-bias-variance-2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 1000)\n",
    "y1 = -(x - 0.5) ** 2\n",
    "y2 = y1 - 0.33 + np.exp(x - 1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y2, lw=10, alpha=0.5, color='blue')\n",
    "ax.plot(x, y1, lw=10, alpha=0.5, color='red')\n",
    "\n",
    "ax.text(0.15, 0.2, \"training score\", rotation=45, size=16, color='blue')\n",
    "ax.text(0.2, -0.05, \"validation score\", rotation=20, size=16, color='red')\n",
    "\n",
    "ax.text(0.02, 0.1, r'$\\longleftarrow$ High Bias', size=18, rotation=90, va='center')\n",
    "ax.text(0.98, 0.1, r'$\\longleftarrow$ High Variance $\\longrightarrow$', size=18, rotation=90, ha='right', va='center')\n",
    "ax.text(0.48, -0.12, 'Best$\\\\longrightarrow$\\nModel', size=18, rotation=90, va='center')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(-0.3, 0.5)\n",
    "\n",
    "ax.set_xlabel(r'model complexity $\\longrightarrow$', size=14)\n",
    "ax.set_ylabel(r'model score $\\longrightarrow$', size=14)\n",
    "\n",
    "ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
    "ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "ax.set_title(\"Validation Curve Schematic\", size=16)\n",
    "\n",
    "fig.savefig('figures/05.03-validation-curve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "N = np.linspace(0, 1, 1000)\n",
    "y1 = 0.75 + 0.2 * np.exp(-4 * N)\n",
    "y2 = 0.7 - 0.6 * np.exp(-4 * N)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y1, lw=10, alpha=0.5, color='blue')\n",
    "ax.plot(x, y2, lw=10, alpha=0.5, color='red')\n",
    "\n",
    "ax.text(0.2, 0.88, \"training score\", rotation=-10, size=16, color='blue')\n",
    "ax.text(0.2, 0.5, \"validation score\", rotation=30, size=16, color='red')\n",
    "\n",
    "ax.text(0.98, 0.45, r'Good Fit $\\longrightarrow$', size=18, rotation=90, ha='right', va='center')\n",
    "ax.text(0.02, 0.57, r'$\\longleftarrow$ High Variance $\\longrightarrow$', size=18, rotation=90, va='center')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.set_xlabel(r'training set size $\\longrightarrow$', size=14)\n",
    "ax.set_ylabel(r'model score $\\longrightarrow$', size=14)\n",
    "\n",
    "ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
    "ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "ax.set_title(\"Learning Curve Schematic\", size=16)\n",
    "\n",
    "fig.savefig('figures/05.03-learning-curve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Gaussian Naive Bayes\n",
    "\n",
    "### Gaussian Naive Bayes Example\n",
    "\n",
    "[Figure Context](05.05-Naive-Bayes.ipynb#Gaussian-Naive-Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "X, y = make_blobs(100, 2, centers=2, random_state=2, cluster_std=1.5)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='RdBu')\n",
    "ax.set_title('Naive Bayes Model', size=14)\n",
    "\n",
    "xlim = (-8, 8)\n",
    "ylim = (-15, 5)\n",
    "\n",
    "xg = np.linspace(xlim[0], xlim[1], 60)\n",
    "yg = np.linspace(ylim[0], ylim[1], 40)\n",
    "xx, yy = np.meshgrid(xg, yg)\n",
    "Xgrid = np.vstack([xx.ravel(), yy.ravel()]).T\n",
    "\n",
    "for label, color in enumerate(['red', 'blue']):\n",
    "    mask = (y == label)\n",
    "    mu, std = X[mask].mean(0), X[mask].std(0)\n",
    "    P = np.exp(-0.5 * (Xgrid - mu) ** 2 / std ** 2).prod(1)\n",
    "    Pm = np.ma.masked_array(P, P < 0.03)\n",
    "    ax.pcolorfast(xg, yg, Pm.reshape(xx.shape), alpha=0.5,\n",
    "                  cmap=color.title() + 's')\n",
    "    ax.contour(xx, yy, P.reshape(xx.shape),\n",
    "               levels=[0.01, 0.1, 0.5, 0.9],\n",
    "               colors=color, alpha=0.2)\n",
    "    \n",
    "ax.set(xlim=xlim, ylim=ylim)\n",
    "\n",
    "fig.savefig('figures/05.05-gaussian-NB.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Linear Regression\n",
    "\n",
    "### Gaussian Basis Functions\n",
    "\n",
    "[Figure Context](05.06-Linear-Regression.ipynb#Gaussian-Basis-Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class GaussianFeatures(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Uniformly-spaced Gaussian Features for 1D input\"\"\"\n",
    "    \n",
    "    def __init__(self, N, width_factor=2.0):\n",
    "        self.N = N\n",
    "        self.width_factor = width_factor\n",
    "    \n",
    "    @staticmethod\n",
    "    def _gauss_basis(x, y, width, axis=None):\n",
    "        arg = (x - y) / width\n",
    "        return np.exp(-0.5 * np.sum(arg ** 2, axis))\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # create N centers spread along the data range\n",
    "        self.centers_ = np.linspace(X.min(), X.max(), self.N)\n",
    "        self.width_ = self.width_factor * (self.centers_[1] - self.centers_[0])\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return self._gauss_basis(X[:, :, np.newaxis], self.centers_,\n",
    "                                 self.width_, axis=1)\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "x = 10 * rng.rand(50)\n",
    "y = np.sin(x) + 0.1 * rng.randn(50)\n",
    "xfit = np.linspace(0, 10, 1000)\n",
    "\n",
    "gauss_model = make_pipeline(GaussianFeatures(10, 1.0),\n",
    "                            LinearRegression())\n",
    "gauss_model.fit(x[:, np.newaxis], y)\n",
    "yfit = gauss_model.predict(xfit[:, np.newaxis])\n",
    "\n",
    "gf = gauss_model.named_steps['gaussianfeatures']\n",
    "lm = gauss_model.named_steps['linearregression']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(10):\n",
    "    selector = np.zeros(10)\n",
    "    selector[i] = 1\n",
    "    Xfit = gf.transform(xfit[:, None]) * selector\n",
    "    yfit = lm.predict(Xfit)\n",
    "    ax.fill_between(xfit, yfit.min(), yfit, color='gray', alpha=0.2)\n",
    "\n",
    "ax.scatter(x, y)\n",
    "ax.plot(xfit, gauss_model.predict(xfit[:, np.newaxis]))\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(yfit.min(), 1.5)\n",
    "\n",
    "fig.savefig('figures/05.06-gaussian-basis.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Helper Code\n",
    "\n",
    "The following will create a module ``helpers_05_08.py`` which contains some tools used in [In-Depth: Decision Trees and Random Forests](05.08-Random-Forests.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%file helpers_05_08.py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from ipywidgets import interact\n",
    "\n",
    "\n",
    "def visualize_tree(estimator, X, y, boundaries=True,\n",
    "                   xlim=None, ylim=None, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Plot the training points\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap='viridis',\n",
    "               clim=(y.min(), y.max()), zorder=3)\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    if xlim is None:\n",
    "        xlim = ax.get_xlim()\n",
    "    if ylim is None:\n",
    "        ylim = ax.get_ylim()\n",
    "    \n",
    "    # fit the estimator\n",
    "    estimator.fit(X, y)\n",
    "    xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                         np.linspace(*ylim, num=200))\n",
    "    Z = estimator.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    n_classes = len(np.unique(y))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
    "                           levels=np.arange(n_classes + 1) - 0.5,\n",
    "                           cmap='viridis', clim=(y.min(), y.max()),\n",
    "                           zorder=1)\n",
    "\n",
    "    ax.set(xlim=xlim, ylim=ylim)\n",
    "    \n",
    "    # Plot the decision boundaries\n",
    "    def plot_boundaries(i, xlim, ylim):\n",
    "        if i >= 0:\n",
    "            tree = estimator.tree_\n",
    "        \n",
    "            if tree.feature[i] == 0:\n",
    "                ax.plot([tree.threshold[i], tree.threshold[i]], ylim, '-k', zorder=2)\n",
    "                plot_boundaries(tree.children_left[i],\n",
    "                                [xlim[0], tree.threshold[i]], ylim)\n",
    "                plot_boundaries(tree.children_right[i],\n",
    "                                [tree.threshold[i], xlim[1]], ylim)\n",
    "        \n",
    "            elif tree.feature[i] == 1:\n",
    "                ax.plot(xlim, [tree.threshold[i], tree.threshold[i]], '-k', zorder=2)\n",
    "                plot_boundaries(tree.children_left[i], xlim,\n",
    "                                [ylim[0], tree.threshold[i]])\n",
    "                plot_boundaries(tree.children_right[i], xlim,\n",
    "                                [tree.threshold[i], ylim[1]])\n",
    "            \n",
    "    if boundaries:\n",
    "        plot_boundaries(0, xlim, ylim)\n",
    "\n",
    "\n",
    "def plot_tree_interactive(X, y):\n",
    "    def interactive_tree(depth=5):\n",
    "        clf = DecisionTreeClassifier(max_depth=depth, random_state=0)\n",
    "        visualize_tree(clf, X, y)\n",
    "\n",
    "    return interact(interactive_tree, depth=[1, 5])\n",
    "\n",
    "\n",
    "def randomized_tree_interactive(X, y):\n",
    "    N = int(0.75 * X.shape[0])\n",
    "    \n",
    "    xlim = (X[:, 0].min(), X[:, 0].max())\n",
    "    ylim = (X[:, 1].min(), X[:, 1].max())\n",
    "    \n",
    "    def fit_randomized_tree(random_state=0):\n",
    "        clf = DecisionTreeClassifier(max_depth=15)\n",
    "        i = np.arange(len(y))\n",
    "        rng = np.random.RandomState(random_state)\n",
    "        rng.shuffle(i)\n",
    "        visualize_tree(clf, X[i[:N]], y[i[:N]], boundaries=False,\n",
    "                       xlim=xlim, ylim=ylim)\n",
    "    \n",
    "    interact(fit_randomized_tree, random_state=[0, 100]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Decision Tree Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 4))\n",
    "ax = fig.add_axes([0, 0, 0.8, 1], frameon=False, xticks=[], yticks=[])\n",
    "ax.set_title('Example Decision Tree: Animal Classification', size=24)\n",
    "\n",
    "def text(ax, x, y, t, size=20, **kwargs):\n",
    "    ax.text(x, y, t,\n",
    "            ha='center', va='center', size=size,\n",
    "            bbox=dict(boxstyle='round', ec='k', fc='w'), **kwargs)\n",
    "\n",
    "text(ax, 0.5, 0.9, \"How big is\\nthe animal?\", 20)\n",
    "text(ax, 0.3, 0.6, \"Does the animal\\nhave horns?\", 18)\n",
    "text(ax, 0.7, 0.6, \"Does the animal\\nhave two legs?\", 18)\n",
    "text(ax, 0.12, 0.3, \"Are the horns\\nlonger than 10cm?\", 14)\n",
    "text(ax, 0.38, 0.3, \"Is the animal\\nwearing a collar?\", 14)\n",
    "text(ax, 0.62, 0.3, \"Does the animal\\nhave wings?\", 14)\n",
    "text(ax, 0.88, 0.3, \"Does the animal\\nhave a tail?\", 14)\n",
    "\n",
    "text(ax, 0.4, 0.75, \"> 1m\", 12, alpha=0.4)\n",
    "text(ax, 0.6, 0.75, \"< 1m\", 12, alpha=0.4)\n",
    "\n",
    "text(ax, 0.21, 0.45, \"yes\", 12, alpha=0.4)\n",
    "text(ax, 0.34, 0.45, \"no\", 12, alpha=0.4)\n",
    "\n",
    "text(ax, 0.66, 0.45, \"yes\", 12, alpha=0.4)\n",
    "text(ax, 0.79, 0.45, \"no\", 12, alpha=0.4)\n",
    "\n",
    "ax.plot([0.3, 0.5, 0.7], [0.6, 0.9, 0.6], '-k')\n",
    "ax.plot([0.12, 0.3, 0.38], [0.3, 0.6, 0.3], '-k')\n",
    "ax.plot([0.62, 0.7, 0.88], [0.3, 0.6, 0.3], '-k')\n",
    "ax.plot([0.0, 0.12, 0.20], [0.0, 0.3, 0.0], '--k')\n",
    "ax.plot([0.28, 0.38, 0.48], [0.0, 0.3, 0.0], '--k')\n",
    "ax.plot([0.52, 0.62, 0.72], [0.0, 0.3, 0.0], '--k')\n",
    "ax.plot([0.8, 0.88, 1.0], [0.0, 0.3, 0.0], '--k')\n",
    "ax.axis([0, 1, 0, 1])\n",
    "\n",
    "fig.savefig('figures/05.08-decision-tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Decision Tree Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from helpers_05_08 import visualize_tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "        \n",
    "fig, ax = plt.subplots(1, 4, figsize=(16, 3))\n",
    "fig.subplots_adjust(left=0.02, right=0.98, wspace=0.1)\n",
    "\n",
    "X, y = make_blobs(n_samples=300, centers=4,\n",
    "                  random_state=0, cluster_std=1.0)\n",
    "\n",
    "for axi, depth in zip(ax, range(1, 5)):\n",
    "    model = DecisionTreeClassifier(max_depth=depth)\n",
    "    visualize_tree(model, X, y, ax=axi)\n",
    "    axi.set_title('depth = {0}'.format(depth))\n",
    "\n",
    "fig.savefig('figures/05.08-decision-tree-levels.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Decision Tree Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "visualize_tree(model, X[::2], y[::2], boundaries=False, ax=ax[0])\n",
    "visualize_tree(model, X[1::2], y[1::2], boundaries=False, ax=ax[1])\n",
    "\n",
    "fig.savefig('figures/05.08-decision-tree-overfitting.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Principal Components Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_vector(v0, v1, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0)\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T\n",
    "pca = PCA(n_components=2, whiten=True)\n",
    "pca.fit(X)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "\n",
    "# plot data\n",
    "ax[0].scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
    "for length, vector in zip(pca.explained_variance_, pca.components_):\n",
    "    v = vector * 3 * np.sqrt(length)\n",
    "    draw_vector(pca.mean_, pca.mean_ + v, ax=ax[0])\n",
    "ax[0].axis('equal');\n",
    "ax[0].set(xlabel='x', ylabel='y', title='input')\n",
    "\n",
    "# plot principal components\n",
    "X_pca = pca.transform(X)\n",
    "ax[1].scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.2)\n",
    "draw_vector([0, 0], [0, 3], ax=ax[1])\n",
    "draw_vector([0, 0], [3, 0], ax=ax[1])\n",
    "ax[1].axis('equal')\n",
    "ax[1].set(xlabel='component 1', ylabel='component 2',\n",
    "          title='principal components',\n",
    "          xlim=(-5, 5), ylim=(-3, 3.1))\n",
    "\n",
    "fig.savefig('figures/05.09-PCA-rotation.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Digits Pixel Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_pca_components(x, coefficients=None, mean=0, components=None,\n",
    "                        imshape=(8, 8), n_components=8, fontsize=12,\n",
    "                        show_mean=True):\n",
    "    if coefficients is None:\n",
    "        coefficients = x\n",
    "        \n",
    "    if components is None:\n",
    "        components = np.eye(len(coefficients), len(x))\n",
    "        \n",
    "    mean = np.zeros_like(x) + mean\n",
    "        \n",
    "\n",
    "    fig = plt.figure(figsize=(1.2 * (5 + n_components), 1.2 * 2))\n",
    "    g = plt.GridSpec(2, 4 + bool(show_mean) + n_components, hspace=0.3)\n",
    "\n",
    "    def show(i, j, x, title=None):\n",
    "        ax = fig.add_subplot(g[i, j], xticks=[], yticks=[])\n",
    "        ax.imshow(x.reshape(imshape), interpolation='nearest')\n",
    "        if title:\n",
    "            ax.set_title(title, fontsize=fontsize)\n",
    "\n",
    "    show(slice(2), slice(2), x, \"True\")\n",
    "    \n",
    "    approx = mean.copy()\n",
    "    \n",
    "    counter = 2\n",
    "    if show_mean:\n",
    "        show(0, 2, np.zeros_like(x) + mean, r'$\\mu$')\n",
    "        show(1, 2, approx, r'$1 \\cdot \\mu$')\n",
    "        counter += 1\n",
    "\n",
    "    for i in range(n_components):\n",
    "        approx = approx + coefficients[i] * components[i]\n",
    "        show(0, i + counter, components[i], r'$c_{0}$'.format(i + 1))\n",
    "        show(1, i + counter, approx,\n",
    "             r\"${0:.2f} \\cdot c_{1}$\".format(coefficients[i], i + 1))\n",
    "        if show_mean or i > 0:\n",
    "            plt.gca().text(0, 1.05, '$+$', ha='right', va='bottom',\n",
    "                           transform=plt.gca().transAxes, fontsize=fontsize)\n",
    "\n",
    "    show(slice(2), slice(-2, None), approx, \"Approx\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "sns.set_style('white')\n",
    "\n",
    "fig = plot_pca_components(digits.data[10],\n",
    "                          show_mean=False)\n",
    "\n",
    "fig.savefig('figures/05.09-digits-pixel-components.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Digits PCA Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=8)\n",
    "Xproj = pca.fit_transform(digits.data)\n",
    "sns.set_style('white')\n",
    "fig = plot_pca_components(digits.data[10], Xproj[10],\n",
    "                          pca.mean_, pca.components_)\n",
    "\n",
    "fig.savefig('figures/05.09-digits-pca-components.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Manifold Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### LLE vs MDS Linkages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_hello(N=1000, rseed=42):\n",
    "    # Make a plot with \"HELLO\" text; save as png\n",
    "    fig, ax = plt.subplots(figsize=(4, 1))\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, 0.4, 'HELLO', va='center', ha='center', weight='bold', size=85)\n",
    "    fig.savefig('hello.png')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Open this PNG and draw random points from it\n",
    "    from matplotlib.image import imread\n",
    "    data = imread('hello.png')[::-1, :, 0].T\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    X = rng.rand(4 * N, 2)\n",
    "    i, j = (X * data.shape).astype(int).T\n",
    "    mask = (data[i, j] < 1)\n",
    "    X = X[mask]\n",
    "    X[:, 0] *= (data.shape[0] / data.shape[1])\n",
    "    X = X[:N]\n",
    "    return X[np.argsort(X[:, 0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_hello_s_curve(X):\n",
    "    t = (X[:, 0] - 2) * 0.75 * np.pi\n",
    "    x = np.sin(t)\n",
    "    y = X[:, 1]\n",
    "    z = np.sign(t) * (np.cos(t) - 1)\n",
    "    return np.vstack((x, y, z)).T\n",
    "\n",
    "X = make_hello(1000)\n",
    "XS = make_hello_s_curve(X)\n",
    "colorize = dict(c=X[:, 0], cmap=plt.cm.get_cmap('rainbow', 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# construct lines for MDS\n",
    "rng = np.random.RandomState(42)\n",
    "ind = rng.permutation(len(X))\n",
    "lines_MDS = [(XS[i], XS[j]) for i in ind[:100] for j in ind[100:200]]\n",
    "\n",
    "# construct lines for LLE\n",
    "nbrs = NearestNeighbors(n_neighbors=100).fit(XS).kneighbors(XS[ind[:100]])[1]\n",
    "lines_LLE = [(XS[ind[i]], XS[j]) for i in range(100) for j in nbrs[i]]\n",
    "titles = ['MDS Linkages', 'LLE Linkages (100 NN)']\n",
    "\n",
    "# plot the results\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6),\n",
    "                       subplot_kw=dict(projection='3d', axisbg='none'))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0, wspace=0)\n",
    "\n",
    "for axi, title, lines in zip(ax, titles, [lines_MDS, lines_LLE]):\n",
    "    axi.scatter3D(XS[:, 0], XS[:, 1], XS[:, 2], **colorize);\n",
    "    axi.add_collection(Line3DCollection(lines, lw=1, color='black',\n",
    "                                        alpha=0.05))\n",
    "    axi.view_init(elev=10, azim=-80)\n",
    "    axi.set_title(title, size=18)\n",
    "\n",
    "fig.savefig('figures/05.10-LLE-vs-MDS.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Expectation-Maximization\n",
    "\n",
    "[Figure Context](05.11-K-Means.ipynb#K-Means-Algorithm:-Expectation-Maximization)\n",
    "\n",
    "The following figure shows a visual depiction of the Expectation-Maximization approach to K Means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "\n",
    "X, y_true = make_blobs(n_samples=300, centers=4,\n",
    "                       cluster_std=0.60, random_state=0)\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "centers = [0, 4] + rng.randn(4, 2)\n",
    "\n",
    "def draw_points(ax, c, factor=1):\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=c, cmap='viridis',\n",
    "               s=50 * factor, alpha=0.3)\n",
    "    \n",
    "def draw_centers(ax, centers, factor=1, alpha=1.0):\n",
    "    ax.scatter(centers[:, 0], centers[:, 1],\n",
    "               c=np.arange(4), cmap='viridis', s=200 * factor,\n",
    "               alpha=alpha)\n",
    "    ax.scatter(centers[:, 0], centers[:, 1],\n",
    "               c='black', s=50 * factor, alpha=alpha)\n",
    "\n",
    "def make_ax(fig, gs):\n",
    "    ax = fig.add_subplot(gs)\n",
    "    ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "    return ax\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "gs = plt.GridSpec(4, 15, left=0.02, right=0.98, bottom=0.05, top=0.95, wspace=0.2, hspace=0.2)\n",
    "ax0 = make_ax(fig, gs[:4, :4])\n",
    "ax0.text(0.98, 0.98, \"Random Initialization\", transform=ax0.transAxes,\n",
    "         ha='right', va='top', size=16)\n",
    "draw_points(ax0, 'gray', factor=2)\n",
    "draw_centers(ax0, centers, factor=2)\n",
    "\n",
    "for i in range(3):\n",
    "    ax1 = make_ax(fig, gs[:2, 4 + 2 * i:6 + 2 * i])\n",
    "    ax2 = make_ax(fig, gs[2:, 5 + 2 * i:7 + 2 * i])\n",
    "    \n",
    "    # E-step\n",
    "    y_pred = pairwise_distances_argmin(X, centers)\n",
    "    draw_points(ax1, y_pred)\n",
    "    draw_centers(ax1, centers)\n",
    "    \n",
    "    # M-step\n",
    "    new_centers = np.array([X[y_pred == i].mean(0) for i in range(4)])\n",
    "    draw_points(ax2, y_pred)\n",
    "    draw_centers(ax2, centers, alpha=0.3)\n",
    "    draw_centers(ax2, new_centers)\n",
    "    for i in range(4):\n",
    "        ax2.annotate('', new_centers[i], centers[i],\n",
    "                     arrowprops=dict(arrowstyle='->', linewidth=1))\n",
    "        \n",
    "    \n",
    "    # Finish iteration\n",
    "    centers = new_centers\n",
    "    ax1.text(0.95, 0.95, \"E-Step\", transform=ax1.transAxes, ha='right', va='top', size=14)\n",
    "    ax2.text(0.95, 0.95, \"M-Step\", transform=ax2.transAxes, ha='right', va='top', size=14)\n",
    "\n",
    "\n",
    "# Final E-step    \n",
    "y_pred = pairwise_distances_argmin(X, centers)\n",
    "axf = make_ax(fig, gs[:4, -4:])\n",
    "draw_points(axf, y_pred, factor=2)\n",
    "draw_centers(axf, centers, factor=2)\n",
    "axf.text(0.98, 0.98, \"Final Clustering\", transform=axf.transAxes,\n",
    "         ha='right', va='top', size=16)\n",
    "\n",
    "\n",
    "fig.savefig('figures/05.11-expectation-maximization.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Interactive K-Means\n",
    "\n",
    "The following script uses IPython's interactive widgets to demonstrate the K-means algorithm interactively.\n",
    "Run this within the IPython notebook to explore the expectation maximization algorithm for computing K Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # for plot styling\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "def plot_kmeans_interactive(min_clusters=1, max_clusters=6):\n",
    "    X, y = make_blobs(n_samples=300, centers=4,\n",
    "                      random_state=0, cluster_std=0.60)\n",
    "        \n",
    "    def plot_points(X, labels, n_clusters):\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=labels, s=50, cmap='viridis',\n",
    "                    vmin=0, vmax=n_clusters - 1);\n",
    "            \n",
    "    def plot_centers(centers):\n",
    "        plt.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                    c=np.arange(centers.shape[0]),\n",
    "                    s=200, cmap='viridis')\n",
    "        plt.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                    c='black', s=50)\n",
    "            \n",
    "\n",
    "    def _kmeans_step(frame=0, n_clusters=4):\n",
    "        rng = np.random.RandomState(2)\n",
    "        labels = np.zeros(X.shape[0])\n",
    "        centers = rng.randn(n_clusters, 2)\n",
    "\n",
    "        nsteps = frame // 3\n",
    "\n",
    "        for i in range(nsteps + 1):\n",
    "            old_centers = centers\n",
    "            if i < nsteps or frame % 3 > 0:\n",
    "                labels = pairwise_distances_argmin(X, centers)\n",
    "\n",
    "            if i < nsteps or frame % 3 > 1:\n",
    "                centers = np.array([X[labels == j].mean(0)\n",
    "                                    for j in range(n_clusters)])\n",
    "                nans = np.isnan(centers)\n",
    "                centers[nans] = old_centers[nans]\n",
    "\n",
    "        # plot the data and cluster centers\n",
    "        plot_points(X, labels, n_clusters)\n",
    "        plot_centers(old_centers)\n",
    "\n",
    "        # plot new centers if third frame\n",
    "        if frame % 3 == 2:\n",
    "            for i in range(n_clusters):\n",
    "                plt.annotate('', centers[i], old_centers[i], \n",
    "                             arrowprops=dict(arrowstyle='->', linewidth=1))\n",
    "            plot_centers(centers)\n",
    "\n",
    "        plt.xlim(-4, 4)\n",
    "        plt.ylim(-2, 10)\n",
    "\n",
    "        if frame % 3 == 1:\n",
    "            plt.text(3.8, 9.5, \"1. Reassign points to nearest centroid\",\n",
    "                     ha='right', va='top', size=14)\n",
    "        elif frame % 3 == 2:\n",
    "            plt.text(3.8, 9.5, \"2. Update centroids to cluster means\",\n",
    "                     ha='right', va='top', size=14)\n",
    "    \n",
    "    return interact(_kmeans_step, frame=[0, 50],\n",
    "                    n_clusters=[min_clusters, max_clusters])\n",
    "\n",
    "plot_kmeans_interactive();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Covariance Type\n",
    "\n",
    "[Figure Context](http://localhost:8888/notebooks/05.12-Gaussian-Mixtures.ipynb#Choosing-the-Covariance-Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GMM\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def draw_ellipse(position, covariance, ax=None, **kwargs):\n",
    "    \"\"\"Draw an ellipse with a given position and covariance\"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Convert covariance to principal axes\n",
    "    if covariance.shape == (2, 2):\n",
    "        U, s, Vt = np.linalg.svd(covariance)\n",
    "        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n",
    "        width, height = 2 * np.sqrt(s)\n",
    "    else:\n",
    "        angle = 0\n",
    "        width, height = 2 * np.sqrt(covariance)\n",
    "    \n",
    "    # Draw the Ellipse\n",
    "    for nsig in range(1, 4):\n",
    "        ax.add_patch(Ellipse(position, nsig * width, nsig * height,\n",
    "                             angle, **kwargs))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(14, 4), sharex=True, sharey=True)\n",
    "fig.subplots_adjust(wspace=0.05)\n",
    "\n",
    "rng = np.random.RandomState(5)\n",
    "X = np.dot(rng.randn(500, 2), rng.randn(2, 2))\n",
    "\n",
    "for i, cov_type in enumerate(['diag', 'spherical', 'full']):\n",
    "    model = GMM(1, covariance_type=cov_type).fit(X)\n",
    "    ax[i].axis('equal')\n",
    "    ax[i].scatter(X[:, 0], X[:, 1], alpha=0.5)\n",
    "    ax[i].set_xlim(-3, 3)\n",
    "    ax[i].set_title('covariance_type=\"{0}\"'.format(cov_type),\n",
    "                    size=14, family='monospace')\n",
    "    draw_ellipse(model.means_[0], model.covars_[0], ax[i], alpha=0.2)\n",
    "    ax[i].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "    ax[i].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "fig.savefig('figures/05.12-covariance-type.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Further Machine Learning Resources](05.15-Learning-More.ipynb) | [Contents](Index.ipynb) |\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/06.00-Figure-Code.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
