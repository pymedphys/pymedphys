{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train as train\n",
    "\n",
    "import loss as loss\n",
    "import unet as unet\n",
    "import random\n",
    "import paths as paths\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# The meaning of life\n",
    "random.seed(42)  \n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_MEAN = 168.3172158554484\n",
    "DATA_STD = 340.21625683608994\n",
    "BATCH_SIZE = 3\n",
    "OUTPUT_CHANNELS = 1\n",
    "DATA_PATH = \"./vet_dataset_cleaned/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WEIGHTS = \"./vacbag/dsc_after_bce_epoch_\" + \"80\" + \".hdf5\"\n",
    "WEIGHTS = \"./vacbag_2/bce_epoch_68.hdf5\"\n",
    "INITIAL_LR = 1e-6\n",
    "OPTIMIZER = tf.keras.optimizers.Adam(lr = INITIAL_LR)\n",
    "LOSS = loss.dsc_loss\n",
    "METRICS = [loss.dice_metric, \n",
    "        tf.keras.metrics.Precision(), \n",
    "        tf.keras.metrics.Recall()]\n",
    "\n",
    "model = unet.model(output_channels=OUTPUT_CHANNELS)\n",
    "model.compile(OPTIMIZER, LOSS, METRICS)\n",
    "model.load_weights(WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_paths = paths.get_patient_paths(DATA_PATH)\n",
    "patient_paths.sort()\n",
    "\n",
    "img_paths = [glob.glob(path + \"/img/*\") for path in patient_paths]\n",
    "mask_paths = [glob.glob(path + \"/mask/*\") for path in patient_paths]\n",
    "\n",
    "valid = int(len(img_paths) * 0.15 // 1)\n",
    "test = int(len(img_paths) * 0.1 // 1)\n",
    "train = int(len(img_paths) - valid - test)\n",
    "\n",
    "train_inputs = paths.flatten_list(img_paths[0:train])\n",
    "train_truths = paths.flatten_list(mask_paths[0:train])\n",
    "\n",
    "train_inputs.sort()\n",
    "train_truths.sort()\n",
    "\n",
    "valid_inputs = paths.flatten_list(img_paths[train:train+valid])\n",
    "valid_truths = paths.flatten_list(mask_paths[train:train+valid])\n",
    "\n",
    "valid_inputs.sort()\n",
    "valid_truths.sort()\n",
    "\n",
    "test_inputs = paths.flatten_list(img_paths[train+valid:])\n",
    "test_truths = paths.flatten_list(mask_paths[train+valid:])\n",
    "\n",
    "test_inputs.sort()\n",
    "test_truths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = np.array([np.load(array) for array in test_inputs])\n",
    "test_truths = np.array([np.load(array) for array in test_truths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = (test_inputs - DATA_MEAN) / DATA_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs.shape, test_truths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x=test_inputs, y=test_truths, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import explore as explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.plot_batch_predict(model, test_inputs, test_truths, x=7, batch_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for index in range(len(test_inputs)):\n",
    "    img = test_inputs[index:index+1]\n",
    "    truth = test_truths[index:index+1]\n",
    "    pred = model.predict(img)\n",
    "    pred = np.round(pred)\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(img[0,...,0], cmap='gray')\n",
    "    plt.contour(truth[0,...,0], colors='yellow', alpha=0.5)\n",
    "    plt.contour(pred[0,...,0], colors='red', alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
