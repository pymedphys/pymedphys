{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "\n",
    "import paths_2D as paths\n",
    "import loss_2D as loss\n",
    "import model_ronneberger_512 as model\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch_predict(x=20, model=model, test_imgs=test_imgs, test_masks=test_masks):\n",
    "    y_input = test_imgs[x:x+5]\n",
    "    y_true = test_masks[x:x+5]\n",
    "\n",
    "    print(\"Input shape:\", y_input.shape)\n",
    "    print(\"Truth shape: \", y_true.shape)\n",
    "\n",
    "    y_pred = model.predict(y_input)\n",
    "    print(\"Predict shape:\", y_pred.shape)\n",
    "\n",
    "    y_pred_rounded = np.round(y_pred)\n",
    "    diff = y_pred_rounded - y_true\n",
    "\n",
    "    CMAP = 'binary'\n",
    "    \n",
    "    for batch_index in range(y_input.shape[0]):\n",
    "        fig, axs = plt.subplots(1, 5, figsize=(15,3), sharey=True)\n",
    "        \n",
    "        for ax in axs:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        axs[0].imshow(np.log(1 + y_input[batch_index,...,0]), cmap=CMAP)\n",
    "        axs[0].set_title(\"Input\")\n",
    "        axs[0].contour(y_true[batch_index,...,0])\n",
    "    \n",
    "        axs[1].imshow(y_true[batch_index,...,0], cmap=CMAP)\n",
    "        axs[1].set_title(\"Truth\")\n",
    "        \n",
    "        axs[2].imshow(y_pred[batch_index,...,0], cmap=CMAP)\n",
    "        axs[2].set_title(\"Probabilistic map\")\n",
    "\n",
    "        axs[3].imshow(y_pred_rounded[batch_index,...,0], cmap=CMAP)\n",
    "        axs[3].set_title(\"Binary prediction\")\n",
    "        \n",
    "        axs[4].imshow(diff[batch_index,...,0], cmap=CMAP)\n",
    "        axs[4].set_title(\"Diff: pred-truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"/home/matthew/datasets/vet_dataset_cleaned_npy/\"\n",
    "path = \"/home/jupyter/vet_dataset_cleaned_npy/\"\n",
    "img_paths = glob.glob(path + \"img/*\")\n",
    "mask_paths = glob.glob(path + \"mask/*\")\n",
    "\n",
    "img_paths.sort()\n",
    "mask_paths.sort()\n",
    "\n",
    "temp = list(zip(img_paths, mask_paths))\n",
    "\n",
    "random.shuffle(temp)\n",
    "\n",
    "img_paths, mask_paths = zip(*temp)\n",
    "\n",
    "print(img_paths[0])\n",
    "print(mask_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMALLER SET\n",
    "# img_paths = img_paths[0:200]\n",
    "# mask_paths = mask_paths[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.array([np.load(x) for x in img_paths])\n",
    "\n",
    "imgs_mean = np.mean(imgs)\n",
    "imgs_std = np.std(imgs)\n",
    "imgs = (imgs - imgs_mean) / imgs_std\n",
    "imgs = imgs[...,np.newaxis]\n",
    "\n",
    "swap = len(imgs)-100\n",
    "train_imgs = imgs[0:swap]\n",
    "test_imgs = imgs[swap:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = [np.load(x) for x in mask_paths]\n",
    "\n",
    "for index, mask in enumerate(masks):\n",
    "    if masks[index].shape == (512, 512, 0):\n",
    "        masks[index] = np.zeros((512, 512, 1))\n",
    "\n",
    "masks = np.array(masks)\n",
    "train_masks = masks[0:swap]\n",
    "test_masks = masks[swap:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imgs.shape)\n",
    "print(masks.shape)\n",
    "print(\"--------\")\n",
    "print(train_imgs.shape)\n",
    "print(train_masks.shape)\n",
    "print(\"--------\")\n",
    "print(test_imgs.shape)\n",
    "print(test_masks.shape)\n",
    "print(\"--------\")\n",
    "print(train_imgs[0].shape)\n",
    "print(train_masks[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import model_ronneberger_512 as model\n",
    "\n",
    "MODEL_SAVE = \"./weights/bce_512.{epoch:02d}.hdf5\"\n",
    "\n",
    "LOSS = tf.keras.losses.BinaryCrossentropy()\n",
    "INITIAL_LR = 1e-4\n",
    "STOPPING_PATIENCE = 50\n",
    "LR_PATIENCE = 4\n",
    "\n",
    "METRICS = [loss.dsc_loss]\n",
    "OPTIMIZER = tf.keras.optimizers.Adam(lr = INITIAL_LR)\n",
    "LR_SCALE = 0.5\n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=STOPPING_PATIENCE, verbose=1, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=LR_SCALE, patience=LR_PATIENCE, verbose=1)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(MODEL_SAVE, save_weights_only=True, verbose=1)\n",
    "\n",
    "CALLBACKS = [early_stopping, model_checkpoint, reduce_lr]\n",
    "\n",
    "model = model.model(train_imgs[0].shape[0], train_masks[0].shape[-1])\n",
    "\n",
    "model.compile(optimizer = OPTIMIZER, loss = LOSS ,metrics = METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "x = 20\n",
    "\n",
    "y_input = train_imgs[x:x+5]\n",
    "y_true = train_masks[x:x+5]\n",
    "\n",
    "print(\"Input shape:\", y_input.shape)\n",
    "print(\"Truth shape: \", y_true.shape)\n",
    "\n",
    "\n",
    "y_pred = model.predict(y_input)\n",
    "#y_pred = np.round(y_pred)\n",
    "print(\"Predict shape:\", y_pred.shape)\n",
    "\n",
    "\n",
    "for batch_index in range(y_input.shape[0]):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20,80))\n",
    "    axs[0].imshow(y_input[batch_index,...,0])\n",
    "    \n",
    "    axs[1].imshow(y_true[batch_index,...,0])\n",
    "    axs[2].imshow(y_pred[batch_index,...,0])\n",
    "\n",
    "    axs[3].imshow(y_true[batch_index,...,0], alpha=0.5)\n",
    "    axs[3].imshow(y_pred[batch_index,...,0], alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "print(\"\\n Training...\")\n",
    "train_history = model.fit(x=train_imgs, \n",
    "                          y=train_masks,\n",
    "                          batch_size=5,\n",
    "                          epochs=EPOCHS, \n",
    "                          callbacks=CALLBACKS, \n",
    "                          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_batch_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import model_ronneberger_512 as model\n",
    "\n",
    "MODEL_SAVE = \"./weights_vacbag/dice_after_1_bce_512.{epoch:02d}.hdf5\"\n",
    "\n",
    "LOSS = loss.dsc_loss\n",
    "INITIAL_LR = 1e-5\n",
    "STOPPING_PATIENCE = 50\n",
    "LR_PATIENCE = 4\n",
    "\n",
    "AUC = tf.keras.metrics.AUC(\n",
    "    num_thresholds=200, curve='ROC', summation_method='interpolation', name=None,\n",
    "    dtype=None, thresholds=None, multi_label=False, label_weights=None\n",
    ")\n",
    "\n",
    "METRICS = [loss.dice_metric, tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), AUC]\n",
    "OPTIMIZER = tf.keras.optimizers.Adam(lr = INITIAL_LR)\n",
    "LR_SCALE = 0.5\n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=STOPPING_PATIENCE, verbose=1, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=LR_SCALE, patience=LR_PATIENCE, verbose=1)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(MODEL_SAVE, save_weights_only=True, verbose=1)\n",
    "\n",
    "CALLBACKS = [early_stopping, model_checkpoint, reduce_lr]\n",
    "\n",
    "model = model.model(train_imgs[0].shape[0], train_masks[0].shape[-1])\n",
    "\n",
    "model.compile(optimizer = OPTIMIZER, loss = LOSS ,metrics = METRICS)\n",
    "\n",
    "model.load_weights(\"./weights/bce_512.01.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "print(\"\\n Training...\")\n",
    "train_history = model.fit(x=train_imgs, \n",
    "                          y=train_masks,\n",
    "                          batch_size=5,\n",
    "                          epochs=EPOCHS, \n",
    "                          callbacks=CALLBACKS, \n",
    "                          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Epoch 00011: saving model to ./weights/dice_after_1_bce_512.11.hdf5\n",
    "\n",
    "plot_batch_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import model_ronneberger_512 as model\n",
    "\n",
    "MODEL_SAVE = \"./weights_vacbag/dice_2_after_1_bce_512.{epoch:02d}.hdf5\"\n",
    "\n",
    "LOSS = loss.dsc_loss\n",
    "INITIAL_LR = 1e-6\n",
    "STOPPING_PATIENCE = 50\n",
    "LR_PATIENCE = 4\n",
    "\n",
    "METRICS = [loss.dice_metric,\n",
    "           tf.keras.metrics.Precision(),\n",
    "           tf.keras.metrics.Recall()]\n",
    "\n",
    "OPTIMIZER = tf.keras.optimizers.Adam(lr = INITIAL_LR)\n",
    "LR_SCALE = 0.5\n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=STOPPING_PATIENCE, verbose=1, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=LR_SCALE, patience=LR_PATIENCE, verbose=1)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(MODEL_SAVE, save_weights_only=True, verbose=1)\n",
    "\n",
    "CALLBACKS = [early_stopping, model_checkpoint, reduce_lr]\n",
    "\n",
    "model = model.model(train_imgs[0].shape[0], train_masks[0].shape[-1])\n",
    "\n",
    "model.compile(optimizer = OPTIMIZER, loss = LOSS ,metrics = METRICS)\n",
    "\n",
    "model.load_weights(\"./weights/dice_after_1_bce_512.11.hdf5\")\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "print(\"\\n Training...\")\n",
    "train_history = model.fit(x=train_imgs, \n",
    "                          y=train_masks,\n",
    "                          batch_size=5,\n",
    "                          epochs=EPOCHS, \n",
    "                          callbacks=CALLBACKS, \n",
    "                          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_batch_predict(x=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x=test_imgs,\n",
    "              y=test_masks,\n",
    "              batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
