{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes it so any changes in pymedphys is automatically\n",
    "# propagated into the notebook without needing a kernel reset.\n",
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymedphys\n",
    "from pymedphys.labs.autosegmentation import pipeline, filtering, indexing, mask, tfrecord\n",
    "from pymedphys._data import zenodo, download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_name = \"auto-segmentation-eye-lens-patient-npz\"\n",
    "\n",
    "paths = pymedphys.zenodo_data_paths(record_name)\n",
    "\n",
    "npz_paths = [path for path in paths if path.suffix == \".npz\"]\n",
    "# npz_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in npz_paths:\n",
    "    with zipfile.ZipFile(path.with_suffix('.zip'), 'w', compression=zipfile.ZIP_LZMA) as z:\n",
    "        z.write(path, arcname=path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_paths = list(pathlib.Path.home().joinpath('.data', 'dicom-ct-and-structures', 'npz_cache').glob('*1.2.840.113704.1.111.3880*.npz'))\n",
    "npz_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in npz_paths:\n",
    "    with zipfile.ZipFile(path.with_suffix('.zip'), 'w', compression=zipfile.ZIP_LZMA) as z:\n",
    "        z.write(path, arcname=path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_dataset_from_zenodo_download(\n",
    "    record_name, ct_uids, structures_to_learn\n",
    "):\n",
    "    npz_download_directory = download.get_data_dir().joinpath(record_name)\n",
    "    npz_paths = {\n",
    "        ct_uid: npz_download_directory.joinpath(f'{ct_uid}.npz')\n",
    "        for ct_uid in ct_uids\n",
    "    }       \n",
    "    \n",
    "    def generator():\n",
    "        for ct_uid, npz_path in npz_paths.items():\n",
    "            if not npz_path.exists():\n",
    "                downloaded_path = pymedphys.zenodo_data_paths(\n",
    "                    record_name, \n",
    "                    filenames=[npz_path.name]\n",
    "                )[0]\n",
    "                \n",
    "                if downloaded_path != npz_path:\n",
    "                    raise ValueError(\"Expected the downloaded path to match the predicted npz_path\")\n",
    "                    \n",
    "            data = np.load(npz_path)\n",
    "            x_grid = data[\"x_grid\"]\n",
    "            y_grid = data[\"y_grid\"]\n",
    "            input_array = data[\"input_array\"]\n",
    "            output_array = data[\"output_array\"]\n",
    "            \n",
    "            input_array = input_array[:, :, None]\n",
    "\n",
    "            yield ct_uid, x_grid, y_grid, input_array, output_array\n",
    "\n",
    "    parameters = (\n",
    "        (tf.string, tf.float64, tf.float64, tf.int32, tf.float64),\n",
    "        (\n",
    "            tf.TensorShape(()),\n",
    "            tf.TensorShape([512]),\n",
    "            tf.TensorShape([512]),\n",
    "            tf.TensorShape([512, 512, 1]),\n",
    "            tf.TensorShape([512, 512, len(structures_to_learn)]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(generator, *parameters)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_from_zenodo_download(\n",
    "    record_name\n",
    "):\n",
    "    filenames_to_download = ['ct_uids_by_training_type.zip', 'structures_to_learn.zip']\n",
    "\n",
    "    configuration_paths = pymedphys.zenodo_data_paths(\n",
    "        record_name, \n",
    "        filenames=filenames_to_download)\n",
    "\n",
    "    configurations = {}\n",
    "    for path in configuration_paths:\n",
    "        with open(path) as f:\n",
    "            configurations[path.stem] = json.load(f)\n",
    "\n",
    "    ct_uids_by_training_type = configurations['ct_uids_by_training_type']\n",
    "    structures_to_learn = configurations['structures_to_learn']\n",
    "    \n",
    "    datasets = {}\n",
    "    for training_type, ct_uids in ct_uids_by_training_type.items():\n",
    "        random.shuffle(ct_uids)\n",
    "        \n",
    "        datasets[training_type] = single_dataset_from_zenodo_download(\n",
    "            record_name, ct_uids, structures_to_learn\n",
    "        )\n",
    "        \n",
    "    return datasets, structures_to_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_name = \"auto-segmentation-eye-lens-patient-npz\"\n",
    "datasets, structures_to_learn = datasets_from_zenodo_download(record_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnostic_plotting(x_grid, y_grid, input_array, output_array):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    \n",
    "    x_grid = x_grid.numpy()\n",
    "    y_grid = y_grid.numpy()\n",
    "    input_array = input_array.numpy()[:,:,0]\n",
    "    output_array = output_array.numpy()\n",
    "    \n",
    "    for i, structure in enumerate(structures_to_learn[0:-1]):\n",
    "        if structure.endswith('left'):\n",
    "            colour = 'r'\n",
    "        elif structure.endswith('right'):\n",
    "            colour = 'b'\n",
    "        else:\n",
    "            raise ValueError(\"Expected either left or right\")\n",
    "            \n",
    "        if structure.startswith('lens'):\n",
    "            colour += '--'\n",
    "        elif structure.startswith('eye'):\n",
    "            colour += '-'\n",
    "        else:\n",
    "            raise ValueError(\"Expected either eye or lens\")\n",
    "\n",
    "        contours = mask.get_contours_from_mask(\n",
    "            x_grid, y_grid, output_array[:,:,i])\n",
    "        for contour in contours:\n",
    "            plt.plot(*contour.T, colour)\n",
    "            \n",
    "    \n",
    "    plt.axis('equal')\n",
    "    ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    contours = mask.get_contours_from_mask(\n",
    "        x_grid, y_grid, output_array[:,:,-1])\n",
    "    for contour in contours:\n",
    "        plt.plot(*contour.T, 'k--')\n",
    "    \n",
    "    windowed = np.copy(input_array)\n",
    "\n",
    "    vmin = 900\n",
    "    vmax = 1200\n",
    "    windowed[windowed<vmin] = vmin\n",
    "    windowed[windowed>vmax] = vmax\n",
    "\n",
    "    plt.contourf(x_grid, y_grid, windowed, 50)\n",
    "    plt.colorbar()\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (\n",
    "    ct_uid, x_grid, y_grid, input_array, output_array\n",
    ") in datasets['training'].prefetch(30):\n",
    "    \n",
    "    ct_uid = ct_uid.numpy().decode()\n",
    "    \n",
    "    display.display(display.Markdown(f\"## {ct_uid}\"))\n",
    "    diagnostic_plotting(x_grid, y_grid, input_array, output_array)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (\n",
    "    ct_uid, x_grid, y_grid, input_array, output_array\n",
    ") in datasets['validation'].prefetch(30):\n",
    "    \n",
    "    ct_uid = ct_uid.numpy().decode()\n",
    "    \n",
    "    display.display(display.Markdown(f\"## {ct_uid}\"))\n",
    "    diagnostic_plotting(x_grid, y_grid, input_array, output_array)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (\n",
    "    ct_uid, x_grid, y_grid, input_array, output_array\n",
    ") in datasets['testing'].prefetch(30):\n",
    "    \n",
    "    ct_uid = ct_uid.numpy().decode()\n",
    "    \n",
    "    display.display(display.Markdown(f\"## {ct_uid}\"))\n",
    "    diagnostic_plotting(x_grid, y_grid, input_array, output_array)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymedphys-master",
   "language": "python",
   "name": "pymedphys-master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
