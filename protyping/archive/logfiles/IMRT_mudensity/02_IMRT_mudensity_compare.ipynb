{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pymedphys.level1.msqconnect import mosaiq_connect\n",
    "from pymedphys.level1.configutilities import (\n",
    "    get_cache_filepaths, get_mu_density_parameters,\n",
    "    get_index, get_centre, get_sql_servers, get_sql_servers_list,\n",
    "    get_filepath\n",
    ")\n",
    "from pymedphys.level1.mudensity import find_relevant_control_points, calc_mu_density\n",
    "from pymedphys.level2.msqdelivery import multi_fetch_and_verify_mosaiq\n",
    "from pymedphys.level3.analyselogfiles import (\n",
    "    analyse_single_hash, find_consecutive_logfiles, get_field_id_key_map, plot_results\n",
    ")\n",
    "\n",
    "from decode_trf.decode_trf import delivery_data_from_logfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config.json') as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = get_index(config)\n",
    "file_hashes = np.array(list(index.keys()))\n",
    "\n",
    "field_types = np.array([\n",
    "    index[file_hash]['delivery_details']['field_type']\n",
    "    for file_hash in file_hashes\n",
    "])\n",
    "\n",
    "file_hashes = file_hashes[field_types == 'DMLC']\n",
    "\n",
    "is_qa = np.array([\n",
    "    index[file_hash]['delivery_details']['qa_mode']\n",
    "    for file_hash in file_hashes\n",
    "])\n",
    "\n",
    "file_hashes = file_hashes[np.invert(is_qa)]\n",
    "\n",
    "machine = np.array([\n",
    "    index[file_hash]['logfile_header']['machine']\n",
    "    for file_hash in file_hashes\n",
    "])\n",
    "\n",
    "# limit to RCCC for now\n",
    "file_hashes = file_hashes[(machine == '2619') | (machine == '2694')]\n",
    "np.random.shuffle(file_hashes)\n",
    "\n",
    "# might need course information\n",
    "index[file_hashes[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_grouped_fields = dict()\n",
    "field_id_grouped_hashes = dict()\n",
    "\n",
    "for file_hash in file_hashes:\n",
    "    delivery_details = index[file_hash]['delivery_details']\n",
    "    patient_id = delivery_details['patient_id']\n",
    "    field_id = delivery_details['field_id']\n",
    "    \n",
    "    if patient_id not in patient_grouped_fields:\n",
    "        patient_grouped_fields[patient_id] = set()\n",
    "        \n",
    "    patient_grouped_fields[patient_id].add(field_id)\n",
    "    \n",
    "    if field_id not in field_id_grouped_hashes:\n",
    "        field_id_grouped_hashes[field_id] = []\n",
    "        \n",
    "    field_id_grouped_hashes[field_id].append(file_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = list(patient_grouped_fields.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = '002911'\n",
    "fields = patient_grouped_fields[patient_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in fields:\n",
    "    print(field_id_grouped_hashes[field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mosaiq_connect('msqsql') as cursor:\n",
    "    for field in fields:\n",
    "        mosaiq_delivery_data = multi_fetch_and_verify_mosaiq(\n",
    "            cursor, field)\n",
    "        print(set(mosaiq_delivery_data.gantry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_consecutive_logfiles(file_hashes, index):\n",
    "    times = np.array([\n",
    "        index[key]['local_time']\n",
    "        for key in file_hashes\n",
    "    ]).astype(np.datetime64)\n",
    "\n",
    "    sort_reference = np.argsort(times)\n",
    "    file_hashes = file_hashes[sort_reference]\n",
    "    times = times[sort_reference]\n",
    "\n",
    "    hours_4 = np.array(60 * 60 * 4).astype(np.timedelta64)\n",
    "    split_locations = np.where(np.diff(times) >= hours_4)[0] + 1\n",
    "\n",
    "    return np.split(file_hashes, split_locations)\n",
    "\n",
    "\n",
    "field_id = list(fields)[0]\n",
    "keys = np.array(field_id_grouped_hashes[field_id])\n",
    "keys = np.hstack([keys, np.array(keys[2])])  # Spin this out into a unit test\n",
    "\n",
    "logfile_groups = group_consecutive_logfiles(keys, index)\n",
    "logfile_groups = [\n",
    "    tuple(group)\n",
    "    for group in logfile_groups\n",
    "]\n",
    "logfile_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_array_agreement(a, b, allowed_deviation):\n",
    "    difference_matrix = np.abs(a[:,None] - b[None,:])\n",
    "    agreement_matrix = difference_matrix <= allowed_deviation\n",
    "    row_agreement = np.any(agreement_matrix, axis=0)\n",
    "    all_rows_have_at_least_one_agreement = np.all(row_agreement)\n",
    "    \n",
    "    return all_rows_have_at_least_one_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mosaiq_connect('msqsql') as cursor:\n",
    "    mosaiq_delivery_data = multi_fetch_and_verify_mosaiq(\n",
    "        cursor, field_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaiq_gantry_angles = np.unique(mosaiq_delivery_data.gantry)\n",
    "mosaiq_gantry_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gantry_tolerance(index, file_hash, config):\n",
    "    machine_name = index[file_hash]['logfile_header']['machine']\n",
    "    machine_type = config['machine_map'][machine_name]['type']\n",
    "    gantry_tolerance = config['machine_types'][machine_type]['gantry_tolerance']\n",
    "    \n",
    "    return gantry_tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_data_grouped_by_gantry_angle = dict()\n",
    "\n",
    "for logfile_group in logfile_groups:\n",
    "    delivery_data_grouped_by_gantry_angle[logfile_group] = dict()\n",
    "    \n",
    "    for file_hash in logfile_group:\n",
    "        filepath = get_filepath(index, config, file_hash)\n",
    "        logfile_delivery_data = delivery_data_from_logfile(filepath)\n",
    "        mu = np.array(logfile_delivery_data.monitor_units)\n",
    "\n",
    "        relevant_control_points = find_relevant_control_points(mu)\n",
    "        \n",
    "        mu = mu[relevant_control_points]\n",
    "        mlc = np.array(logfile_delivery_data.mlc)[relevant_control_points]\n",
    "        jaw = np.array(logfile_delivery_data.jaw)[relevant_control_points]\n",
    "        logfile_gantry_angles = np.array(logfile_delivery_data.gantry)[relevant_control_points]\n",
    "        \n",
    "        gantry_tolerance = get_gantry_tolerance(index, file_hash, config)\n",
    "                \n",
    "        assert check_array_agreement(\n",
    "            np.unique(logfile_gantry_angles), mosaiq_gantry_angles, gantry_tolerance\n",
    "        ), (\n",
    "            'There is a logfile gantry angle that deviates by more than {} degrees '\n",
    "            'from the Mosaiq control points. Unsure how to handle this.'.format(gantry_tolerance))\n",
    "        \n",
    "        delivery_data_grouped_by_gantry_angle[logfile_group][file_hash] = dict()\n",
    "        \n",
    "        for mosaiq_gantry_angle in mosaiq_gantry_angles:\n",
    "            delivery_data_grouped_by_gantry_angle[logfile_group][file_hash][mosaiq_gantry_angle] = dict()\n",
    "            agrees_within_tolerance = (\n",
    "                np.abs(logfile_gantry_angles - mosaiq_gantry_angle) <= gantry_tolerance)\n",
    "            \n",
    "            delivery_data_grouped_by_gantry_angle[logfile_group][file_hash][mosaiq_gantry_angle]['mu'] = mu[agrees_within_tolerance]\n",
    "            delivery_data_grouped_by_gantry_angle[logfile_group][file_hash][mosaiq_gantry_angle]['mlc'] = mlc[agrees_within_tolerance]\n",
    "            delivery_data_grouped_by_gantry_angle[logfile_group][file_hash][mosaiq_gantry_angle]['jaw'] = jaw[agrees_within_tolerance]\n",
    "            \n",
    "            \n",
    "            \n",
    "                \n",
    "#         print(set(logfile_gantry_angles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delivery_data_grouped_by_gantry_angle[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delivery_data_grouped_by_gantry_angle[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_density_by_gantry_angle = dict()\n",
    "\n",
    "for logfile_group in logfile_groups:\n",
    "    delivery_data = delivery_data_grouped_by_gantry_angle[logfile_group]\n",
    "    mu_density_by_gantry_angle[logfile_group] = dict()\n",
    "    \n",
    "    for file_hash in logfile_group:\n",
    "        for mosaiq_gantry_angle in mosaiq_gantry_angles:\n",
    "            mu_density = calc_mu_density(**delivery_data[file_hash][mosaiq_gantry_angle])\n",
    "            if mosaiq_gantry_angle not in mu_density_by_gantry_angle[logfile_group]:\n",
    "                mu_density_by_gantry_angle[logfile_group][mosaiq_gantry_angle] = list(mu_density)\n",
    "            else:\n",
    "                assert np.all(mu_density_by_gantry_angle[logfile_group][mosaiq_gantry_angle][0] == mu_density[0])\n",
    "                assert np.all(mu_density_by_gantry_angle[logfile_group][mosaiq_gantry_angle][1] == mu_density[1])\n",
    "                mu_density_by_gantry_angle[logfile_group][mosaiq_gantry_angle][2] += mu_density[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu_density_by_gantry_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array(mosaiq_delivery_data.monitor_units)\n",
    "mlc = np.array(mosaiq_delivery_data.mlc)\n",
    "jaw = np.array(mosaiq_delivery_data.jaw)\n",
    "gantry_angles = np.array(mosaiq_delivery_data.gantry)\n",
    "\n",
    "mosaiq_delivery_data_by_gantry_angle = dict()\n",
    "\n",
    "for mosaiq_gantry_angle in mosaiq_gantry_angles:\n",
    "    gantry_angle_matches = gantry_angles == mosaiq_gantry_angle\n",
    "    \n",
    "    diff_mu = np.concatenate([[0], np.diff(mu)])[gantry_angle_matches]\n",
    "    gantry_angle_specific_mu = np.cumsum(diff_mu)\n",
    "    \n",
    "#     assert np.sum(np.diff(np.concatenate([[False], gantry_angle_matches, [False]]))) <= 3, (\n",
    "#         \"Cannot currently handle two distinct beams with the same gantry angle that are not \"\n",
    "#         \"immediately adjacent to one another. The way the control points are extracted by \"\n",
    "#         \"gantry angle will appear\"\n",
    "#     )\n",
    "    \n",
    "    mosaiq_delivery_data_by_gantry_angle[mosaiq_gantry_angle] = dict()\n",
    "    mosaiq_delivery_data_by_gantry_angle[mosaiq_gantry_angle]['mu'] = gantry_angle_specific_mu\n",
    "    mosaiq_delivery_data_by_gantry_angle[mosaiq_gantry_angle]['mlc'] = mlc[gantry_angle_matches]\n",
    "    mosaiq_delivery_data_by_gantry_angle[mosaiq_gantry_angle]['jaw'] = jaw[gantry_angle_matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_mu = np.concatenate([[0], np.diff(mu)])\n",
    "# mu = np.cumsum(diff_mu)\n",
    "# mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = np.concatenate([gantry_angles, [-170, -170, -170]])\n",
    "\n",
    "# np.concatenate([[False], test == -170, [False]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaiq_mu_density_by_gantry_angle = dict()\n",
    "\n",
    "for mosaiq_gantry_angle in mosaiq_gantry_angles:\n",
    "    mu_density = calc_mu_density(**mosaiq_delivery_data_by_gantry_angle[mosaiq_gantry_angle])\n",
    "    mosaiq_mu_density_by_gantry_angle[mosaiq_gantry_angle] = mu_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mosaiq_mu_density_by_gantry_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mosaiq_gantry_angle in mosaiq_gantry_angles:\n",
    "    display(Markdown(\"### Gantry Angle: {}\".format(mosaiq_gantry_angle)))\n",
    "    grid_xx = mosaiq_mu_density_by_gantry_angle[mosaiq_gantry_angle][0]\n",
    "    grid_yy = mosaiq_mu_density_by_gantry_angle[mosaiq_gantry_angle][1]\n",
    "    mosaiq_mu_density = mosaiq_mu_density_by_gantry_angle[mosaiq_gantry_angle][2]\n",
    "\n",
    "    for logfile_group in logfile_groups:\n",
    "        for file_hash in logfile_group:\n",
    "            filepath = get_filepath(index, config, file_hash)\n",
    "            print(filepath)\n",
    "        assert np.all(grid_xx == mu_density_by_gantry_angle[logfile_group][mosaiq_gantry_angle][0])\n",
    "        assert np.all(grid_yy == mu_density_by_gantry_angle[logfile_group][mosaiq_gantry_angle][1])\n",
    "\n",
    "        logfile_mu_density = mu_density_by_gantry_angle[logfile_group][mosaiq_gantry_angle][2]\n",
    "        \n",
    "        plot_results(grid_xx, grid_yy, logfile_mu_density, mosaiq_mu_density)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.abs(logfile_gantry_angles - -170) <= gantry_tolerance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gantry_tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.any(np.abs(np.unique(logfile_gantry_angles)[:,None] - mosaiq_gantry_angles[None,:]) <= 0.3, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile_gantry_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaiq_gantry_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile_gantry_angles[change_in_mu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(logfile_delivery_data.mlc)[change_in_mu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change_in_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_hash = file_hashes[0]\n",
    "\n",
    "# logfile_index_record = index[file_hash]\n",
    "# field_id = logfile_index_record['delivery_details']['field_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mosaiq_connect('msqsql') as cursor:\n",
    "    mosaiq_delivery_data = multi_fetch_and_verify_mosaiq(\n",
    "        cursor, field_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaiq_delivery_data.gantry"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
